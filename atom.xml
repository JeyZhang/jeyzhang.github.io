<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Jey Zhang</title>
  <icon>http://www.gravatar.com/avatar/a09a367dbb62016817f10c76cffda3c3</icon>
  <subtitle>Life is Now.</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.jeyzhang.com/"/>
  <updated>2018-04-22T12:28:12.910Z</updated>
  <id>http://www.jeyzhang.com/</id>
  
  <author>
    <name>Jey Zhang</name>
    <email>zhangjieup@gmail.com</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>推荐一本适合机器学习工程师的读物</title>
    <link href="http://www.jeyzhang.com/machine-learning-for-engineers.html"/>
    <id>http://www.jeyzhang.com/machine-learning-for-engineers.html</id>
    <published>2018-04-22T12:09:26.000Z</published>
    <updated>2018-04-22T12:28:12.910Z</updated>
    
    <content type="html"><![CDATA[<p>最近看到一本NG大神写的书，叫《Machine Learning Yearning》。特别适合机器学习方向的工程师们阅读，里面谈到了很多工程上机器学习经常面临的问题，比如如何选择dev/test数据集（如何构造？大概数据量多少合适？），如何对DSAT（分类错误的case）进行分析，提供了很多很好的建议和经验。</p><p>整本书目前仅仅31页（仍在持续更新中），通俗易懂，建议大家（尤其是做这方面的工程师们）阅读~</p><p><strong>下载地址如下</strong>：</p><p>百度云链接地址<a href="https://pan.baidu.com/s/13F25_sZG9aSaqKb7W4waHQ" target="_blank" rel="external">在这里</a> 密码：h7ea</p><p><strong>之前打赏过我的小伙伴可以直接在我分享的学习资料大礼包的”1机器学习”目录下找到，大礼包里面的资源会逐渐更新，之后我看到好的资料也会放在相应的目录下。</strong></p><hr><p><strong>文章写得不错？打赏一个呗:)</strong></p><p><img src="http://i.imgur.com/tTBAnzw.png" alt=""></p><p><strong>【打赏1.99￥以上，备注你的邮箱，可获得博主精心为你准备的深度学习/机器学习/自然语言处理的学习资料大礼包】</strong></p><p><strong>近期博主准备筹建NLP方面的技术群，欢迎感兴趣的小伙伴加我入群交流:)，加好友请备注：”博客”。</strong></p><p><img src="https://i.imgur.com/pBtBjMe.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;最近看到一本NG大神写的书，叫《Machine Learning Yearning》。特别适合机器学习方向的工程师们阅读，里面谈到了很多工程上机器学习经常面临的问题，比如如何选择dev/test数据集（如何构造？大概数据量多少合适？），如何对DSAT（分类错误的case）进
      
    
    </summary>
    
      <category term="Machine Learning" scheme="http://www.jeyzhang.com/categories/Machine-Learning/"/>
    
    
      <category term="Deep Learning" scheme="http://www.jeyzhang.com/tags/Deep-Learning/"/>
    
      <category term="Machine Learning" scheme="http://www.jeyzhang.com/tags/Machine-Learning/"/>
    
      <category term="Resource" scheme="http://www.jeyzhang.com/tags/Resource/"/>
    
  </entry>
  
  <entry>
    <title>北京的一天</title>
    <link href="http://www.jeyzhang.com/one-day-of-beijing.html"/>
    <id>http://www.jeyzhang.com/one-day-of-beijing.html</id>
    <published>2018-04-15T13:04:45.000Z</published>
    <updated>2018-04-15T14:27:23.488Z</updated>
    
    <content type="html"><![CDATA[<p>今天的北京阳光灿烂，风清气爽，气温适宜，好像除了空气中飘着一些烦人的柳絮之外，一切都刚刚好。</p><p>索性去了趟玉渊潭公园，活动活动筋骨。通往公园的桥边上站着一群上了年纪的大爷们守着鱼竿，通往公园的路上各色的人群攒动，耳朵里是小贩的叫卖声，协警的指引声，人群里除了各种寒暄声还夹杂着孩童的哭闹声。这种浓烈喧闹的市民生活气息好像已经很久没有感受过了，工作以来的我一到周末就愿意宅家，躺着不想出门，像在学校读书的时候一样，仿佛在一个属于自己的小角落里与世隔离很久。所以那种喧闹咋一来仿佛还挺新鲜，把我从安静的独居拽入一个仿佛真实仿佛也不那么真实的群体环境里。也许人独处久了，就会希望将自己置身于一个群体中，哪怕这个群体对你而言很陌生，甚至无需与之交流。</p><p>回来的路上，我看着出租车外面那灿烂阳光照耀下的北京，一条条从未觉得如此干净的街道，旁边一棵棵长出嫩绿的小树，周边一幢幢整齐排列的居民楼，还有远处反光的高楼表面，这些画面组合的那一刻，我仿佛感受到了这座城市从所未有的美，似乎这座城市是带有温情的，是一个你愿意安定下来的地方。</p><p>当你感到生活乏味找不到意义时，我建议你挑个天气好的日子出去走走，其实只要自己尝试着放慢自己，细细地去发掘这座城市，你会发现生活其实没有那么无聊糟糕，所在的城市好像也没有那么冰冷无情。我们常在探索生命的意义而未果，而今天的我觉得生命的意义或许就像是树枝上刚长出来的新芽，我们都知道总将有一天它会老化脱落、不复存在，然后周而复始地开始重复着，但此时此刻你看，这些嫩芽就在阳光下闪烁着它的光辉，让人欢欣鼓舞。怀抱着希望并给予身边的人希望，或许就是生命的意义。</p><p>现在的我，则希望能凭借自身的努力在这片土地上找到一个归属的角落。</p><p><img src="https://i.imgur.com/3Qj9d3C.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;今天的北京阳光灿烂，风清气爽，气温适宜，好像除了空气中飘着一些烦人的柳絮之外，一切都刚刚好。&lt;/p&gt;
&lt;p&gt;索性去了趟玉渊潭公园，活动活动筋骨。通往公园的桥边上站着一群上了年纪的大爷们守着鱼竿，通往公园的路上各色的人群攒动，耳朵里是小贩的叫卖声，协警的指引声，人群里除了各种
      
    
    </summary>
    
      <category term="Life" scheme="http://www.jeyzhang.com/categories/Life/"/>
    
    
      <category term="Life" scheme="http://www.jeyzhang.com/tags/Life/"/>
    
  </entry>
  
  <entry>
    <title>解决国内Hexo+Next无法正常使用disqus评论系统的问题</title>
    <link href="http://www.jeyzhang.com/using-disqus-in-china.html"/>
    <id>http://www.jeyzhang.com/using-disqus-in-china.html</id>
    <published>2018-01-21T13:09:02.000Z</published>
    <updated>2018-01-27T14:15:47.062Z</updated>
    
    <content type="html"><![CDATA[<p>今天在家里没有连V的情况下，发现博客的评论竟然加载不出来了（我说这么最近半年博文的评论数直线下降（大雾））…搜了一下才知道原来半年前国内就不能正常访问disqus了，因为本站用到了disqus作为评论系统，所以自然是挂了…</p><p>真是感叹国内的互联网环境的安(xian)全(e)，看了一下解决方法：首先检测当前访问下能不能正常加载disqus（即在一定时间内有响应）；如果能，那么走正常的流程，调disqus的服务即可；如果不能，那么需要通过一个VPS来调用disqus-api来拿到结果，再返回给前端以展示出来。</p><p>立个FLAG，明天抽空来修复一下~<br>（update: 好难… 修了一晚上没修好T_T）</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;今天在家里没有连V的情况下，发现博客的评论竟然加载不出来了（我说这么最近半年博文的评论数直线下降（大雾））…搜了一下才知道原来半年前国内就不能正常访问disqus了，因为本站用到了disqus作为评论系统，所以自然是挂了…&lt;/p&gt;
&lt;p&gt;真是感叹国内的互联网环境的安(xia
      
    
    </summary>
    
      <category term="Hexo" scheme="http://www.jeyzhang.com/categories/Hexo/"/>
    
    
      <category term="Comment" scheme="http://www.jeyzhang.com/tags/Comment/"/>
    
      <category term="Disqus" scheme="http://www.jeyzhang.com/tags/Disqus/"/>
    
      <category term="Hexo" scheme="http://www.jeyzhang.com/tags/Hexo/"/>
    
      <category term="Next" scheme="http://www.jeyzhang.com/tags/Next/"/>
    
  </entry>
  
  <entry>
    <title>我的2018年计划和一些感想</title>
    <link href="http://www.jeyzhang.com/my-plans-for-2018.html"/>
    <id>http://www.jeyzhang.com/my-plans-for-2018.html</id>
    <published>2018-01-20T12:18:16.000Z</published>
    <updated>2018-02-19T13:44:42.000Z</updated>
    
    <content type="html"><![CDATA[<p>建立这个博客已经两年多，自己从来还没有在这上面写过关于个人的东西。当初对这个博客的定位是希望能督促自己多写出一些技术类的文章，一来可以一边学习一边总结，二来也给自己留一个底，方便打捞自己曾经学习过的东西，三来获取能够帮助到别人。</p><p>今天想要写些关于自己的东西，多年没有动笔写作，才发觉文笔生疏了很多，想起五六年前还在读本科的自己，动不动地就在空间里文笔大攉强说愁，现在想来除了觉得有点可笑和幼稚之外，也多了一些感慨。</p><p>实话说，自从工作这一年半以来，我的内心深处一直藏着诸多的迷茫和空洞。不是说工作本身不忙，或者工作内容不够充实，是我发现自从毕业之后，我好像突然没有了一个明确的目标和方向，我每天工作这么忙和加班，但我不知道有什么意义和目的。</p><p>一个友人问我，“你最想得到什么？”。我的第一反应是关于钱和物质，我希望能早日财富自由。友人说那你应该能很容易能实现，但财富的积累并不是一件值得当做梦想的事，除了财富之外呢？我竟无言以对。</p><p>越长大越发现自己逐渐地开始迷失，以前的自己喜欢想象自己的未来，喜欢那些所谓的正能量和鸡汤文，喜欢给自己设定目标并付诸努力加以实现。但工作以来，我发现现在的自己仿佛在距离那个以前的自己越来越远，内心越来越注重现实，而缺少某种情怀。</p><p>昨晚看了一部电影，叫《被嫌弃的松子的一生》，在那些不了解松子（女主）的外人眼中，她的人生如此平庸无聊，甚至是失败和不堪。但通过了解了她的人生才发现，她的人生是多么的轰轰烈烈和敢爱敢恨，至少她那么毫无保留地敢于追逐自己向往的那种爱情过。因为种种的误会、冲动和不幸，她仿佛失去了所有美好的亲情、友情和爱情，在以为人生快要结束的时候顽强地开始，在最终选择重新开始的时候不幸结束，命运有时就是这样富有戏剧性。“生而为人，我很抱歉”，是她最后写给世界的话；但在我看来，如此热烈地活过，远胜于千千万万的那些所谓成功但实则平庸的人生。</p><p>我多么希望我也是这样一个勇敢而纯粹的人啊，有自己的情怀和向往并敢于追逐不向现实低头。</p><p>看完这部影片，我开始想象自己今后的人生。是啊，以后的自己会活成什么样子，是不是如同小时候那样的幻想，有一个光明的未来，抑或是一段普通平庸的时光而已。后来的我开始不敢想，因为就现在的生活状态而言，我不知道未来有什么光明可言，因为现在的我仿佛没有什么理想和追求，每天浑浑噩噩，犯懒，得过且过，好像只是希望获得那些常人看起来的所谓成功，在北京落户、有房有车。我突然觉得，这不是我内心想要真正追求的东西，我还在25岁，年轻时有更值得追求的东西。</p><p>所以，我回顾了之前一些自己的想法和目标。希望列出来，给自己一些提醒，也算是flags吧。公示之也是希望自己会有受到监督的感觉，能有一些压力和动力。</p><ul><li><p><strong>健康和外表</strong>：</p><ul><li>一周至少运动一次；</li><li>多吃多增肌；</li><li>按时休息（11:30左右入睡，坚持午休），保持充沛的精力；</li><li>坚持护肤和保养，保持年轻的状态；</li></ul></li><li><p><strong>技术积累和职业规划</strong></p><ul><li>坚持1-2周能有一篇技术博文（不在乎字数，在乎学到的东西）；</li><li>坚持学习，对技术抱有好奇心和探索精神；</li><li>能多从产品和用户体验角度思考技术上的问题，能够drive一件事情往前直至做成为止（老板给的工作建议）；</li><li>开始关注transfer的事宜，早做准备（口语上和技术上）；</li><li>投入一些精力管理技术群；</li></ul></li><li><p><strong>财务</strong></p><ul><li>坚持学习理财知识，建立一个系统的理财计划，培养自己的风控意识（工作时间之外）；</li><li>能建立一个小的理财交流圈；</li></ul></li><li><p><strong>其他</strong></p><ul><li>每月能够抽空看一些文学类书籍，提升自己的文学修养；</li><li>每1-2周主动给家里打电话，主动关心家里人；</li></ul></li></ul><p>暂时先设这些计划（太多也怕自己完成不了…），后续需要逐步细化，如果有目标最好能够设定一个时间节点，督促自己完成。</p><p>新的一年，走过路过的也来聊聊你的计划和目标？（<strong>在评论区写下你的FLAG，让我们相互督促对方~</strong>）</p><p><strong>愿我们的人生都能【甘于平凡，但不甘于平凡地溃败】。</strong></p><hr><p><strong>文章写得不错？打赏一个呗:)</strong></p><p><img src="http://i.imgur.com/tTBAnzw.png" alt=""></p><p><strong>【打赏1.99￥以上，备注你的邮箱，可获得博主精心为你准备的深度学习/机器学习/自然语言处理的学习资料大礼包】</strong></p><p><strong>近期博主准备筹建NLP方面的技术群，欢迎感兴趣的小伙伴加我入群交流:)，加好友请备注：”博客”。</strong></p><p><img src="https://i.imgur.com/pBtBjMe.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;建立这个博客已经两年多，自己从来还没有在这上面写过关于个人的东西。当初对这个博客的定位是希望能督促自己多写出一些技术类的文章，一来可以一边学习一边总结，二来也给自己留一个底，方便打捞自己曾经学习过的东西，三来获取能够帮助到别人。&lt;/p&gt;
&lt;p&gt;今天想要写些关于自己的东西，多
      
    
    </summary>
    
      <category term="Life" scheme="http://www.jeyzhang.com/categories/Life/"/>
    
    
      <category term="Life" scheme="http://www.jeyzhang.com/tags/Life/"/>
    
  </entry>
  
  <entry>
    <title>文本分类实战系列（一）：特征工程</title>
    <link href="http://www.jeyzhang.com/text-classification-in-action.html"/>
    <id>http://www.jeyzhang.com/text-classification-in-action.html</id>
    <published>2017-12-09T09:15:31.000Z</published>
    <updated>2018-02-19T13:44:53.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文的话题老生常谈，文本分类应该是很多NLPer非常常遇到和熟悉的任务之一了，下面总结一下博主在处理这类任务的过程中特征工程方面的经验，希望对各位NLP入门者或者在做此类任务的新手有所帮助。对于其他的文本处理任务，也会有一定的参考意义。</p><h2 id="概述">概述</h2><p>文本分类，顾名思义，就是根据文本内容本身将文本归为不同的类别，通常是有监督学习的任务。根据文本内容的长短，有做句子、段落或者文章的分类；文本的长短不同可能会导致文本可抽取的特征上的略微差异，但是总体上来说，<strong>文本分类的核心都是如何从文本中抽取出能够体现文本特点的关键特征，抓取特征到类别之间的映射</strong>。所以，特征工程就显得非常重要，特征找的好，分类效果也会大幅提高（当然前提是标注数据质量和数量也要合适，数据的好坏决定效果的下限，特征工程决定效果的上限）。</p><p>也许会有人问最近的深度学习技术能够避免我们构造特征这件事，为什么还需要特征工程？深度学习并不是万能的，在NLP领域深度学习技术取得的效果有限（毕竟语言是高阶抽象的信息，深度学习在图像、语音这些低阶具体的信息处理上更适合，因为在低阶具体的信息上构造特征是一件费力的事情），并不是否认深度学习在NLP领域上取得的成绩，工业界现在通用的做法都是会把深度学习模型作为系统的一个子模块（也是一维特征），和一些传统的基于统计的自然语言技术的特征，还有一些针对具体任务本身专门设计的特征，一起作为一个或多个模型（也称Ensemble，即模型集成）的输入，最终构成一个文本处理系统。</p><h2 id="特征工程">特征工程</h2><p>那么，对于文本分类任务而言，工业界常用到的特征有哪些呢？下面用一张图以概括：</p><p><img src="https://i.imgur.com/TULIWnI.png" alt=""></p><p>我主要将这些特征分为四个层次，由下往上，特征由抽象到具体，粒度从细到粗。我们希望能够从不同的角度和纬度来设计特征，以捕捉这些特征和类别之间的关系。下面详细介绍这四个层次上常用到的特征表示。</p><h3 id="基于词袋模型的特征表示">基于词袋模型的特征表示</h3><p>词袋模型的基本思想是将文本符号化，将一段文本表示成一堆符号的集合；由于中文文本的多样性，通常导致构建的词袋维数较大，仅仅以词为单位（Unigram）构建的词袋可能就达到几万维，如果考虑二元词组（Bigram）、三元词组（Trigram）的话词袋大小可能会有几十万之多，因此基于词袋模型的特征表示通常是极其稀疏的。</p><p>词袋模型的one-hot表示示意图如下（假设我们构建了一个2w维的词袋模型，每一维表示一个词）：</p><p><img src="https://i.imgur.com/25KYCfO.png" alt=""></p><p>从上到下，可以看出几种不同的表示方法：</p><ul><li>第1种：Naive版本，不考虑词出现的频率，只要出现过就在相应的位置标1，否则为0；</li><li>第2种：考虑词频（即term frequency），认为一段文本中出现越多的词越重要，因此权重也越大；</li><li>第3种：考虑词的重要性，以TFIDF表征一个词的重要程度（不了解TFIDF的点<a href="https://zh.wikipedia.org/wiki/Tf-idf" target="_blank" rel="external">这里</a>）。简单来说，<strong>TFIDF反映了一种折中的思想</strong>：即在一篇文档中，TF认为一个词出现的次数越大可能越重要，但也可能并不是（比如停用词：“的”“是”之类的）；IDF认为一个词出现在的文档数越少越重要，但也可能不是（比如一些无意义的生僻词）。</li></ul><p><strong>通常情况下，我们都会采用第3种方法。</strong>原因也很直观，文本中所出现的词的重要程度是不太一样的，比如上面的例子中“我”，“喜欢”，“学习”这3个词就要比其他词更为重要。除了TFIDF的表征方法，还有chi-square，互信息（MI），熵等其他一些衡量词重要性的指标（<a href="https://www.zhihu.com/question/21374143" target="_blank" rel="external">见这里</a>）。但是一般TFIDF用得比较普遍。</p><p><strong>经验总结</strong>：</p><ul><li>通常考虑unigram和bigram来构建词袋模型（trigram的话维数太高，取得的gain也不高）；</li><li>用TFIDF时，注意对TF作归一化，通常用词频除以文本的长度；</li><li>如果构建的词袋维数太高，可以用TF（或者TFIDF）来卡，将一些不常见的词（会有很多噪音词，如联系方式、邮箱之类的）过滤掉；</li><li>如果有一些先验的词袋，word count通常都是比较强的一维特征（比如情感分类中，正负情感词的出现次数），可以考虑；</li><li><strong>基于词袋模型构建的特征通常高维但稀疏，通常使用非线性模型取得的效果较线性的要好，推荐大家尝试使用一些基于决策树的boosting模型，如<a href="https://en.wikipedia.org/wiki/Gradient_boosting" target="_blank" rel="external">GBDT</a></strong>；这也很好理解，较线性模型而言，非线性模型能够学习出更加复杂的规则，对于文本而言，体现在能够一定程度上考虑词出现的语境（context）情况，比如，对于识别文本是否为骂人语料，文本中出现“妈”，同时也出现“你”，那么为骂人的概率会增大。</li></ul><p>词袋模型比较简单直观，它通常能学习出一些关键词和类别之间的映射关系，<strong>但是缺点也很明显</strong>：</p><ul><li>丢失了文本中词出现的先后顺序信息；</li><li>仅将词语符号化，没有考虑词之间的语义联系（比如，“麦克风”和“话筒”是不同的词，但是语义是相同的）；</li></ul><h3 id="基于embedding的特征表示">基于embedding的特征表示</h3><p>上一部分介绍了基于词袋模型如何提取文本特征，这主要是从词形的角度考虑的，并没有考虑词语之间的语义关联信息。提到语义关联，大家都会联想到著名的<a href="https://zh.wikipedia.org/wiki/Word2vec" target="_blank" rel="external">word2vec</a>。<strong>word2vec的原理很简单，基本思想是用词出现的上下文来表示这个词，上下文越接近的词之间的语义相似性越高。</strong>例如，上一小节中举到的例子，“话筒”和“麦克风”两者的上下文可能非常接近，因此会被认为是语义接近的。（不过语义接近并不代表含义接近，例如“黑色”和“白色”的上下文是相似的，但所代表的含义可能却是相反的）。</p><p>目前做word embedding的方法很多，比较流行的有下面两种：</p><ul><li><a href="https://code.google.com/archive/p/word2vec/" target="_blank" rel="external">word2vec</a></li><li><a href="https://nlp.stanford.edu/projects/glove/" target="_blank" rel="external">GloVe</a></li></ul><p>word2vec和GloVe两者的思想是类似的，都是用词的上下文来表示这个词，但是用的方法不同：word2vec是predict-based，用一个3层的NN模型来预测词的上下文（或者反过来），词向量是训练过程的中间产物；而GloVe则是count-based的方法，通过对共现词矩阵做降维来获取词的向量。两者在效果上相差不大，但GloVe模型的优势在于矩阵运算可以并行化，这样训练速度能加快。具体两者的差别可以参考<a href="https://www.quora.com/How-is-GloVe-different-from-word2vec" target="_blank" rel="external">Quora上的回答</a>。</p><p>有了word embedding之后，我们怎么得到文本的embedding呢？</p><p>对于短文本而言，比较好的方法有：</p><p>(1) 取短文本的各个词向量之和（或者取平均）作为文本的向量表示；</p><p>(2) 用一个pre-train好的NN model得到文本作为输入的最后一层向量表示；</p><p>除此之外，还有<a href="https://github.com/minghui/Twitter-LDA" target="_blank" rel="external">TwitterLda</a>，TwitterLda是Lda的简化版本，针对短文本做主题刻画，实际效果也还不错。</p><p>基于embedding的特征刻画的是语义、主题层面上的特征，较词匹配而言，有一定的泛化能力。</p><h3 id="基于NN_Model抽取的特征">基于NN Model抽取的特征</h3><p>NN的好处在于能end2end实现模型的训练和测试，利用模型的非线性和众多参数来学习特征，而不需要手工提取特征。CNN和RNN都是NLP中常用的模型，两个模型捕捉特征的角度也不太一样，<strong>CNN善于捕捉文本中关键的局部信息，而RNN则善于捕捉文本的上下文信息（考虑语序信息），并且有一定的记忆能力，两者都可以用在文本分类任务中，而且效果都不错</strong>。</p><p>对于简单的文本分类任务，用几个简单的NN模型基本就够了（调参数也是一大累活儿）。网上有很多关于NN的实现，这里推荐一个TensorFlow的实现版本，里面有一个浅层的CNN和RNN实现（word-based和chat-based都有），代码也很好懂，可以快速实验验证效果。地址在<a href="https://github.com/gaussic/text-classification-cnn-rnn" target="_blank" rel="external">这里</a>。</p><p>最后我们可以将这些NNs预测的分值作为我们分类系统的一个特征，来加强分类系统的性能。</p><h3 id="基于任务本身抽取的特征">基于任务本身抽取的特征</h3><p>这一部分的特征主要是针对具体任务而设计的，通过我们对数据的观察和感知，也许能够发现一些可能有用的特征。有时候，这些手工特征对最后的分类效果提升很大。举个例子，比如对于正负面评论分类任务，对于负面评论，包含负面词的数量就是一维很强的特征。</p><p>这部分的特征设计就是在拼脑力和拼经验，建议可以多看看各个类别数据找找感觉，将那些你直观上感觉对分类有帮助的东西设计成特征，有时候这些经验主义的东西很有用（可能是模型从数据学习不出来的）。</p><h2 id="特征融合">特征融合</h2><p>在设计完这些特征之后，怎么融合更合适呢？对于特征维数较高、数据模式复杂的情况，建议用非线性模型（如比较流行的GDBT, XGBoost）；对于特征维数较低、数据模式简单的情况，建议用简单的线性模型即可（如LR）。下面分享一个我做特征融合的模型框架，任务是正负面评论分类（负面评论定义是不适合出现在网络上的评论，如政治敏感、带有人身攻击、强烈负面情绪的评论）。</p><p><img src="https://i.imgur.com/2Abcoej.png" alt=""></p><p>其中，橙色框表示模型，蓝色框表示用到的特征，[]里面表示特征的维数。这里需要注意的是，<strong>训练子模型（GBDT/DNN）的训练数据和训练融合模型（LR）的训练数据需要不一样</strong>，这也很好理解，就是防止子模型因为“见过”这些训练数据而产生偏向于子模型的情况。实际的模型训练中，可以用training数据集作为子模型的训练数据，dev数据集作为最终融合模型的训练数据。</p><p>模型融合能够从多个角度更加全面地学习出训练数据中的模式，往往能比单个模型效果好一点（2~3个点左右）。</p><p>另外，通过观察LR模型给各个特征分配的权重大小和正负，我们可以看出对于训练数据而言，这些特征影响分类的重要程度（权重大小（绝对值）），以及特征影响最终分类目标的极性。特别的，我们可以通过观察那些手工特征的权重来验证这些特征的有效性和有效程度。</p><h2 id="总结">总结</h2><p>这篇文章主要从宏观上介绍了对于文本分类任务而言设计特征的思路，对于其他的NLP任务，也可以参考类似的方法。总而言之，特征工程的核心是尽量从多个角度和纬度来捕捉数据中的模式，并用数值特征来加以刻画。最近流行的深度学习模型可以end2end地学习数据中隐含的模式，免去了人工提取特征的麻烦，然而对于信息高度抽象的文本数据而言，深度学习模型能取得的效果有限，在实际的产品中，我们往往会加入一些传统的基于统计学习的自然语言技术，以及根据我们对业务和数据的理解而人工设计的特征，来最终实现一个比较优良的结果。</p><p>下一篇，我会具体介绍一下文本分类中常用到的模型和算法。请各位坐等更新:)</p><hr><p>本文结束，感谢欣赏。</p><p><strong>欢迎转载，请注明本文的链接地址：</strong></p><p><a href="http://www.jeyzhang.com/text-classification-in-action.html">http://www.jeyzhang.com/text-classification-in-action.html</a></p><hr><p><strong>文章写得不错？打赏一个呗:)</strong> </p><p><img src="http://i.imgur.com/tTBAnzw.png" alt=""></p><p><strong>【打赏1.99￥以上，备注你的邮箱，可获得博主精心为你准备的深度学习/机器学习/自然语言处理的学习资料大礼包】</strong></p><p><strong>近期博主准备筹建NLP方面的技术群，欢迎感兴趣的小伙伴加我入群交流:)，加好友请备注：”博客”。</strong></p><p><img src="https://i.imgur.com/pBtBjMe.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本文的话题老生常谈，文本分类应该是很多NLPer非常常遇到和熟悉的任务之一了，下面总结一下博主在处理这类任务的过程中特征工程方面的经验，希望对各位NLP入门者或者在做此类任务的新手有所帮助。对于其他的文本处理任务，也会有一定的参考意义。&lt;/p&gt;
&lt;h2 id=&quot;概述&quot;&gt;概述
      
    
    </summary>
    
      <category term="Deep Learning" scheme="http://www.jeyzhang.com/categories/Deep-Learning/"/>
    
    
      <category term="Deep Learning" scheme="http://www.jeyzhang.com/tags/Deep-Learning/"/>
    
      <category term="Feature Engineering" scheme="http://www.jeyzhang.com/tags/Feature-Engineering/"/>
    
      <category term="NLP" scheme="http://www.jeyzhang.com/tags/NLP/"/>
    
      <category term="TensorFlow" scheme="http://www.jeyzhang.com/tags/TensorFlow/"/>
    
      <category term="Text Classification" scheme="http://www.jeyzhang.com/tags/Text-Classification/"/>
    
  </entry>
  
  <entry>
    <title>理解LSTM/RNN中的Attention机制</title>
    <link href="http://www.jeyzhang.com/understand-attention-in-rnn.html"/>
    <id>http://www.jeyzhang.com/understand-attention-in-rnn.html</id>
    <published>2017-07-03T10:59:56.000Z</published>
    <updated>2018-02-19T13:44:57.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="导读">导读</h3><p>目前采用编码器-解码器 (Encode-Decode) 结构的模型非常热门，是因为它在许多领域较其他的传统模型方法都取得了更好的结果。这种结构的模型通常将输入序列编码成一个固定长度的向量表示，对于长度较短的输入序列而言，该模型能够学习出对应合理的向量表示。然而，这种模型存在的问题在于：<strong>当输入序列非常长时，模型难以学到合理的向量表示</strong>。</p><p>在这篇博文中，我们将探索加入LSTM/RNN模型中的attention机制是如何克服传统编码器-解码器结构存在的问题的。</p><p>通过阅读这篇博文，你将会学习到：</p><ul><li>传统编码器-解码器结构存在的问题及如何将输入序列编码成固定的向量表示；</li><li>Attention机制是如何克服上述问题的，以及在模型输出时是如何考虑输出与输入序列的每一项关系的；</li><li>基于attention机制的LSTM/RNN模型的5个应用领域：机器翻译、图片描述、语义蕴涵、语音识别和文本摘要。</li></ul><p>让我们开始学习吧。</p><h3 id="长输入序列带来的问题">长输入序列带来的问题</h3><p>使用传统编码器-解码器的RNN模型先用一些LSTM单元来对输入序列进行学习，编码为固定长度的向量表示；然后再用一些LSTM单元来读取这种向量表示并解码为输出序列。</p><p>采用这种结构的模型在许多比较难的序列预测问题（如文本翻译）上都取得了最好的结果，因此迅速成为了目前的主流方法。</p><p>例如：</p><ul><li><a href="https://arxiv.org/abs/1409.3215" target="_blank" rel="external">Sequence to Sequence Learning with Neural Networks, 2014</a></li><li><a href="https://arxiv.org/abs/1406.1078" target="_blank" rel="external">Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation, 2014</a></li></ul><p>这种结构在很多其他的领域上也取得了不错的结果。然而，它存在一个问题在于：<strong>输入序列不论长短都会被编码成一个固定长度的向量表示，而解码则受限于该固定长度的向量表示</strong>。</p><p>这个问题限制了模型的性能，尤其是<strong>当输入序列比较长时，模型的性能会变得很差</strong>（在文本翻译任务上表现为待翻译的原始文本长度过长时翻译质量较差）。</p><blockquote><p>“一个潜在的问题是，采用编码器-解码器结构的神经网络模型需要将输入序列中的必要信息表示为一个固定长度的向量，而当输入序列很长时则难以保留全部的必要信息（因为太多），尤其是当输入序列的长度比训练数据集中的更长时。”</p><p>— Dzmitry Bahdanau, et al., <a href="https://arxiv.org/abs/1409.0473" target="_blank" rel="external">Neural machine translation by jointly learning to align and translate, 2015</a></p></blockquote><h3 id="使用attention机制">使用attention机制</h3><p>Attention机制的基本思想是，<strong>打破了传统编码器-解码器结构在编解码时都依赖于内部一个固定长度向量的限制</strong>。</p><p>Attention机制的实现是<strong>通过保留LSTM编码器对输入序列的中间输出结果，然后训练一个模型来对这些输入进行选择性的学习并且在模型输出时将输出序列与之进行关联</strong>。</p><p>换一个角度而言，输出序列中的每一项的生成概率取决于在输入序列中选择了哪些项。</p><blockquote><p>“在文本翻译任务上，使用attention机制的模型每生成一个词时都会在输入序列中找出一个与之最相关的词集合。之后模型根据当前的上下文向量 (context vectors) 和所有之前生成出的词来预测下一个目标词。</p><p>… 它将输入序列转化为一堆向量的序列并自适应地从中选择一个子集来解码出目标翻译文本。这感觉上像是用于文本翻译的神经网络模型需要“压缩”输入文本中的所有信息为一个固定长度的向量，不论输入文本的长短。”</p><p>— Dzmitry Bahdanau, et al., <a href="https://arxiv.org/abs/1409.0473" target="_blank" rel="external">Neural machine translation by jointly learning to align and translate, 2015</a></p></blockquote><p>虽然模型使用attention机制之后会增加计算量，但是性能水平能够得到提升。另外，使用attention机制便于理解在模型输出过程中输入序列中的信息是如何影响最后生成序列的。这有助于我们更好地理解模型的内部运作机制以及对一些特定的输入-输出进行debug。</p><blockquote><p>“论文提出的方法能够直观地观察到生成序列中的每个词与输入序列中一些词的对齐关系，这可以通过对标注 (annotations) 权重参数可视化来实现…每个图中矩阵的每一行表示与标注相关联的权重。由此我们可以看出在生成目标词时，源句子中的位置信息会被认为更重要。”</p><p>— Dzmitry Bahdanau, et al., <a href="https://arxiv.org/abs/1409.0473" target="_blank" rel="external">Neural machine translation by jointly learning to align and translate, 2015</a></p></blockquote><h3 id="大型图片带来的问题">大型图片带来的问题</h3><p>被广泛应用于计算机视觉领域的卷积神经网络模型同样存在类似的问题： 对于特别大的图片输入，模型学习起来比较困难。</p><p>由此，一种启发式的方法是将在模型做预测之前先对大型图片进行某种近似的表示。</p><blockquote><p>“人类的感知有一个重要的特性是不会立即处理外界的全部输入，相反的，人类会将注意力专注于所选择的部分来得到所需要的信息，然后结合不同时间段的局部信息来建立一个内部的场景表示，从而引导眼球的移动及做出决策。”</p><p>— <a href="https://arxiv.org/abs/1406.6247" target="_blank" rel="external">Recurrent Models of Visual Attention, 2014</a></p></blockquote><p>这种启发式方法某种程度上也可以认为是考虑了attention，但在这篇博文中，这种方法并不认为是基于attention机制的。</p><p>基于attention机制的相关论文如下：</p><ul><li><a href="https://arxiv.org/abs/1406.6247" target="_blank" rel="external">Recurrent Models of Visual Attention, 2014</a></li><li><a href="https://arxiv.org/abs/1502.04623" target="_blank" rel="external">DRAW: A Recurrent Neural Network For Image Generation, 2014</a></li><li><a href="https://arxiv.org/abs/1412.7755" target="_blank" rel="external">Multiple Object Recognition with Visual Attention, 2014</a></li></ul><h3 id="基于attention模型的应用实例">基于attention模型的应用实例</h3><p>这部分将列举几个具体的应用实例，介绍attention机制是如何用在LSTM/RNN模型来进行序列预测的。</p><h4 id="1-_Attention在文本翻译任务上的应用">1. Attention在文本翻译任务上的应用</h4><p>文本翻译这个实例在前面已经提过了。</p><p>给定一个法语的句子作为输入序列，需要输出翻译为英语的句子。Attention机制被用在输出输出序列中的每个词时会专注考虑输入序列中的一些被认为比较重要的词。</p><blockquote><p>我们对原始的编码器-解码器模型进行了改进，使其有一个模型来对输入内容进行搜索，也就是说在生成目标词时会有一个编码器来做这个事情。这打破了之前的模型是基于将整个输入序列强行编码为一个固定长度向量的限制，同时也让模型在生成下一个目标词时重点考虑输入中相关的信息。</p><p>— Dzmitry Bahdanau, et al., <a href="https://arxiv.org/abs/1409.0473" target="_blank" rel="external">Neural machine translation by jointly learning to align and translate, 2015</a></p></blockquote><p><img src="http://i.imgur.com/V9HYowa.png" alt=""></p><p><em>Attention在文本翻译任务（输入为法语文本序列，输出为英语文本序列）上的可视化（图片来源于Dzmitry Bahdanau, et al., <a href="https://arxiv.org/abs/1409.0473" target="_blank" rel="external">Neural machine translation by jointly learning to align and translate, 2015</a>）</em></p><h4 id="2-_Attention在图片描述上的应用">2. Attention在图片描述上的应用</h4><p>与之前启发式方法不同的是，基于序列生成的attention机制可以应用在计算机视觉相关的任务上，帮助卷积神经网络重点关注图片的一些局部信息来生成相应的序列，典型的任务就是对一张图片进行文本描述。</p><p>给定一张图片作为输入，输出对应的英文文本描述。Attention机制被用在输出输出序列的每个词时会专注考虑图片中不同的局部信息。</p><blockquote><p>我们提出了一种基于attention的方法，该方法在3个标准数据集上都取得了最佳的结果……同时展现了attention机制能够更好地帮助我们理解模型地生成过程，模型学习到的对齐关系与人类的直观认知非常的接近（如下图）。</p><p>— <a href="https://arxiv.org/abs/1502.03044" target="_blank" rel="external">Show, Attend and Tell: Neural Image Caption Generation with Visual Attention, 2016</a></p></blockquote><p><img src="http://i.imgur.com/qycpffZ.png" alt=""></p><p><em>Attention在图片描述任务（输入为图片，输出为描述的文本）上的可视化（图片来源于Attend and Tell: Neural Image Caption Generation with Visual Attention, 2016）</em></p><h4 id="3-_Attention在语义蕴涵_(Entailment)_中的应用">3. Attention在语义蕴涵 (Entailment) 中的应用</h4><p>给定一个用英文描述的前提和假设作为输入，输出假设与前提是否矛盾、是否相关或者是否成立。</p><p>举个例子：</p><p><strong>前提</strong>：在一个婚礼派对上拍照</p><p><strong>假设</strong>：有人结婚了</p><p>该例子中的假设是成立的。</p><p>Attention机制被用于关联假设和前提描述文本之间词与词的关系。</p><blockquote><p>我们提出了一种基于LSTM的神经网络模型，和把每个输入文本都独立编码为一个语义向量的模型不同的是，该模型同时读取前提和假设两个描述的文本序列并判断假设是否成立。我们在模型中加入了attention机制来找出假设和前提文本中词/短语之间的对齐关系。……加入attention机制能够使模型在实验结果上有2.6个点的提升，这是目前数据集上取得的最好结果…</p><p>— <a href="https://arxiv.org/abs/1509.06664" target="_blank" rel="external">Reasoning about Entailment with Neural Attention, 2016</a></p></blockquote><p><img src="http://i.imgur.com/B70hRCE.png" alt=""></p><p><em>Attention在语义蕴涵任务（输入是前提文本，输出是假设文本）上的可视化（图片来源于Reasoning about Entailment with Neural Attention, 2016）</em></p><h4 id="4-_Attention在语音识别上的应用">4. Attention在语音识别上的应用</h4><p>给定一个英文的语音片段作为输入，输出对应的音素序列。</p><p>Attention机制被用于对输出序列的每个音素和输入语音序列中一些特定帧进行关联。</p><blockquote><p>…一种基于attention机制的端到端可训练的语音识别模型，能够结合文本内容和位置信息来选择输入序列中下一个进行编码的位置。该模型有一个优点是能够识别长度比训练数据长得多的语音输入。</p><p>— <a href="https://arxiv.org/abs/1506.07503" target="_blank" rel="external">Attention-Based Models for Speech Recognition, 2015.</a></p></blockquote><p><img src="http://i.imgur.com/BTCD2NH.png" alt=""></p><p><em>Attention在语音识别任务（输入是音帧，输出是音素的位置）上的可视化（图片来源于Attention-Based Models for Speech Recognition, 2015）</em></p><h4 id="5-_Attention在文本摘要上的应用">5. Attention在文本摘要上的应用</h4><p>给定一篇英文文章作为输入序列，输出一个对应的摘要序列。</p><p>Attention机制被用于关联输出摘要中的每个词和输入中的一些特定词。</p><blockquote><p>… 在最近神经网络翻译模型的发展基础之上，提出了一个用于生成摘要任务的基于attention的神经网络模型。通过将这个概率模型与一个生成式方法相结合来生成出准确的摘要。</p><p>— <a href="https://arxiv.org/abs/1509.00685" target="_blank" rel="external">A Neural Attention Model for Abstractive Sentence Summarization, 2015</a></p></blockquote><p><img src="http://i.imgur.com/Kh3gwhV.png" alt=""></p><p><em>Attention在文本摘要任务（输入为文章，输出为文本摘要）上的可视化（图片来源于A Neural Attention Model for Abstractive Sentence Summarization, 2015）</em></p><h3 id="进一步的阅读">进一步的阅读</h3><p>如果你想进一步地学习如何在LSTM/RNN模型中加入attention机制，可阅读以下论文：</p><ul><li><a href="http://www.wildml.com/2016/01/attention-and-memory-in-deep-learning-and-nlp/" target="_blank" rel="external">Attention and memory in deep learning and NLP</a></li><li><a href="https://blog.heuritech.com/2016/01/20/attention-mechanism/" target="_blank" rel="external">Attention Mechanism</a></li><li><a href="http://yanran.li/peppypapers/2015/10/07/survey-attention-model-1.html" target="_blank" rel="external">Survey on Attention-based Models Applied in NLP</a></li><li><a href="https://www.quora.com/What-is-exactly-the-attention-mechanism-introduced-to-RNN-recurrent-neural-network-It-would-be-nice-if-you-could-make-it-easy-to-understand" target="_blank" rel="external">What is exactly the attention mechanism introduced to RNN?</a> （来自Quora）</li><li><a href="https://www.quora.com/What-is-Attention-Mechanism-in-Neural-Networks" target="_blank" rel="external">What is Attention Mechanism in Neural Networks?</a></li></ul><p>目前Keras官方还没有单独将attention模型的代码开源，下面有一些第三方的实现：</p><ul><li><a href="http://ben.bolte.cc/blog/2016/language.html" target="_blank" rel="external">Deep Language Modeling for Question Answering using Keras</a></li><li><a href="https://github.com/fchollet/keras/issues/2067" target="_blank" rel="external">Attention Model Available!</a></li><li><a href="https://github.com/philipperemy/keras-attention-mechanism" target="_blank" rel="external">Keras Attention Mechanism</a></li><li><a href="https://github.com/fchollet/keras/issues/1472" target="_blank" rel="external">Attention and Augmented Recurrent Neural Networks</a></li><li><a href="https://github.com/fchollet/keras/issues/4962" target="_blank" rel="external">How to add Attention on top of a Recurrent Layer (Text Classification)</a></li><li><a href="https://github.com/fchollet/keras/issues/1472" target="_blank" rel="external">Attention Mechanism Implementation Issue</a></li><li><a href="https://github.com/fchollet/keras/issues/2612" target="_blank" rel="external">Implementing simple neural attention model (for padded inputs)</a></li><li><a href="https://github.com/fchollet/keras/issues/1094" target="_blank" rel="external">Attention layer requires another PR</a></li><li><a href="https://github.com/farizrahman4u/seq2seq" target="_blank" rel="external">seq2seq library</a></li></ul><h3 id="总结">总结</h3><p>通过这篇博文，你应该学习到了attention机制是如何应用在LSTM/RNN模型中来解决序列预测存在的问题。</p><p>具体而言，采用传统编码器-解码器结构的LSTM/RNN模型存在一个问题：不论输入长短都将其编码成一个固定长度的向量表示，这使模型对于长输入序列的学习效果很差（解码效果很差）。而attention机制则克服了上述问题，原理是在模型输出时会选择性地专注考虑输入中的对应相关的信息。使用attention机制的方法被广泛应用在各种序列预测任务上，包括文本翻译、语音识别等。</p><hr><p>本文结束，感谢欣赏。</p><p>感谢原作者<strong><a href="http://machinelearningmastery.com/author/jasonb/" target="_blank" rel="external">Jason Brownlee</a></strong>。原文链接见：<strong><a href="http://machinelearningmastery.com/attention-long-short-term-memory-recurrent-neural-networks/" target="_blank" rel="external">Attention in Long Short-Term Memory Recurrent Neural Networks</a></strong></p><p>同时，本译文稍作修改被刊登在公众号：<strong>AI科技大本营</strong>上，文章链接见<strong><a href="http://mp.weixin.qq.com/s/0SWcAAiuN3BYtStDZXyAXg" target="_blank" rel="external">一文读懂Attention：Facebook曾拿CNN秒杀谷歌，现如今谷歌拿它秒杀所有人</a></strong>。欢迎关注这个公众号（微信搜索<strong>rgznai100</strong>），上面有较多机器学习/深度学习相关的资源（尽管文章稍有些标题党=。=）。</p><hr><p><strong>文章写得不错？打赏一个呗:)</strong></p><p><img src="http://i.imgur.com/tTBAnzw.png" alt=""></p><p><strong>【打赏1.99￥以上，备注你的邮箱，可获得博主精心为你准备的深度学习/机器学习/自然语言处理的学习资料大礼包】</strong></p><p><strong>近期博主准备筹建NLP方面的技术群，欢迎感兴趣的小伙伴加我入群交流:)，加好友请备注：”博客”。</strong></p><p><img src="https://i.imgur.com/pBtBjMe.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;导读&quot;&gt;导读&lt;/h3&gt;&lt;p&gt;目前采用编码器-解码器 (Encode-Decode) 结构的模型非常热门，是因为它在许多领域较其他的传统模型方法都取得了更好的结果。这种结构的模型通常将输入序列编码成一个固定长度的向量表示，对于长度较短的输入序列而言，该模型能够学习出
      
    
    </summary>
    
      <category term="Deep Learning" scheme="http://www.jeyzhang.com/categories/Deep-Learning/"/>
    
    
      <category term="Attention" scheme="http://www.jeyzhang.com/tags/Attention/"/>
    
      <category term="Deep Learning" scheme="http://www.jeyzhang.com/tags/Deep-Learning/"/>
    
      <category term="LSTM" scheme="http://www.jeyzhang.com/tags/LSTM/"/>
    
      <category term="Machine Learning" scheme="http://www.jeyzhang.com/tags/Machine-Learning/"/>
    
      <category term="RNN" scheme="http://www.jeyzhang.com/tags/RNN/"/>
    
  </entry>
  
  <entry>
    <title>聊天机器人中的深度学习技术之二：基于检索模型的实现</title>
    <link href="http://www.jeyzhang.com/deep-learning-for-chatbots-2.html"/>
    <id>http://www.jeyzhang.com/deep-learning-for-chatbots-2.html</id>
    <published>2016-11-27T03:05:31.000Z</published>
    <updated>2018-02-19T13:44:38.000Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://www.jeyzhang.com/deep-learning-for-chatbots-1.html">上篇博文：聊天机器人中的深度学习技术之一：导读</a>主要从宏观上对目前聊天机器人所用到的主要技术进行了介绍。这篇博文会介绍并实现一个基于检索的模型，使用了双层Decoder的LSTM模型，通过这个模型可以实现聊天机器人。</p><p>本文涉及到的数据和代码见<a href="https://github.com/dennybritz/chatbot-retrieval/" target="_blank" rel="external">Github仓库地址</a>。</p><hr><h2 id="基于检索模型的聊天机器人">基于检索模型的聊天机器人</h2><p>本文我们将介绍和实现一个基于检索模型的聊天机器人。检索模型所使用的回复数据通常是<strong>预先存储且知道（或定义）的数据</strong>，而不像生成式模型那样可以创造出崭新的、未知的回复内容（模型没有见过）。准确来讲，检索式模型的输入是<strong>一段上下文内容 C (会话到目前未知的内容信息)</strong> 和<strong>一个可能作为回复的候选答案</strong>；模型的输出是对这个候选答案的打分。寻找最合适的回复内容的过程是：先对一堆候选答案进行打分及排序，最后选出分值最高的那个最为回复。</p><p>也许你会质疑为什么不直接使用生成式模型，生成式模型不需要预先存储且定义好的数据，比起检索模型更加的灵活多变。原因在于目前生成式模型的效果并不佳，由于生成式模型的约束条件少，过于多变的模型导致生成的response中出现一些语法错误和语义无关的内容。生成式模型需要海量的训练数据，且难以优化。目前工业界常用的模型还是基于检索的模型，或者以生成式模型作为补充的两者结合，谷歌的<a href="http://arxiv.org/abs/1606.04870" target="_blank" rel="external">Smart Reply</a>就是一个例子。尽管目前生成式模型是学术界的研究热点，但在实践中使用检索式模型是更加合适的选择。</p><h2 id="Ubuntu对话数据集">Ubuntu对话数据集</h2><p>这篇博客我们将使用Ubuntu对话数据集（<a href="http://arxiv.org/abs/1506.08909" target="_blank" rel="external">论文来源</a> <a href="https://github.com/rkadlec/ubuntu-ranking-dataset-creator" target="_blank" rel="external">github地址</a>）。这个数据集（Ubuntu Dialog Corpus, UDC）是目前最大的公开对话数据集之一，它是来自Ubuntu的IRC网络上的对话日志。<a href="http://arxiv.org/abs/1506.08909" target="_blank" rel="external">这篇论文</a>介绍了该数据集生成的具体细节。下面简单介绍一下数据的格式。</p><p>训练数据有1,000,000条实例，其中一半是正例（label为1），一半是负例（label为0，负例为随机生成）。每条实例包括一段上下文信息（context），即Query；和一段可能的回复内容，即Response；Label为1表示该Response确实是Query的回复，Label为0则表示不是。下面是数据示例：</p><p><img src="http://i.imgur.com/tlKSbnT.png" alt=""></p><p>数据集的生成使用了<a href="http://www.nltk.org/" target="_blank" rel="external">NLTK工具</a>，包括分词、stemmed、lemmatized等文本预处理步骤；同时还使用了NER技术，将文本中的实体，如姓名、地点、组织、URL等替换成特殊字符。这些文本预处理并不是必须的，但是能够提升一些模型的性能。据统计，query的平均长度为86个word，而response的平均长度为17个word，更多的数据统计信息见<a href="https://github.com/dennybritz/chatbot-retrieval/blob/master/notebooks/Data%20Exploration.ipynb" target="_blank" rel="external">Jupyter notebook</a>。</p><p>数据集也包括了测试和验证集，但这两部分的数据和训练数据在格式上不太一样。在测试集和验证集中，对于每一条实例，有一个正例和九个负例数据（也称为干扰数据）。模型的目标在于给正例的得分尽可能的高，而给负例的得分尽可能的低。下面是数据示例：</p><p><img src="http://i.imgur.com/EoEK6vy.png" alt=""></p><p>模型的评测方式有很多种。其中最常用到的是<strong>recall@k</strong>，即经模型对候选的response排序后，前k个候选中存在正例数据（正确的那个）的占比；显然k值越大，该指标会越高，因为这对模型性能的要求越松。</p><p>在Ubuntu数据集中，负例数据都是随机生成的；然而在现实中，想要从全部的数据中随机生成负例是不可能的。谷歌的Smart Reply则使用了<a href="http://arxiv.org/abs/1606.04870" target="_blank" rel="external">聚类技术</a>，然后将每个类的中取一些作为负例，这样生成负例的方式显得更加合理（考虑了负例数据的多样性，同时减少时间开销）。</p><h2 id="BASELINE">BASELINE</h2><p>在使用NN模型之前，先设立一些简单的baseline模型，以方便后续的效果对比。使用如下的函数来计算<strong>recall@k</strong>:</p><pre><code><span class="function"><span class="keyword">def</span> <span class="title">evaluate_recall</span><span class="params">(y, y_test, k=<span class="number">1</span>)</span>:</span>    num_examples = float(len(y))    num_correct = <span class="number">0</span>    <span class="keyword">for</span> predictions, label <span class="keyword">in</span> zip(y, y_test):        <span class="keyword">if</span> label <span class="keyword">in</span> predictions[:k]:            num_correct += <span class="number">1</span>    <span class="keyword">return</span> num_correct/num_examples</code></pre><p>其中，<code>y</code>是所预测的以降序排列的模型预测分值，<code>y_test</code>是实际的label值。举个例子，假设<code>y</code>的值为[0,3,1,2,5,6,4,7,8,9]，这说明第0号的候选的预测分值最高、作为回复的可能性最高，而9号则最低。这里的第0号同时也是正确的那个，即正例数据，标号为1-9的为随机生成的负例数据。</p><p>理论上，最base的随机模型（Random Predictor）的recall@1的值为10%，recall@2的值为20%。相应的代码如下：</p><pre><code><span class="comment"># Random Predictor</span><span class="function"><span class="keyword">def</span> <span class="title">predict_random</span><span class="params">(context, utterances)</span>:</span>    <span class="keyword">return</span> np.random.choice(len(utterances), <span class="number">10</span>, replace=<span class="keyword">False</span>)<span class="comment"># Evaluate Random predictor</span>y_random = [predict_random(test_df.Context[x], test_df.iloc[x,<span class="number">1</span>:].values) <span class="keyword">for</span> x <span class="keyword">in</span> range(len(test_df))]y_test = np.zeros(len(y_random))<span class="keyword">for</span> n <span class="keyword">in</span> [<span class="number">1</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">10</span>]:    print(<span class="string">"Recall @ ({}, 10): {:g}"</span>.format(n, evaluate_recall(y_random, y_test, n)))</code></pre><p>实际的模型结果如下：</p><pre><code>Recall @ (<span class="number">1</span>, <span class="number">10</span>): <span class="number">0.0937632</span>Recall @ (<span class="number">2</span>, <span class="number">10</span>): <span class="number">0.194503</span>Recall @ (<span class="number">5</span>, <span class="number">10</span>): <span class="number">0.49297</span>Recall @ (<span class="number">10</span>, <span class="number">10</span>): <span class="number">1</span></code></pre><p>这与理论预期相符，但这不是我们所追求的结果。</p><p>另外一个baseline的模型为<strong>tfidf predictor</strong>。tfidf表示词频（term frequency）和逆文档词频（inverse document frequency），它衡量了一个词在一篇文档中的重要程度（基于整个语料库）。直观上，两篇文档对应的tfidf向量越接近，两篇文章的内容也越相似。同样的，对于一个QR pair，它们语义上接近的词共现的越多，也将越可能是一个正确的QR pair（<strong>这句话存疑，原因在于QR之间也有可能不存在语义上的相似，一个Q对应的R是多样的。</strong>）。tfidf predictor对应的代码如下（利用<a href="http://scikit-learn.org/" target="_blank" rel="external">scikit-learn工具</a>能够轻易实现）：</p><pre><code>class <span class="type">TFIDFPredictor</span>:    def __init__(self):        self.vectorizer = <span class="type">TfidfVectorizer</span>()    def train(self, data):        self.vectorizer.fit(np.append(data.<span class="type">Context</span>.values,data.<span class="type">Utterance</span>.values))    def predict(self, context, utterances):        <span class="comment"># Convert context and utterances into tfidf vector</span>        vector_context = self.vectorizer.transform([context])        vector_doc = self.vectorizer.transform(utterances)        <span class="comment"># The dot product measures the similarity of the resulting vectors</span>        <span class="literal">result</span> = np.dot(vector_doc, vector_context.T).todense()        <span class="literal">result</span> = np.asarray(<span class="literal">result</span>).flatten()        <span class="comment"># Sort by top results and return the indices in descending order</span>        <span class="keyword">return</span> np.argsort(<span class="literal">result</span>, axis=<span class="number">0</span>)[::-<span class="number">1</span>]<span class="comment"># Evaluate TFIDF predictor</span>pred = <span class="type">TFIDFPredictor</span>()pred.train(train_df)y = [pred.predict(test_df.<span class="type">Context</span>[x], test_df.iloc[x,<span class="number">1</span>:].values) <span class="keyword">for</span> x <span class="keyword">in</span> <span class="type">range</span>(len(test_df))]<span class="keyword">for</span> n <span class="keyword">in</span> [<span class="number">1</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">10</span>]:    print(<span class="string">"Recall @ ({}, 10): {:g}"</span>.format(n, evaluate_recall(y, y_test, n)))</code></pre><p>模型结果如下：</p><pre><code>Recall @ (<span class="number">1</span>, <span class="number">10</span>): <span class="number">0.495032</span>Recall @ (<span class="number">2</span>, <span class="number">10</span>): <span class="number">0.596882</span>Recall @ (<span class="number">5</span>, <span class="number">10</span>): <span class="number">0.766121</span>Recall @ (<span class="number">10</span>, <span class="number">10</span>): <span class="number">1</span></code></pre><p>显然这比Random的模型要好得多，但这还不够。之前的假设并不完美，首先query和response之间并不一定要是语义上的相近；其次tfidf模型忽略了词序这一重要的信息。使用NN模型我们能做得更好一些。</p><h2 id="LSTM">LSTM</h2><p>这篇博文将建立的NN模型为两层Encoder的LSTM模型（Dual Encoder LSTM Network），这种形式的网络被广泛应用在chatbot中（尽管可能效果并不是最佳的那个，你可以尽可能地尝试其他的NN模型）。<a href="https://www.tensorflow.org/versions/r0.9/tutorials/seq2seq/index.html" target="_blank" rel="external">seq2seq模型</a>常用于机器翻译领域，并取得了较大的效果。使用Dual LSTM模型的原因在于这个模型被证明在这个数据集有较好的效果（<a href="http://arxiv.org/abs/1510.03753" target="_blank" rel="external">详情见这里</a>）,这可以作为我们后续模型效果的验证。</p><p>两层Encoder的LSTM模型的结构图如下（<a href="http://arxiv.org/abs/1506.08909" target="_blank" rel="external">论文来源</a>）：</p><p><img src="http://i.imgur.com/qpFDJWM.png" alt=""></p><p>大致的流程如下：</p><p>(1) Query和Response都是经过分词的，分词后每个词embedded为向量形式。初始的词向量使用<a href="http://nlp.stanford.edu/projects/glove/" target="_blank" rel="external">GloVe vectors</a>，之后词向量随着模型的训练会进行fine-tuned（实验发现，初始的词向量使用GloVe并没有在性能上带来显著的提升）。</p><p>(2) 分词且向量化的Query和Response经过相同的RNN（word by word）。RNN最终生成一个向量表示，捕捉了Query和Response之间的[语义联系]（图中的c和r）；这个向量的维度是可以指定的，这里指定为256维。</p><p>(3) 将向量c与一个矩阵M相乘，来预测一个可能的回复r’。如果c为一个256维的向量，M维256*256的矩阵，两者相乘的结果为另一个256维的向量，我们可以将其解释为[一个生成式的回复向量]。矩阵M是需要训练的参数。</p><p>(4) 通过点乘的方式来预测生成的回复r’和候选的回复r之间的相似程度，点乘结果越大表示候选回复作为回复的可信度越高；之后通过sigmoid函数归一化，转成概率形式。图中把第(3)步和第(4)步结合在一起了。</p><p>为了训练模型，我们还需要一个损失函数（loss function）。这里使用二元的交叉熵（binary cross-entropy）作为损失函数。我们已知实例的真实label <code>y</code>，值为0或1；通过上面的第(4)步可以得到一个概率值 <code>y&#39;</code>；因此，交叉熵损失值为<code>L = -y * ln(y&#39;) - (1 - y) * ln(1 - y&#39;)</code>。这个公式的意义是直观的，即当<code>y=1</code>时，<code>L = -ln(y&#39;)</code>，我们期望<code>y&#39;</code>尽量地接近1使得损失函数的值越小；反之亦然。</p><p>实现过程中使用了<a href="http://www.numpy.org/" target="_blank" rel="external">numpy</a>、<a href="http://pandas.pydata.org/" target="_blank" rel="external">pandas</a>、<a href="http://www.tensorflow.org/" target="_blank" rel="external">TensorFlow</a>和<a href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/learn/python/learn" target="_blank" rel="external">TF Learn</a>等工具。</p><h3 id="数据预处理">数据预处理</h3><p><a href="https://github.com/rkadlec/ubuntu-ranking-dataset-creator" target="_blank" rel="external">数据集</a>的原始格式为csv格式，我们需要先将其转为<a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/example/example.proto" target="_blank" rel="external">TensorFlow专有的格式</a>，这种格式的好处在于能够直接从输入文件中load tensors，并让TensorFlow来处理洗牌(shuffling)、批量(batching)和队列化(queuing)等操作。预处理中还包括创建一个字典库，将词进行标号，TFRecord文件将直接存储这些词的标号。</p><p>每个实例包括如下几个字段：</p><ul><li>Query：表示为一串词标号的序列，如[231, 2190, 737, 0, 912]；</li><li>Query的长度；</li><li>Response：同样是一串词标号的序列；</li><li>Response的长度；</li><li>Label；</li><li>Distractor_[N]：表示负例干扰数据，仅在验证集和测试集中有，N的取值为0-8；</li><li>Distractor_[N]的长度；</li></ul><p>数据预处理的Python脚本见<a href="https://github.com/dennybritz/chatbot-retrieval/blob/master/scripts/prepare_data.py" target="_blank" rel="external">这里</a>，生成了3个文件：train.tfrecords, validation.tfrecords 和 test.tfrecords。你可以尝试自己运行程序，或者直接下载和使用<a href="https://drive.google.com/open?id=0B_bZck-ksdkpVEtVc1R6Y01HMWM" target="_blank" rel="external">预处理后的数据</a>。</p><h3 id="创建输入函数">创建输入函数</h3><p>为了使用TensoFlow内置的训练和评测模块，我们需要创建一个输入函数：这个函数返回输入数据的batch。因为训练数据和测试数据的格式不同，我们需要创建不同的输入函数。输入函数需要返回批量(batch)的特征和标签值(如果有的话)。类似于如下：</p><pre><code><span class="function"><span class="keyword">def</span> <span class="title">input_fn</span><span class="params">()</span>:</span>  <span class="comment"># TODO Load and preprocess data here</span>  <span class="keyword">return</span> batched_features, labels</code></pre><p>因为我们需要在模型训练和评测过程中使用不同的输入函数，为了防止重复书写代码，我们创建一个包装器(wrapper)，名称为<code>create_input_fn</code>，针对不同的mode使用相应的code，如下：</p><pre><code><span class="function"><span class="keyword">def</span> <span class="title">create_input_fn</span><span class="params">(mode, input_files, batch_size, num_epochs=None)</span>:</span>  <span class="function"><span class="keyword">def</span> <span class="title">input_fn</span><span class="params">()</span>:</span>    <span class="comment"># TODO Load and preprocess data here</span>    <span class="keyword">return</span> batched_features, labels  <span class="keyword">return</span> input_fn</code></pre><p>完整的code见<a href="https://github.com/dennybritz/chatbot-retrieval/blob/master/udc_inputs.py" target="_blank" rel="external">udc_inputs.py</a>。整体上，这个函数做了如下的事情：</p><p>(1) 定义了示例文件中的feature字段；<br>(2) 使用<code>tf.TFRecordReader</code>来读取<code>input_files</code>中的数据；<br>(3) 根据feature字段的定义对数据进行解析；<br>(4) 提取训练数据的标签；<br>(5) 产生批量化的训练数据；<br>(6) 返回批量的特征数据及对应标签；</p><h3 id="定义评测指标">定义评测指标</h3><p>之前已经提到用<code>recall@k</code>这个指标来评测模型，TensorFlow中已经实现了许多标准指标（包括<code>recall@k</code>）。为了使用这些指标，需要创建一个字典，key为指标名称，value为对应的计算函数。如下：</p><pre><code><span class="function"><span class="keyword">def</span> <span class="title">create_evaluation_metrics</span><span class="params">()</span>:</span>  eval_metrics = {}  <span class="keyword">for</span> k <span class="keyword">in</span> [<span class="number">1</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">10</span>]:    eval_metrics[<span class="string">"recall_at_%d"</span> % k] = functools.partial(        tf.contrib.metrics.streaming_sparse_recall_at_k,        k=k)  <span class="keyword">return</span> eval_metrics</code></pre><p>如上，我们使用了<a href="https://docs.python.org/2/library/functools.html#functools.partial" target="_blank" rel="external">functools.partial</a>函数，这个函数的输入参数有两个。不要被<code>streaming_sparse_recall_at_k</code>所困惑，其中的<code>streaming</code>的含义是表示指标的计算是增量式的。</p><p>训练和测试所使用的评测方式是不一样的，训练过程中我们对每个case可能作为正确回复的概率进行预测，而测试过程中我们对每组数据（包含10个case，其中1个是正确的，另外9个是生成的负例/噪音数据）中的case进行逐条概率预测，得到例如<code>[0.34, 0.11, 0.22, 0.45, 0.01, 0.02, 0.03, 0.08, 0.33, 0.11]</code>这样格式的输出，这些输出值的和并不要求为1（因为是逐条预测的，有单独的预测概率值，在0到1之间）；而对于这组数据而言，因为<code>数据index=0</code>对应的为正确答案，这里<code>recall@1</code>为0，因为<code>0.34</code>是其中第二大的值，所以<code>recall@2</code>是1（表示这组数据中预测概率值在前二的中有一个是正确的）。</p><h3 id="训练程序样例">训练程序样例</h3><p>首先，给一个模型训练和测试的程序样例，这之后你可以参照程序中所用到的标准函数，来快速切换和使用其他的网络模型。假设我们有一个函数<code>model_fn</code>，函数的输入参数有<code>batched features</code>，<code>label</code>和<code>mode(train/evaluation)</code>，函数的输出为预测值。程序样例如下：</p><pre><code>estimator = tf.contrib.learn.Estimator(model_fn=model_fn,model_dir=MODEL_DIR,config=tf.contrib.learn.RunConfig())input_fn_train = udc_inputs.create_input_fn(mode=tf.contrib.learn.ModeKeys.TRAIN,input_files=[TRAIN_FILE],batch_size=hparams.batch_size)input_fn_eval = udc_inputs.create_input_fn(mode=tf.contrib.learn.ModeKeys.EVAL,input_files=[VALIDATION_FILE],batch_size=hparams.eval_batch_size,num_epochs=<span class="number">1</span>)eval_metrics = udc_metrics.create_evaluation_metrics()<span class="comment"># We need to subclass theis manually for now. The next TF version will</span><span class="comment"># have support ValidationMonitors with metrics built-in.</span><span class="comment"># It's already on the master branch.</span><span class="class"><span class="keyword">class</span> <span class="title">EvaluationMonitor</span><span class="params">(tf.contrib.learn.monitors.EveryN)</span>:</span><span class="function"><span class="keyword">def</span> <span class="title">every_n_step_end</span><span class="params">(self, step, outputs)</span>:</span>  self._estimator.evaluate(    input_fn=input_fn_eval,    metrics=eval_metrics,    steps=<span class="keyword">None</span>)eval_monitor = EvaluationMonitor(every_n_steps=FLAGS.eval_every)estimator.fit(input_fn=input_fn_train, steps=<span class="keyword">None</span>, monitors=[eval_monitor])</code></pre><p>这里创建了一个<code>model_fn</code>的<code>estimator</code>(评估函数)；两个输入函数，<code>input_fn_train</code>和<code>input_fn_eval</code>，以及计算评测指标的函数；</p><h3 id="创建模型">创建模型</h3><p>到目前为止，我们创建了模型的输入、解析、评测和训练的样例程序。现在我们来写LSTM的程序，<a href="https://github.com/dennybritz/chatbot-retrieval/blob/master/udc_model.py" target="_blank" rel="external">create_model_fn</a>函数用以处理不同格式的训练和测试数据；它的输入参数为<code>model_impl</code>，这个函数表示实际作出预测的模型，这里就是用的LSTM，当然你可以替换成任意的其他模型。程序如下：</p><pre><code><span class="function"><span class="keyword">def</span> <span class="title">dual_encoder_model</span><span class="params">(    hparams,    mode,    context,    context_len,    utterance,    utterance_len,    targets)</span>:</span>  <span class="comment"># Initialize embedidngs randomly or with pre-trained vectors if available</span>  embeddings_W = get_embeddings(hparams)  <span class="comment"># Embed the context and the utterance</span>  context_embedded = tf.nn.embedding_lookup(      embeddings_W, context, name=<span class="string">"embed_context"</span>)  utterance_embedded = tf.nn.embedding_lookup(      embeddings_W, utterance, name=<span class="string">"embed_utterance"</span>)  <span class="comment"># Build the RNN</span>  <span class="keyword">with</span> tf.variable_scope(<span class="string">"rnn"</span>) <span class="keyword">as</span> vs:    <span class="comment"># We use an LSTM Cell</span>    cell = tf.nn.rnn_cell.LSTMCell(        hparams.rnn_dim,        forget_bias=<span class="number">2.0</span>,        use_peepholes=<span class="keyword">True</span>,        state_is_tuple=<span class="keyword">True</span>)    <span class="comment"># Run the utterance and context through the RNN</span>    rnn_outputs, rnn_states = tf.nn.dynamic_rnn(        cell,        tf.concat(<span class="number">0</span>, [context_embedded, utterance_embedded]),        sequence_length=tf.concat(<span class="number">0</span>, [context_len, utterance_len]),        dtype=tf.float32)    encoding_context, encoding_utterance = tf.split(<span class="number">0</span>, <span class="number">2</span>, rnn_states.h)  <span class="keyword">with</span> tf.variable_scope(<span class="string">"prediction"</span>) <span class="keyword">as</span> vs:    M = tf.get_variable(<span class="string">"M"</span>,      shape=[hparams.rnn_dim, hparams.rnn_dim],      initializer=tf.truncated_normal_initializer())    <span class="comment"># "Predict" a  response: c * M</span>    generated_response = tf.matmul(encoding_context, M)    generated_response = tf.expand_dims(generated_response, <span class="number">2</span>)    encoding_utterance = tf.expand_dims(encoding_utterance, <span class="number">2</span>)    <span class="comment"># Dot product between generated response and actual response</span>    <span class="comment"># (c * M) * r</span>    logits = tf.batch_matmul(generated_response, encoding_utterance, <span class="keyword">True</span>)    logits = tf.squeeze(logits, [<span class="number">2</span>])    <span class="comment"># Apply sigmoid to convert logits to probabilities</span>    probs = tf.sigmoid(logits)    <span class="comment"># Calculate the binary cross-entropy loss</span>    losses = tf.nn.sigmoid_cross_entropy_with_logits(logits, tf.to_float(targets))  <span class="comment"># Mean loss across the batch of examples</span>  mean_loss = tf.reduce_mean(losses, name=<span class="string">"mean_loss"</span>)  <span class="keyword">return</span> probs, mean_loss</code></pre><p>完整的程序见<a href="https://github.com/dennybritz/chatbot-retrieval/blob/master/models/dual_encoder.py" target="_blank" rel="external">dual_encoder.py</a>。基于这个，我们能够实例化model函数在我们之前定义的<a href="https://github.com/dennybritz/chatbot-retrieval/blob/master/udc_train.py" target="_blank" rel="external">udc_train.py</a>，如下：</p><pre><code><span class="attribute">model_fn </span>=<span class="string"> udc_model.create_model_fn(  hparams=hparams,  model_impl=dual_encoder_model)</span></code></pre><p>这样我们就可以直接运行<code>udc_train.py</code>文件，来开始模型的训练和评测了，你可以设定<code>--eval_every</code>参数来控制模型在验证集上的评测频率。更多的命令行参数信息可见<code>tf.flags</code>和<code>hparams</code>，你也可以运行<code>python udc_train.py --help</code>来查看。</p><p>运行程序的效果如下：</p><pre><code>INFO:tensorflow:training step <span class="number">20200</span>, loss = <span class="number">0.36895</span> (<span class="number">0.330</span> sec/batch).INFO:tensorflow:Step <span class="number">20201</span>: mean_loss:<span class="number">0</span> = <span class="number">0.385877</span>INFO:tensorflow:training step <span class="number">20300</span>, loss = <span class="number">0.25251</span> (<span class="number">0.338</span> sec/batch).INFO:tensorflow:Step <span class="number">20301</span>: mean_loss:<span class="number">0</span> = <span class="number">0.405653</span>...INFO:tensorflow:Results after <span class="number">270</span> steps (<span class="number">0.248</span> sec/batch): recall_at_1 = <span class="number">0.507581018519</span>, recall_at_2 = <span class="number">0.689699074074</span>, recall_at_5 = <span class="number">0.913020833333</span>, recall_at_10 = <span class="number">1.0</span>, loss = <span class="number">0.5383</span>...</code></pre><h3 id="模型的评测">模型的评测</h3><p>在训练完模型后，你可以将其应用在测试集上，使用：</p><pre><code>python udc_test.py --model_dir=<span class="variable">$MODEL</span>_DIR_FROM_TRAINING    </code></pre><p>例如：</p><pre><code>python udc_test.py --model_dir=~<span class="regexp">/github/</span>chatbot-retrieval<span class="regexp">/runs/</span><span class="number">1467389151</span></code></pre><p>这将得到模型在测试集上的<code>recall@k</code>的结果，注意在使用<code>udc_test.py</code>文件时，需要使用与训练时相同的参数。</p><p>在训练模型的次数大约2w次时(在GPU上大约花费1小时)，模型在测试集上得到如下的结果：</p><pre><code>recall_at_1 = <span class="number">0.507581018519</span>recall_at_2 = <span class="number">0.689699074074</span>recall_at_5 = <span class="number">0.913020833333</span></code></pre><p>其中，<code>recall@1</code>的值与tfidf模型的差不多，但是<code>recall@2</code>和<code>recall@5</code>的值则比tfidf模型的结果好太多。原论文中的结果依次是0.55,0.72和0.92，可能通过模型调参或者预处理能够达到这个结果。</p><h3 id="使用模型进行预测">使用模型进行预测</h3><p>对于新的数据，你可以使用<a href="https://github.com/dennybritz/chatbot-retrieval/blob/master/udc_predict.py" target="_blank" rel="external">udc_predict.py</a>来进行预测；例如：</p><pre><code>python udc_predict<span class="class">.py</span> --model_dir=./runs/<span class="number">1467576365</span>/</code></pre><p>结果如下：</p><pre><code>Context: Example contextResponse <span class="number">1</span>: <span class="number">0.44806</span>Response <span class="number">2</span>: <span class="number">0.481638</span></code></pre><p>你可以从候选的回复中，选择预测分值最高的那个作为回复。</p><h3 id="总结">总结</h3><p>这篇博文中，我们实现了一个基于检索的NN模型，它能够对候选的回复进行预测和打分，通过输出分值最高（或者满足一定阈值）的候选回复已完成聊天的过程。后续可以尝试其他更好的模型，或者通过调参来取得更好的实验结果。</p><p>以上内容为原文 <a href="http://www.wildml.com/2016/07/deep-learning-for-chatbots-2-retrieval-based-model-tensorflow/" target="_blank" rel="external">DEEP LEARNING FOR CHATBOTS, PART 2 – IMPLEMENTING A RETRIEVAL-BASED MODEL IN TENSORFLOW</a> 的翻译，供自己学习及他人参考。本文涉及到的数据和代码见<a href="https://github.com/dennybritz/chatbot-retrieval/" target="_blank" rel="external">Github仓库地址</a>。</p><hr><p>本文结束，感谢欣赏。</p><p><strong>欢迎转载，请注明本文的链接地址：</strong></p><p><a href="http://www.jeyzhang.com/deep-learning-for-chatbots-2.html">http://www.jeyzhang.com/deep-learning-for-chatbots-2.html</a></p><hr><p><strong>文章写得不错？打赏一个呗:)</strong></p><p><img src="http://i.imgur.com/tTBAnzw.png" alt=""></p><p><strong>【打赏1.99￥以上，备注你的邮箱，可获得博主精心为你准备的深度学习/机器学习/自然语言处理的学习资料大礼包】</strong></p><p><strong>近期博主准备筹建NLP方面的技术群，欢迎感兴趣的小伙伴加我入群交流:)，加好友请备注：”博客”。</strong></p><p><img src="https://i.imgur.com/pBtBjMe.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a href=&quot;http://www.jeyzhang.com/deep-learning-for-chatbots-1.html&quot;&gt;上篇博文：聊天机器人中的深度学习技术之一：导读&lt;/a&gt;主要从宏观上对目前聊天机器人所用到的主要技术进行了介绍。这篇博文会介绍并实现一个基于
      
    
    </summary>
    
      <category term="Deep Learning" scheme="http://www.jeyzhang.com/categories/Deep-Learning/"/>
    
    
      <category term="ChatBot" scheme="http://www.jeyzhang.com/tags/ChatBot/"/>
    
      <category term="Deep Learning" scheme="http://www.jeyzhang.com/tags/Deep-Learning/"/>
    
      <category term="TensorFlow" scheme="http://www.jeyzhang.com/tags/TensorFlow/"/>
    
  </entry>
  
  <entry>
    <title>理解LSTM网络</title>
    <link href="http://www.jeyzhang.com/understanding-lstm-network.html"/>
    <id>http://www.jeyzhang.com/understanding-lstm-network.html</id>
    <published>2016-10-19T03:38:26.000Z</published>
    <updated>2018-02-19T13:42:22.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="循环神经网络(RNN)">循环神经网络(RNN)</h2><p>人们的每次思考并不都是从零开始的。比如说你在阅读这篇文章时，你基于对前面的文字的理解来理解你目前阅读到的文字，而不是每读到一个文字时，都抛弃掉前面的思考，从头开始。你的记忆是有持久性的。</p><p>传统的神经网络并不能如此，这似乎是一个主要的缺点。例如，假设你在看一场电影，你想对电影里的每一个场景进行分类。传统的神经网络不能够基于前面的已分类场景来推断接下来的场景分类。</p><p>循环神经网络(Recurrent Neural Networks)解决了这个问题。这种神经网络带有环，可以将信息持久化。</p><p><img src="http://7xqwhn.com1.z0.glb.clouddn.com/2016-10-19-14585451475265.jpg" alt="Recurrent Neural Networks have loops. -c100"></p><a id="more"></a><p>在上图所示的神经网络$A$中，输入为$X_t$，输出为$h_t$。$A$上的环允许将每一步产生的信息传递到下一步中。环的加入使得RNN变得神秘。不过，如果你多思考一下的话，其实RNN跟普通的神经网络也没有那么不同。一个RNN可以看作是同一个网络的多份副本，每一份都将信息传递到下一个副本。如果我们将环展开的话：</p><p><img src="http://7xqwhn.com1.z0.glb.clouddn.com/2016-10-19-14585464218639.png" alt="An unrolled recurrent neural network. -c600"></p><p>这种链式结构展示了RNN与序列和列表的密切关系。RNN的这种结构能够非常自然地使用这类数据。而且事实的确如此。在过去的几年里，RNN在一系列的任务中都取得了令人惊叹的成就，比如语音识别，语言建模，翻译，图片标题等等。关于RNN在各个领域所取得的令人惊叹的成就，参见<a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/" target="_blank" rel="external">这篇文章</a>。</p><p>LSTM是这一系列成功中的必要组成部分。LSTM(Long Short Term Memory)是一种特殊的循环神经网络，在许多任务中，LSTM表现得比标准的RNN要出色得多。几乎所有基于RNN的令人赞叹的结果都是LSTM取得的。本文接下来将着重介绍LSTM。</p><h2 id="长期依赖(Long_Term_Dependencies)的问题">长期依赖(Long Term Dependencies)的问题</h2><p>RNN的一个核心思想是将以前的信息连接到当前的任务中来，例如，通过前面的视频帧来帮助理解当前帧。如果RNN真的能够这样做的话，那么它们将会极其有用。但是事实真是如此吗？未必。</p><p>有时候，我们只需要看最近的信息，就可以完成当前的任务。比如，考虑一个语言模型，通过前面的单词来预测接下来的单词。如果我们想预测句子“the clouds are in the <em>sky</em>”中的最后一个单词，我们不需要更多的上下文信息——很明显下一个单词应该是sky。在这种情况下，当前位置与相关信息所在位置之间的距离相对较小，RNN可以被训练来使用这样的信息。</p><p><img src="http://7xqwhn.com1.z0.glb.clouddn.com/2016-10-19-14585476990034.jpg" alt="-c400"></p><p>然而，有时候我们需要更多的上下文信息。比如，我们想预测句子“I grew up in France… I speak fluent <em>French</em>”中的最后一个单词。最近的信息告诉我们，最后一个单词可能是某种语言的名字，然而如果我们想确定到底是哪种语言的话，我们需要France这个更远的上下文信息。实际上，相关信息和需要该信息的位置之间的距离可能非常的远。</p><p>不幸的是，随着距离的增大，RNN对于如何将这样的信息连接起来无能为力。</p><p><img src="http://7xqwhn.com1.z0.glb.clouddn.com/2016-10-19-14585481509571.png" alt="-c600"></p><p>理论上说，RNN是有能力来处理这种长期依赖(Long Term Dependencies)的。人们可以通过精心调参来构建模型处理一个这种玩具问题(Toy Problem)。不过，在实际问题中，RNN并没有能力来学习这些。<a href="http://people.idsia.ch/~juergen/SeppHochreiter1991ThesisAdvisorSchmidhuber.pdf" target="_blank" rel="external">Hochreiter (1991) German</a>更深入地讲了这个问题，<a href="http://www-dsi.ing.unifi.it/~paolo/ps/tnn-94-gradient.pdf" target="_blank" rel="external">Bengio, et al. (1994)</a>发现了RNN的一些非常基础的问题。</p><p>幸运的是，LSTM并没有上述问题！</p><h2 id="LSTM网络">LSTM网络</h2><p>LSTM，全称为长短期记忆网络(Long Short Term Memory networks)，是一种特殊的RNN，能够学习到长期依赖关系。LSTM由<a href="http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf" target="_blank" rel="external">Hochreiter &amp; Schmidhuber (1997)</a>提出，许多研究者进行了一系列的工作对其改进并使之发扬光大。LSTM在许多问题上效果非常好，现在被广泛使用。</p><p>LSTM在设计上明确地避免了长期依赖的问题。记住长期信息是小菜一碟！所有的循环神经网络都有着重复的神经网络模块形成链的形式。在普通的RNN中，重复模块结构非常简单，例如只有一个tanh层。</p><p><img src="http://7xqwhn.com1.z0.glb.clouddn.com/2016-10-19-14585498578776.jpg" alt="The repeating module in a standard RNN contains a single layer. -c600"></p><p>LSTM也有这种链状结构，不过其重复模块的结构不同。LSTM的重复模块中有4个神经网络层，并且他们之间的交互非常特别。</p><p><img src="http://7xqwhn.com1.z0.glb.clouddn.com/2016-10-19-14585500063294.png" alt="The repeating module in an LSTM contains four interacting layers. -c600"></p><p>现在暂且不必关心细节，稍候我们会一步一步地对LSTM的各个部分进行介绍。开始之前，我们先介绍一下将用到的标记。</p><p><img src="http://7xqwhn.com1.z0.glb.clouddn.com/2016-10-19-14585501719114.jpg" alt="-c500"></p><p>在上图中，每条线表示向量的传递，从一个结点的输出传递到另外结点的输入。粉红圆表示向量的元素级操作，比如相加或者相乘。黄色方框表示神经网络的层。线合并表示向量的连接，线分叉表示向量复制。</p><h2 id="LSTM核心思想">LSTM核心思想</h2><p>LSTM的关键是元胞状态(Cell State)，下图中横穿整个元胞顶部的水平线。</p><p>元胞状态有点像是传送带，它直接穿过整个链，同时只有一些较小的线性交互。上面承载的信息可以很容易地流过而不改变。</p><p><img src="http://7xqwhn.com1.z0.glb.clouddn.com/2016-10-19-14585507601229.jpg" alt="-c600"></p><p>LSTM有能力对元胞状态添加或者删除信息，这种能力通过一种叫门的结构来控制。</p><p>门是一种选择性让信息通过的方法。它们由一个Sigmoid神经网络层和一个元素级相乘操作组成。</p><p><img src="http://7xqwhn.com1.z0.glb.clouddn.com/2016-10-19-14585511223368.jpg" alt="-c100"></p><p>Sigmoid层输出0~1之间的值，每个值表示对应的部分信息是否应该通过。0值表示不允许信息通过，1值表示让所有信息通过。一个LSTM有3个这种门，来保护和控制元胞状态。</p><h2 id="LSTM分步详解">LSTM分步详解</h2><p>LSTM的第一步是决定我们将要从元胞状态中扔掉哪些信息。该决定由一个叫做“遗忘门(Forget Gate)”的Sigmoid层控制。遗忘门观察\(h_{t-1}\)和\(x_{t}\)，对于元胞状态\(C_{t-1}\)中的每一个元素，输出一个0~1之间的数。1表示“完全保留该信息”，0表示“完全丢弃该信息”。</p><p>回到之前的预测下一个单词的例子。在这样的一个问题中，元胞状态可能包含当前主语的性别信息，以用来选择正确的物主代词。当我们遇到一个新的主语时，我们就需要把旧的性别信息遗忘掉。</p><p><img src="http://7xqwhn.com1.z0.glb.clouddn.com/2016-10-19-14585517843913.jpg" alt="-c600"></p><p>下一步是决定我们将会把哪些新信息存储到元胞状态中。这步分为两部分。首先，有一个叫做“输入门(Input Gate)”的Sigmoid层决定我们要更新哪些信息。接下来，一个tanh层创造了一个新的候选值，$\tilde{C_t}$，该值可能被加入到元胞状态中。在下一步中，我们将会把这两个值组合起来用于更新元胞状态。</p><p>在语言模型的例子中，我们可能想要把新主语的性别加到元胞状态中，来取代我们已经遗忘的旧值。</p><p><img src="http://7xqwhn.com1.z0.glb.clouddn.com/2016-10-19-14585522130400.jpg" alt="-c600"></p><p>现在我们该更新旧元胞状态$C_{t-1}$到新状态$C_t$了。上面的步骤中已经决定了该怎么做，这一步我们只需要实际执行即可。</p><p>我们把旧状态$C_{t-1}$乘以$f_t$，忘掉我们已经决定忘记的内容。然后我们再加上$i_t * \tilde{C_t}$，这个值由新的候选值（$\tilde{C_t}$）乘以候选值的每一个状态我们决定更新的程度（$i_t$）构成。</p><p>还是语言模型的例子，在这一步，我们按照之前的决定，扔掉了旧的主语的性别信息，并且添加了新的信息。</p><p><img src="http://7xqwhn.com1.z0.glb.clouddn.com/2016-10-19-14585647039038.jpg" alt="-c600"></p><p>最后，我们需要决定最终的输出。输出将会基于目前的元胞状态，并且会加入一些过滤。首先我们建立一个Sigmoid层的输出门(Output Gate)，来决定我们将输出元胞的哪些部分。然后我们将元胞状态通过tanh之后（使得输出值在-1到1之间），与输出门相乘，这样我们只会输出我们想输出的部分。</p><p>对于语言模型的例子，由于刚刚只输出了一个主语，因此下一步可能需要输出与动词相关的信息。举例来说，可能需要输出主语是单数还是复数，以便于我们接下来选择动词时能够选择正确的形式。</p><p><img src="http://7xqwhn.com1.z0.glb.clouddn.com/2016-10-19-14585652046323.jpg" alt="-c600"></p><h2 id="LSTM的变种">LSTM的变种</h2><p>本文前面所介绍的LSTM是最普通的LSTM，但并非所有的LSTM模型都与前面相同。事实上，似乎每一篇paper中所用到的LSTM都是稍微不一样的版本。不同之处很微小，不过其中一些值得介绍。</p><p>一个流行的LSTM变种，由<a href="ftp://ftp.idsia.ch/pub/juergen/TimeCount-IJCNN2000.pdf" target="_blank" rel="external">Gers &amp; Schmidhuber (2000)</a>提出，加入了“窥视孔连接(peephole connection)”。也就是说我们让各种门可以观察到元胞状态。</p><p><img src="http://7xqwhn.com1.z0.glb.clouddn.com/2016-10-19-14585655553885.jpg" alt="-c600"></p><p>上图中，对于所有的门都加入了“窥视孔”，不过也有一些paper中只加一部分。</p><p>另一种变种是使用<strong>对偶</strong>的遗忘门和输入门。我们不再是单独地决定需要遗忘什么信息，需要加入什么新信息；而是一起做决定：我们只会在需要在某处放入新信息时忘记该处的旧值；我们只会在已经忘记旧值的位置放入新值。</p><p><img src="http://7xqwhn.com1.z0.glb.clouddn.com/2016-10-19-14585661398239.jpg" alt="-c600"></p><p>另一个变化更大一些的LSTM变种叫做Gated Recurrent Unit，或者GRU，由<a href="http://arxiv.org/pdf/1406.1078v3.pdf" target="_blank" rel="external">Cho, et al. (2014)</a>提出。GRU将遗忘门和输入门合并成为单一的“更新门(Update Gate)”。GRU同时也将元胞状态(Cell State)和隐状态(Hidden State)合并，同时引入其他的一些变化。该模型比标准的LSTM模型更加简化，同时现在也变得越来越流行。</p><p><img src="http://7xqwhn.com1.z0.glb.clouddn.com/2016-10-19-14585667357562.png" alt="-c600"></p><p>另外还有很多其他的模型，比如<a href="http://arxiv.org/pdf/1508.03790v2.pdf" target="_blank" rel="external">Yao, et al. (2015)</a>提出的Depth Gated RNNs。同时，还有很多完全不同的解决长期依赖问题的方法，比如<a href="http://arxiv.org/pdf/1402.3511v1.pdf" target="_blank" rel="external">Koutnik, et al. (2014)</a>提出的Clockwork RNNs。</p><p>不同的模型中哪个最好？这其中的不同真的有关系吗？<a href="http://arxiv.org/pdf/1503.04069.pdf" target="_blank" rel="external">Greff, et al. (2015)</a>对流行的变种做了一个比较，发现它们基本相同。<a href="http://jmlr.org/proceedings/papers/v37/jozefowicz15.pdf" target="_blank" rel="external">Jozefowicz, et al. (2015)</a>测试了一万多种RNN结构，发现其中的一些在特定的任务上效果比LSTM要好。</p><h2 id="结论">结论</h2><p>前文中，我提到了人们使用RNN所取得的出色的成就。本质上，几乎所有的成就都是由LSTM取得的。对于大部分的任务，LSTM表现得非常好。</p><p>由于LSTM写在纸上是一堆公式，因此看起来很吓人。希望本文的分步讲解能让读者更容易接受和理解。</p><p>LSTM使得我们在使用RNN能完成的任务上迈进了一大步。很自然，我们会思考，还会有下一个一大步吗？研究工作者们的共同观点是：“是的！还有一个下一步，那就是注意力(Attention)！”注意力机制的思想是，在每一步中，都让RNN从一个更大的信息集合中去选择信息。举个例子，假如你使用RNN来生成一幅图片的说明文字，RNN可能在输出每一个单词时，都会去观察图片的一部分。事实上，<a href="http://arxiv.org/pdf/1502.03044v2.pdf" target="_blank" rel="external">Xu, et al.(2015)</a>做的正是这个工作！如果你想探索注意力机制的话，这会是一个很有趣的起始点。现在已经有很多使用注意力的令人兴奋的成果，而且似乎更多的成果马上将会出来……</p><p>注意力并不是RNN研究中唯一让人兴奋的主题。举例说，由<a href="http://arxiv.org/pdf/1507.01526v1.pdf" target="_blank" rel="external">Kalchbrenner, et al. (2015)</a>提出的Grid LSTM似乎极有前途。在生成式模型中使用RNN的工作——比如<a href="http://arxiv.org/pdf/1502.04623.pdf" target="_blank" rel="external">Gregor, et al. (2015)</a>、<a href="http://arxiv.org/pdf/1506.02216v3.pdf" target="_blank" rel="external">Chung, et al. (2015)</a>以及<a href="http://arxiv.org/pdf/1411.7610v3.pdf" target="_blank" rel="external">Bayer &amp; Osendorfer (2015)</a>——看起来也非常有意思。最近的几年对于RNN来说是一段非常令人激动的时间，接下来的几年也必将更加使人振奋！</p><hr><p>本文结束，感谢欣赏。</p><h4 id="注：本文翻译自colah’s_blog，原文链接：http://colah-github-io/posts/2015-08-Understanding-LSTMs/。译文原作者：Naitong_Yu，译文链接：https://yunaitong-cn/understanding-lstm-networks-html">注：本文翻译自<a href="http://colah.github.io/" target="_blank" rel="external">colah’s blog</a>，原文链接：<a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="external">http://colah.github.io/posts/2015-08-Understanding-LSTMs/</a>。译文原作者：Naitong Yu，译文链接：<a href="https://yunaitong.cn/understanding-lstm-networks.html" target="_blank" rel="external">https://yunaitong.cn/understanding-lstm-networks.html</a></h4><hr><p><strong>文章写得不错？打赏一个呗:)</strong></p><p><img src="http://i.imgur.com/tTBAnzw.png" alt=""></p><p><strong>【打赏1.99￥以上，备注你的邮箱，可获得博主精心为你准备的深度学习/机器学习/自然语言处理的学习资料大礼包】</strong></p><p><strong>近期博主准备筹建NLP方面的技术群，欢迎感兴趣的小伙伴加我入群交流:)，加好友请备注：”博客”。</strong></p><p><img src="https://i.imgur.com/pBtBjMe.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;循环神经网络(RNN)&quot;&gt;循环神经网络(RNN)&lt;/h2&gt;&lt;p&gt;人们的每次思考并不都是从零开始的。比如说你在阅读这篇文章时，你基于对前面的文字的理解来理解你目前阅读到的文字，而不是每读到一个文字时，都抛弃掉前面的思考，从头开始。你的记忆是有持久性的。&lt;/p&gt;
&lt;p&gt;传统的神经网络并不能如此，这似乎是一个主要的缺点。例如，假设你在看一场电影，你想对电影里的每一个场景进行分类。传统的神经网络不能够基于前面的已分类场景来推断接下来的场景分类。&lt;/p&gt;
&lt;p&gt;循环神经网络(Recurrent Neural Networks)解决了这个问题。这种神经网络带有环，可以将信息持久化。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xqwhn.com1.z0.glb.clouddn.com/2016-10-19-14585451475265.jpg&quot; alt=&quot;Recurrent Neural Networks have loops. -c100&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Machine Learning" scheme="http://www.jeyzhang.com/categories/Machine-Learning/"/>
    
    
      <category term="Deep Learning" scheme="http://www.jeyzhang.com/tags/Deep-Learning/"/>
    
      <category term="LSTM" scheme="http://www.jeyzhang.com/tags/LSTM/"/>
    
      <category term="Machine Learning" scheme="http://www.jeyzhang.com/tags/Machine-Learning/"/>
    
      <category term="RNN" scheme="http://www.jeyzhang.com/tags/RNN/"/>
    
  </entry>
  
  <entry>
    <title>各种系统下Shadowsocks客户端的安装与配置</title>
    <link href="http://www.jeyzhang.com/how-to-install-and-setup-shadowsocks-client-in-different-os.html"/>
    <id>http://www.jeyzhang.com/how-to-install-and-setup-shadowsocks-client-in-different-os.html</id>
    <published>2016-10-08T03:44:57.000Z</published>
    <updated>2017-12-09T07:13:27.953Z</updated>
    
    <content type="html"><![CDATA[<p>下面介绍如何在 Windows / Mac / Linux(Ubuntu) / iOS / Android 系统下对Shadowsocks的客户端（下面简称SS）的安装和配置，以便于使用相应的VPN服务。在此之前假设你已经知道了SS服务器的端口和密码，如果不知道的话，可以向VPN的提供者（管理员）索要。这里假设你端口号和密码已经获取得到，<strong>请结合自己所使用的系统环境找到对应的安装配置方法，在需要输入端口号和密码的地方输入即可</strong>。（<strong>注意：最新的版本的加密算法已经从rc4-md5改成chacha20-ietf-poly1305了</strong>。）</p><hr><h2 id="Windows下SS客户端的安装与配置">Windows下SS客户端的安装与配置</h2><p>适用于Windows 7及以上的系统。</p><h3 id="第一步：下载SS客户端">第一步：下载SS客户端</h3><ul><li>下载方式：百度云</li><li>下载链接：<a href="http://pan.baidu.com/s/1eSOSAJ4" target="_blank" rel="external">点击此处</a></li><li>密码：320a</li></ul><p>下载解压（解压密码：jeyzhang）后，你会看到一个Shadowsocks.exe的文件。</p><h3 id="第二步：配置客户端">第二步：配置客户端</h3><p>运行exe文件，你会看到如下窗口；请按照图片中的内容进行配置：</p><p><img src="http://i.imgur.com/GeA3Wtj.png" alt=""></p><p><strong>输入端口号和密码，点击OK，右键右下角的运行图标：勾选[启动系统代理]</strong>，之后你应该就可以正常访问外网了。</p><h2 id="MAC系统下的VPN配置方法">MAC系统下的VPN配置方法</h2><h3 id="第一步：下载SS客户端-1">第一步：下载SS客户端</h3><ul><li>下载方式：百度云</li><li>下载链接：<a href="http://pan.baidu.com/s/1pKOZWqZ" target="_blank" rel="external">点击此处</a></li><li>密码：5zx9</li></ul><p>解压缩（解压密码：jeyzhang）后，你会看到一个Shadowsocks-2.6.3.dmg文件。双击打开，并按照提示将ShadowsocksX拖拽至Applications文件夹完成安装。</p><h3 id="第二步：运行客户端">第二步：运行客户端</h3><p>运行ShadowsocksX后，会提示输入密码进行安装，如下图所示，请输入帐号密码并继续。</p><p><img src="http://i.imgur.com/ucFPvck.png" alt=""></p><p>点击左下角+号添加服务器，你会看到如下窗口；请按照图片中的内容进行配置：</p><p><img src="http://i.imgur.com/XqsJwhg.png" alt=""></p><p><strong>输入给你的端口号和密码，点击OK即可</strong>。此时你应该就能够访问国外网络了。</p><h2 id="Linux_(Ubuntu_14-04)下Shadowsocks的配置方法">Linux (Ubuntu 14.04)下Shadowsocks的配置方法</h2><p>下面介绍如何在Ubuntu 14.04 下通过配置Shadowsocks和浏览器来使用VPN服务，主要分两步：</p><ul><li><p>配置Shadowsocks命令行程序；</p></li><li><p>配置浏览器（Firefox或Chrome）；</p></li></ul><h3 id="第一步：配置Shadowsocks命令行程序">第一步：配置Shadowsocks命令行程序</h3><p>打开终端，输入：</p><pre><code>sudo apt-<span class="built_in">get</span> <span class="keyword">update</span>sudo apt-<span class="built_in">get</span> install <span class="keyword">python</span>-pipsudo apt-<span class="built_in">get</span> install <span class="keyword">python</span>-setuptools m2crypto</code></pre><p>安装Shadowsocks，输入：</p><pre><code>sudo pip <span class="keyword">install</span> shadowsocks</code></pre><p>启动Shadowsocks</p><pre><code>sslocal <span class="operator">-s</span> 服务器域名或IP -p 服务器端口号 -k “密码” <span class="operator">-l</span> <span class="number">1080</span> -t <span class="number">600</span> -m rc4-md5 </code></pre><p><strong>注意</strong>：密码格式为”<em>*</em>”，包含双引号。</p><p>正常情况下应显示如下：</p><p><img src="http://i.imgur.com/max1GHE.png" alt=""></p><p>（注意图中的命令按照实际情况输入。）</p><h3 id="第二步：配置浏览器">第二步：配置浏览器</h3><p>这里仅以Firefox和Chrome为例，其他浏览器可自行搜索，配置方式相似。</p><p><strong>1. Firefox浏览器</strong></p><ul><li><strong>添加并安装插件</strong></li></ul><p><img src="http://i.imgur.com/OKZb5Yn.png" alt=""></p><p>搜索”foxyproxy”，</p><p><img src="http://i.imgur.com/OFHOu1B.png" alt=""></p><ul><li><strong>重启浏览器后，配置foxyproxy</strong></li></ul><p><img src="http://i.imgur.com/7pLHF56.png" alt=""></p><p>新建代理服务器：</p><p><img src="http://i.imgur.com/qs6AAt5.png" alt=""></p><p>起一个代理名称：</p><p><img src="http://i.imgur.com/SwYltYZ.png" alt=""></p><p>配置代理服务器：</p><p><img src="http://i.imgur.com/kPTi4N8.png" alt=""></p><p>添加“模式订阅”：</p><p><img src="http://i.imgur.com/vKCjHNL.png" alt=""></p><p>建议把下面<strong>两个模式文件</strong>都订阅一下：</p><ul><li><a href="http://firefoxfan.org/gfwlist/gfwlist.txt" target="_blank" rel="external">http://firefoxfan.org/gfwlist/gfwlist.txt</a></li><li><a href="http://sslite.top/gfwlist/gfwlist.txt" target="_blank" rel="external">http://sslite.top/gfwlist/gfwlist.txt</a></li></ul><p><img src="http://i.imgur.com/WIci2co.png" alt=""></p><p>显示模式订阅导入成功：</p><p><img src="http://i.imgur.com/ALzZFoI.png" alt=""></p><p>之后重启浏览器，点击浏览器上的应用图标，选择“使用预定义模板的代理服器”：</p><p><img src="http://i.imgur.com/PD0pfo6.png" alt=""></p><p>此时你应该可以使用firefox浏览器浏览国外网站了。</p><p><strong>2. Chrome浏览器</strong></p><ul><li><strong>安装SwitchySharp插件</strong>、</li></ul><p>在Chrome的插件商店里搜索”SwitchSharp”并安装：</p><p><img src="http://i.imgur.com/h6S0Jyl.png" alt=""></p><p>安装完之后，重启浏览器，浏览器右上角会出现应用的图标：</p><p><img src="http://i.imgur.com/2Fv7xcL.png" alt=""></p><p>然后点击”Options”，按照如下进行配置：</p><p><img src="http://i.imgur.com/RbYWilM.png" alt=""></p><p>配置完成后，重启浏览器，点击应用图标，选择刚才配置的”SS”即可。之后你应该就可以正常访问国外网站啦。</p><h2 id="iOS系统下的Shadowsocks配置">iOS系统下的Shadowsocks配置</h2><p>适用于iPhone和iPad。</p><p>首先打开AppStore应用商店，搜索<strong>Wingy</strong>应用（目前是免费应用），下载并安装。（该方法已经不适用，最新方法需要下载Potatso lite或者Potatso 2。）</p><h3 id="第一步：添加线路">第一步：添加线路</h3><p>打开应用后，首页显示如下，<strong>点击[选择线路（添加线路）]</strong>：</p><p><img src="http://i.imgur.com/itFnELi.png" alt=""></p><p><img src="http://i.imgur.com/GUmwU9Z.png" alt=""></p><h3 id="第二步：配置">第二步：配置</h3><p>按照如下的<strong>红框要求</strong>，填写配置信息（你的端口号和密码），最后保存退出。</p><p><img src="http://i.imgur.com/uVxRQyn.png" alt=""></p><p>回到首页后，点击中间大大的 [开启按钮] 即可打开VPN（注意：弹出的系统框<strong>选择Allow</strong>）。</p><p>之后你就可以自由地上网啦~</p><p><img src="http://i.imgur.com/YX4Ndke.png" alt=""></p><h2 id="Android系统下的Shadowsocks配置">Android系统下的Shadowsocks配置</h2><p>下面介绍如何在Android系统下进行Shadowsocks的配置，以使用VPN服务。注意，你的安卓手机最好先root，root的教程就不再赘述了，网上搜索下载个root的软件即可。本教程使用的安卓手机为乐视1s手机，其他安卓系统的手机操作方式类似。</p><h3 id="第一步：下载SS客户端-2">第一步：下载SS客户端</h3><ul><li>下载方式：百度云</li><li>下载链接：<a href="http://pan.baidu.com/s/1bp7jA5D" target="_blank" rel="external">点击此处</a></li><li>密码：i7lr</li></ul><h3 id="第二步：导入apk文件至手机">第二步：导入apk文件至手机</h3><p>（1）手机连接PC后，选择如下的模式进行文件的导入：</p><p><img src="http://i.imgur.com/A2TKNMI.jpg" alt=""></p><p>（2）打开手机中的”文件管理器”，点击相应的apk文件进行安装即可。</p><h3 id="第三步：打开Shadowsocks客户端，进行相应的配置">第三步：打开Shadowsocks客户端，进行相应的配置</h3><p>（1）填入相应的配置信息：</p><p><img src="http://i.imgur.com/GUZO2f4.jpg" alt=""></p><p>注意，服务器的端口和密码按照实际情况填入。</p><p>还可以通过“分应用代理”来选择什么应用使用代理服务（示例：这里只在使用Chrome的时候使用代理服务）：</p><p><img src="http://i.imgur.com/ejXEesK.jpg" alt=""></p><p>点击右上角的“开启键”，并保持Shadowsocks客户端在后台的运行。之后你就可以正常访问国外网站啦。</p><p><img src="http://i.imgur.com/Ke40JYP.jpg" alt=""></p><p>使用Chrome浏览器访问，</p><p><img src="http://i.imgur.com/rFlvuX5.jpg" alt=""></p><hr><p>本文结束，感谢欣赏。</p><p><strong>欢迎转载，请注明本文的链接地址：</strong></p><p><a href="http://www.jeyzhang.com/how-to-install-and-setup-shadowsocks-client-in-different-os.html">http://www.jeyzhang.com/how-to-install-and-setup-shadowsocks-client-in-different-os.html</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;下面介绍如何在 Windows / Mac / Linux(Ubuntu) / iOS / Android 系统下对Shadowsocks的客户端（下面简称SS）的安装和配置，以便于使用相应的VPN服务。在此之前假设你已经知道了SS服务器的端口和密码，如果不知道的话，可以向
      
    
    </summary>
    
      <category term="Network" scheme="http://www.jeyzhang.com/categories/Network/"/>
    
    
      <category term="Android" scheme="http://www.jeyzhang.com/tags/Android/"/>
    
      <category term="Linux" scheme="http://www.jeyzhang.com/tags/Linux/"/>
    
      <category term="Mac" scheme="http://www.jeyzhang.com/tags/Mac/"/>
    
      <category term="Shadowsocks" scheme="http://www.jeyzhang.com/tags/Shadowsocks/"/>
    
      <category term="VPN" scheme="http://www.jeyzhang.com/tags/VPN/"/>
    
      <category term="Windows" scheme="http://www.jeyzhang.com/tags/Windows/"/>
    
      <category term="iOS" scheme="http://www.jeyzhang.com/tags/iOS/"/>
    
  </entry>
  
  <entry>
    <title>C#学习笔记2：多线程</title>
    <link href="http://www.jeyzhang.com/csharp-learning-notes-2-multithreading.html"/>
    <id>http://www.jeyzhang.com/csharp-learning-notes-2-multithreading.html</id>
    <published>2016-08-28T02:18:53.000Z</published>
    <updated>2017-02-07T08:50:08.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="理解进程与线程">理解进程与线程</h2><p>进程 (Process) 是Windows系统中的一个基本概念，它包含着一个运行程序所需要的资源。进程之间是相对独立的，一个进程无法访问另一个进程的数据（除非利用分布式计算方式），一个进程运行的失败也不会影响其他进程的运行，Windows系统就是利用进程把工作划分为多个独立的区域的。进程可以理解为一个程序的基本边界。</p><p>应用程序域 (AppDomain) 是一个程序运行的逻辑区域，它可以视为一个轻量级的进程，.NET的程序集正是在应用程序域中运行的，一个进程可以包含有多个应用程序域，一个应用程序域也可以包含多个程序集。在一个应用程序域中包含了一个或多个上下文context，使用上下文CLR就能够把某些特殊对象的状态放置在不同容器当中。</p><p>线程 (Thread) 是进程中的基本执行单元，在进程入口执行的第一个线程被视为这个进程的主线程。在.NET应用程序中，都是以Main方法作为入口的，当调用此方法时系统就会自动创建一个主线程。线程主要是由CPU寄存器、调用栈和线程本地存储器 (Thread Local Storage，TLS) 组成的。CPU寄存器主要记录当前所执行线程的状态，调用栈主要用于维护线程所调用到的内存与数据，TLS主要用于存放线程的状态信息。</p><p>一个进程内可以包括多个应用程序域，也有包括多个线程，线程也可以穿梭于多个应用程序域当中。但在同一个时刻，线程只会处于一个应用程序域内。</p><h2 id="线程的生命周期">线程的生命周期</h2><p>线程生命周期开始于 <strong>System.Threading.Thread</strong> 类的对象被创建时，结束于线程被终止或完成执行时。</p><p>下面列出了线程生命周期中的各种状态：</p><ul><li><p><strong>未启动状态</strong>：当线程实例被创建但 Start 方法未被调用时的状况。</p></li><li><p><strong>就绪状态</strong>：当线程准备好运行并等待 CPU 周期时的状况。</p></li><li><p><strong>不可运行状态</strong>：下面的几种情况下线程是不可运行的：</p><ul><li>已经调用 Sleep 方法</li><li>已经调用 Wait 方法</li><li>通过 I/O 操作阻塞</li></ul></li><li><p><strong>死亡状态</strong>：当线程已完成执行或已中止时的状况。</p></li></ul><h2 id="线程的操作">线程的操作</h2><h3 id="System-Threading-Thread类">System.Threading.Thread类</h3><p>System.Threading.Thread 是用于控制线程的基础类，通过Thread可以控制当前应用程序域中线程的创建、挂起、停止、销毁。</p><h4 id="属性">属性</h4><p><img src="http://i.imgur.com/HxlKoyz.png" alt=""></p><ul><li>ManagedThreadId 是确认线程的唯一标识符，程序在大部分情况下都是通过 <strong>Thread.ManagedThreadId</strong> 来辨别线程的。而 Name 是一个可变值，在默认时候，Name 为一个空值 Null，开发人员可以通过程序设置线程的名称，但这只是一个辅助功能。</li><li>.NET 为线程设置了 <strong>Priority</strong> 属性来定义线程执行的优先级别，里面包含5个选项（Lowest, BelowNormal, Normal, AboveNormal, Highest），其中 Normal 是默认值。<strong>除非系统有特殊要求，否则不应该随便设置线程的优先级别</strong>。</li><li>通过 <strong>ThreadState</strong> 可以检测线程是处于 Unstarted、Sleeping、Running 等等状态，它比 IsAlive 属性能提供更多的特定信息。</li><li>一个应用程序域中可能包括多个上下文，而通过 CurrentContext 可以获取线程当前的上下文。</li><li>CurrentThread 是最常用的一个属性，它是用于获取当前运行的线程。</li></ul><h4 id="方法">方法</h4><p><img src="http://i.imgur.com/TyjtHe2.png" alt=""></p><h4 id="程序示例">程序示例</h4><p>通过Thread显示当前线程信息：</p><pre><code><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">Main</span><span class="params">(<span class="built_in">string</span>[] args)</span>    </span>{        Thread thread = Thread.CurrentThread;        thread.Name = <span class="string">"Main Thread"</span>;        <span class="built_in">string</span> threadMessage = <span class="built_in">string</span>.Format(<span class="string">"Thread ID:{0}\n    Current AppDomainId:{1}\n    "</span>+            <span class="string">"Current ContextId:{2}\n    Thread Name:{3}\n    "</span>+            <span class="string">"Thread State:{4}\n    Thread Priority:{5}\n"</span>,            thread.ManagedThreadId, Thread.GetDomainID(), Thread.CurrentContext.ContextID,            thread.Name, thread.ThreadState, thread.Priority);        Console.WriteLine(threadMessage);        Console.ReadKey();    }</code></pre><p>结果如下：</p><p><img src="http://i.imgur.com/NGRlCRH.png" alt=""></p><h3 id="实现多线程">实现多线程</h3><h4 id="无参数传入：使用ThreadStart委托">无参数传入：使用ThreadStart委托</h4><p>示例如下，首先在 Message 类中建立一个方法 ShowMessage()，里面显示了当前运行线程的 Id，并使用 Thread.Sleep(int) 方法模拟部分工作。在 main() 中通过 ThreadStart委托 绑定Message对象的 ShowMessage()方法，然后通过 Thread.Start() 执行异步方法。</p><pre><code><span class="keyword">public</span> <span class="keyword">class</span> Message  {      <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">ShowMessage</span><span class="params">()</span>      </span>{          <span class="built_in">string</span> message = <span class="built_in">string</span>.Format(<span class="string">"Async threadId is :{0}"</span>,                                          Thread.CurrentThread.ManagedThreadId);          Console.WriteLine(message);          <span class="keyword">for</span> (<span class="keyword">int</span> n = <span class="number">0</span>; n &lt; <span class="number">10</span>; n++)          {              Thread.Sleep(<span class="number">300</span>);                 Console.WriteLine(<span class="string">"The number is:"</span> + n.ToString());           }      }  }  <span class="keyword">class</span> Program  {      <span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">Main</span><span class="params">(<span class="built_in">string</span>[] args)</span>      </span>{          Console.WriteLine(<span class="string">"Main threadId is:"</span>+                            Thread.CurrentThread.ManagedThreadId);          Message message=<span class="keyword">new</span> Message();          Thread thread = <span class="keyword">new</span> Thread(<span class="keyword">new</span> ThreadStart(message.ShowMessage));          thread.Start();          Console.WriteLine(<span class="string">"Do something ..........!"</span>);          Console.WriteLine(<span class="string">"Main thread working is complete!"</span>);      }  }</code></pre><p>在调用 Thread.Start()方法 后，系统以异步方式运行 Message.ShowMessage()，而主线程的操作是继续执行的，在 Message.ShowMessage() 完成前，主线程已完成所有的操作。结果如下：</p><p><img src="http://i.imgur.com/7vb7sR3.png" alt=""></p><h4 id="参数传入：三种方式">参数传入：三种方式</h4><p>使用 ThreadStart委托 的缺点在于无法给线程传递参数，下面介绍三种方式以实现给线程传递参数：</p><ul><li><strong>使用ParameterizedThreadStart委托</strong></li></ul><p>如果使用了ParameterizedThreadStart委托，线程的入口必须有一个object类型的参数，且返回类型为void。如下面的例子：</p><pre><code><span class="keyword">class</span> <span class="title">Program</span>{    <span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">Main</span>(<span class="params"><span class="keyword">string</span>[] args</span>)    </span>{        <span class="keyword">string</span> hello = <span class="string">"hello world"</span>;        <span class="comment">//这里也可简写成Thread thread = new Thread(ThreadMainWithParameters);</span>        <span class="comment">//但是为了让大家知道这里用的是ParameterizedThreadStart委托，就没有简写了</span>        Thread thread = <span class="keyword">new</span> Thread(<span class="keyword">new</span> ParameterizedThreadStart(ThreadMainWithParameters));        thread.Start(hello);        Console.Read();    }    <span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">ThreadMainWithParameters</span>(<span class="params"><span class="keyword">object</span> obj</span>)    </span>{        <span class="keyword">string</span> str = obj <span class="keyword">as</span> <span class="keyword">string</span>;        <span class="keyword">if</span>(!<span class="keyword">string</span>.IsNullOrEmpty(str))            Console.WriteLine(<span class="string">"Running in a thread,received: {0}"</span>, str);    }}</code></pre><p>这里稍微有点麻烦的就是 <strong>ThreadMainWithParameters方法 里的参数必须是 object类型 的</strong>，我们需要进行类型转换。为什么参数必须是object类型呢？看看ParameterizedThreadStart委托的声明就知道了。</p><pre><code><span class="function"><span class="keyword">public</span> <span class="keyword">delegate</span> <span class="keyword">void</span> <span class="title">ParameterizedThreadStart</span>(<span class="params"><span class="keyword">object</span> obj</span>)</span>;   <span class="comment">//ParameterizedThreadStart委托的声明</span></code></pre><ul><li><strong>创建自定义类</strong></li></ul><p>定义一个类，在其中定义需要的字段，将线程的主方法定义为类的一个实例方法。如下面的例子：</p><pre><code><span class="keyword">public</span> <span class="keyword">class</span> <span class="title">MyThread</span>{    <span class="keyword">private</span> <span class="keyword">string</span> data;    <span class="function"><span class="keyword">public</span> <span class="title">MyThread</span>(<span class="params"><span class="keyword">string</span> data</span>)    </span>{        <span class="keyword">this</span>.data = data;    }    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">ThreadMain</span>(<span class="params"></span>)    </span>{        Console.WriteLine(<span class="string">"Running in a thread,data: {0}"</span>, data);    }}<span class="keyword">class</span> <span class="title">Program</span>{    <span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">Main</span>(<span class="params"><span class="keyword">string</span>[] args</span>)    </span>{        MyThread myThread = <span class="keyword">new</span> MyThread(<span class="string">"hello world"</span>);        Thread thread = <span class="keyword">new</span> Thread(myThread.ThreadMain);        thread.Start();        Console.Read();    }}    </code></pre><ul><li><strong>使用匿名方法</strong></li></ul><p>示例如下：</p><pre><code><span class="keyword">class</span> <span class="title">Program</span>{    <span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">Main</span>(<span class="params"><span class="keyword">string</span>[] args</span>)    </span>{        <span class="keyword">string</span> hello = <span class="string">"hello world"</span>;        <span class="comment">//如果写成Thread thread = new Thread(ThreadMainWithParameters(hello));这种形式，编译时就会报错</span>        Thread thread = <span class="keyword">new</span> Thread(() =&gt; ThreadMainWithParameters(hello));        thread.Start();        Console.Read();    }    <span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">ThreadMainWithParameters</span>(<span class="params"><span class="keyword">string</span> str</span>)    </span>{         Console.WriteLine(<span class="string">"Running in a thread,received: {0}"</span>, str);    }</code></pre><p>通过反编译体现了第三种方法其实和第二种方法其实是一样的。</p><h3 id="关于async_action的问题">关于async action的问题</h3><p><strong>特别需要注意 new Task(async () =&gt; await FuncAsync()) 这种类似的写法</strong>，这种写法后面是不能await到函数执行结束的结果的。</p><p>见下面的例子：</p><pre><code><span class="keyword">class</span> <span class="title">TestTask</span>{    <span class="function"><span class="keyword">private</span> <span class="keyword">async</span> <span class="keyword">static</span> Task <span class="title">TestAsync</span>(<span class="params"><span class="keyword">int</span> opt</span>)    </span>{        <span class="keyword">await</span> Task.Delay(<span class="number">1000</span>);        Console.WriteLine(<span class="string">"opt {0}: finish async task."</span>, opt);    }    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">TestSync</span>(<span class="params"><span class="keyword">int</span> opt</span>)    </span>{        Thread.Sleep(<span class="number">1000</span>);        Console.WriteLine(<span class="string">"opt {0}: finish sync."</span>, opt);    }    <span class="function"><span class="keyword">private</span> <span class="keyword">async</span> <span class="keyword">static</span> Task <span class="title">StartAsync</span>(<span class="params"></span>)    </span>{        List&lt;Task&gt; tasks = <span class="keyword">new</span> List&lt;Task&gt;();        tasks.Add(<span class="keyword">new</span> Task(() =&gt; TestSync(<span class="number">1</span>)));        tasks.Add(<span class="keyword">new</span> Task(<span class="keyword">async</span> () =&gt; <span class="keyword">await</span> TestAsync(<span class="number">2</span>))); <span class="comment">// 这条语句存在问题，不能await到函数执行的结果</span>        <span class="keyword">foreach</span> (<span class="keyword">var</span> task <span class="keyword">in</span> tasks)        {            task.Start();        }        <span class="comment">// 以下t1, t2, t3均不需要task.Start()方法</span>        <span class="comment">//var t1 = new Task&lt;Task&gt;(async () =&gt; await TestAsync(2));</span>        <span class="comment">//t1.Start();</span>        <span class="comment">//tasks.Add(t1.Unwrap());</span>        <span class="comment">//var t2 = Task.Factory.StartNew(async()=&gt;await TestAsync(2));</span>        <span class="comment">//tasks.Add(t2.Unwrap());</span>        <span class="comment">//var t3 = Task.Run(async () =&gt; await TestAsync(2));</span>        <span class="comment">//tasks.Add(t3); </span>        Task.WaitAll(tasks.ToArray());        Console.WriteLine(<span class="string">"finish start."</span>);    }    <span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">Main</span>(<span class="params"></span>)    </span>{        StartAsync().GetAwaiter().GetResult();    }}</code></pre><p>执行结果为如下：</p><p><img src="http://i.imgur.com/bAK9YYd.png" alt=""></p><p><strong>可以看出没有等到 TestAsync(2) 的返回结果。</strong></p><p>应该将上述存在问题的语句改为如下中的任意一种即可：</p><pre><code><span class="comment">// 以下t1, t2, t3均不需要task.Start()方法</span><span class="keyword">var</span> t1 = <span class="keyword">new</span> Task&lt;Task&gt;(<span class="keyword">async</span> () =&gt; <span class="keyword">await</span> TestAsync(<span class="number">2</span>));t1.Start();tasks.Add(t1.Unwrap());<span class="keyword">var</span> t2 = Task.Factory.StartNew(<span class="keyword">async</span> () =&gt; <span class="keyword">await</span> TestAsync(<span class="number">2</span>));tasks.Add(t2.Unwrap());<span class="keyword">var</span> t3 = Task.Run(<span class="keyword">async</span> () =&gt; <span class="keyword">await</span> TestAsync(<span class="number">2</span>));tasks.Add(t3); </code></pre><p>此时执行结果为：</p><p><img src="http://i.imgur.com/73LlSIO.png" alt=""></p><hr><p>本文结束，感谢欣赏。</p><p><strong>欢迎转载，请注明本文的链接地址：</strong></p><p><a href="http://www.jeyzhang.com/csharp-learning-notes-2-multithreading.html">http://www.jeyzhang.com/csharp-learning-notes-2-multithreading.html</a></p><p><strong>参考资料</strong></p><p><a href="http://www.cnblogs.com/leslies2/archive/2012/02/07/2310495.html#t3" target="_blank" rel="external">C#综合揭秘——细说多线程</a></p><p><a href="http://www.runoob.com/csharp/csharp-multithreading.html" target="_blank" rel="external">C#多线程 | 菜鸟教程</a></p><p><a href="http://www.cnblogs.com/lexiaoyao/archive/2011/12/01/2271120.html" target="_blank" rel="external">C# 给多线程传参的三种方式</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;理解进程与线程&quot;&gt;理解进程与线程&lt;/h2&gt;&lt;p&gt;进程 (Process) 是Windows系统中的一个基本概念，它包含着一个运行程序所需要的资源。进程之间是相对独立的，一个进程无法访问另一个进程的数据（除非利用分布式计算方式），一个进程运行的失败也不会影响其他进程
      
    
    </summary>
    
      <category term="C#" scheme="http://www.jeyzhang.com/categories/C/"/>
    
    
      <category term="C#" scheme="http://www.jeyzhang.com/tags/C/"/>
    
      <category term="Multithreading" scheme="http://www.jeyzhang.com/tags/Multithreading/"/>
    
  </entry>
  
  <entry>
    <title>聊天机器人中的深度学习技术之一：导读</title>
    <link href="http://www.jeyzhang.com/deep-learning-for-chatbots-1.html"/>
    <id>http://www.jeyzhang.com/deep-learning-for-chatbots-1.html</id>
    <published>2016-08-08T11:43:58.000Z</published>
    <updated>2018-02-19T13:44:40.000Z</updated>
    
    <content type="html"><![CDATA[<p>以下内容为原文 <a href="http://www.wildml.com/2016/04/deep-learning-for-chatbots-part-1-introduction/" target="_blank" rel="external">《Deep Learning For Chatbots, Part 1 - Introduction》</a> 的翻译，供自己学习及他人参考。</p><p>这篇博文主要概述了目前聊天机器人主要用到的技术，从宏观上进行介绍，不涉及具体的技术细节。<a href="http://www.jeyzhang.com/deep-learning-for-chatbots-2.html">下一篇博文：聊天机器人中的深度学习技术之二：基于检索模型的实现</a>会介绍并实现一个基于检索的LSTM模型，通过这个模型可以实现聊天机器人。</p><hr><p>聊天机器人 (Chatbot)，也被称为对话引擎或者对话系统，是目前的热点之一。微软公司在聊天机器人上的投入巨大（<a href="http://www.bloomberg.com/features/2016-microsoft-future-ai-chatbots/" target="_blank" rel="external">链接</a>），著名产品有小冰 (xiaoice)、bot framework等，其他公司也纷纷在这个领域发力，如Facebook的M，苹果公司的Siri等等。此外，一大批的创业公司发布了类似的产品，例如客户应用<a href="https://operator.com/" target="_blank" rel="external">Operator</a>，<a href="https://x.ai/" target="_blank" rel="external">x.ai</a>，bot framework <a href="http://chatfuel.com/" target="_blank" rel="external">Chatfuel</a>，bot开发工具 <a href="http://howdy.ai/botkit/" target="_blank" rel="external">Howdy’s Botkit</a>。微软也发布了供开发者使用的 <a href="https://dev.botframework.com/" target="_blank" rel="external">bot developer framework</a>。</p><p>许多公司希望能开发出与用户进行自然语言式对话的机器人，并且声称使用了NLP和深度学习相关技术使之成为可能，然而这并不容易实现。在这个博文系列中，我将会重温一些被用于聊天机器人中的深度学习技术，披露出目前技术能够解决或者可能解决的问题以及几乎难以解决的问题。这篇文章是个概述，在接下来的博文中将介绍具体的技术细节。</p><h2 id="模型分类">模型分类</h2><h3 id="基于检索技术的模型_VS_生成式模型">基于检索技术的模型 VS 生成式模型</h3><p><strong>基于检索技术的模型</strong>较为简单，主要是根据用户的输入和上下文内容，使用了知识库（存储了事先定义好的回复内容）和一些启发式方法来得到一个合适的回复。启发式方法简单的有基于规则的表达式匹配，复杂的有一些机器学习里的分类器。这些系统不能够生成任何新的内容，只是从一个固定的数据集中找到合适的内容作为回复。</p><p><strong>生成式模型</strong>则更加复杂，它不依赖于预定义好的回复内容，而是通过<strong>抓取(Scratch)</strong>的方法生成新的回复内容。生成式模型典型的有<strong>基于机器翻译模型</strong>的，与传统机器翻译模型不同的是，生成式模型的任务不是将一句话翻译成其他语言的一句话，而是将<strong>用户的输入[翻译]为一个回答(response)</strong></p><p><img src="http://i.imgur.com/P03eaBZ.png" alt=""></p><p><strong>总结</strong></p><p>以上两种模型均有优缺点。对于基于检索技术的模型，由于使用了知识库且数据为预先定义好的，因此进行回复的内容语法上较为通顺，较少出现语法错误；但是基于检索技术的模型中没有会话概念，不能结合上下文给出更加[智能]的回复。而生成式模型则更加[智能]一些，它能够更加有效地利用上下文信息从而知道你在讨论的东西是什么；然而生成式模型比较难以训练，并且输出的内容经常存在一些语法错误（尤其对于长句子而言），以及模型训练需要大规模的数据。</p><p>深度学习技术都能够用于基于检索技术的模型和生成式模型中，但是目前的研究热点在生成式模型上。深度学习框架例如<strong>Sequence to Sequence</strong>非常适合用来生成文本，非常多的研究者希望能够在这个领域取得成功。然而目前这一块的研究还在初期阶段，工业界的产品更多的还是使用基于检索计算的模型。</p><h3 id="短对话_VS_长对话">短对话 VS 长对话</h3><p>直观上处理长对话内容将更加困难，这是因为你需要在当前对话的情境下知道之前的对话说过什么。如果是一问一答的形式，技术上这将简单的多。通常对于客服对话而言，长对话更加常见，一次对话中往往会伴随着多个关联问题。</p><h3 id="开放域_VS_特定领域">开放域 VS 特定领域</h3><p>面向开放域的聊天机器人技术面临更多困难，这是因为会话可能涉及的面太广，没有一个清晰的目标和意图。在一些社交网站例如Twitter和Reddit上的会话是属于开放域的，会话涉及的主题多种多样，需要的知识量也将非常巨大。</p><p>面向特定领域的相关技术则相对简单一些，这是因为特定领域给会话的主题进行了限制，目标和意图也更加清晰，典型的例子有客服系统助手和购物助手。这些系统通常是为了完成某些特定任务，尽管用户在该系统中也能够问些其他方面的东西，但是系统并不会给出相应的回复。</p><h2 id="面临的挑战">面临的挑战</h2><p>下面介绍一下聊天机器人技术所面临的挑战。</p><h3 id="如何结合上下文信息">如何结合上下文信息</h3><p>为了产生质量更高的回复，聊天机器人系统通常需要利用一些上下文信息(Context)，这里的上下文信息包括了<strong>对话过程中的语言上下文信息</strong>和<strong>用户的身份信息</strong>等。在长对话中人们关注的是之前说了什么内容以及产生了什么内容的交换，这是语言上下文信息的典型。常见的方法是将一个会话转化为向量形式，但这对长会话而言是困难的。论文<a href="http://arxiv.org/abs/1507.04808" target="_blank" rel="external">Building End-To-End Dialogue Systems Using Generative Hierarchical Neural Network Models</a>和<a href="http://arxiv.org/abs/1510.08565" target="_blank" rel="external">Attention with Intention for a Neural Network Conversation Model</a>中的实验结果表明了这一点。另外，可以结合的上下文信息还包括会话进行时的日期地点信息、用户信息等。</p><h3 id="语义一致性">语义一致性</h3><p>理论上来说，机器人面对相同语义而不同形式的问题应该给予一致的回复，例如这两个问题[How old are you?]和[What’s your age?]。这理解起来是简单的，但却是学术界目前的难题之一（如下图）。许多系统都试图对相同语义而不同形式的问题给予语义上合理的回复，但却没有考虑一致性，最大的原因在于训练模型的数据来源于大量不同的用户，这导致机器人失去了固定统一的人格。论文<a href="http://arxiv.org/abs/1603.06155" target="_blank" rel="external">A Persona-Based Neural Conversation Model</a>中提及的模型旨在创建具有固定统一人格的机器人。</p><p><img src="http://i.imgur.com/JGrn8LK.png" alt=""></p><h3 id="对话模型的评测">对话模型的评测</h3><p>评价一个对话模型的好坏在于它是否很好地完成了某项任务，例如在对话中解决了客户的问题。这样的训练数据需要人工标注和评测，所以获取上需要一定人力代价。有时在开放域中的对话系统也没有一个清晰的优化目标。用于机器翻译的评测指标<a href="https://en.wikipedia.org/wiki/BLEU" target="_blank" rel="external">BLEU</a>不能适用于此，是因为它的计算基础是语言表面上的匹配程度，而对话中的回答可以是完全不同词型但语义通顺的语句。论文<a href="http://arxiv.org/abs/1603.08023" target="_blank" rel="external">How NOT To Evaluate Your Dialogue System: An Empirical Study of Unsupervised Evaluation Metrics for Dialogue Response Generation</a>中给出结论，目前常用的评测指标均与人工评测无关。</p><h3 id="意图和回复多样性">意图和回复多样性</h3><p>生成式模型中的一个普遍问题是，它们都想要生成一些通用的回答，例如[That’s great!]和[I don’t know]这样的可以应付许多的用户询问。早期的Google智能回复基本上以[I love you]回复所有的东西<a href="http://googleresearch.blogspot.com/2015/11/computer-respond-to-this-email.html" target="_blank" rel="external">链接</a>，这是一些模型最终训练出来的结果，原因在于训练数据和训练的优化目标。因此，有些研究学者开始关注<a href="http://arxiv.org/abs/1510.03055" target="_blank" rel="external">如何提升机器人的回复的多样性</a>，然而人们在对话过程中的回复与询问有一定特定关系，是有一定意图的，而许多面向开放域的机器人不具备特定的意图。</p><h2 id="实际效果">实际效果</h2><p>以目前的研究水平所制造的机器人能够取得的效果如何？使用基于检索技术的显然无法制作出面向开放域的机器人，这是因为你不能编写覆盖所有领域的语料；而生成式的面向开放域的机器人还属于<strong>通用人工智能(Artifical General Intelligence, AGI)</strong>水平，距离理想状态还相距甚远，但相关研究学者还在致力于此。</p><p>对于特定领域的机器人，基于检索的技术和生成式模型都能够利用。但是对于长对话的情境，也面临许多困难。</p><p>在最近对<a href="http://www.seattletimes.com/business/baidu-research-chief-andrew-ng-fixed-on-self-taught-computers-self-driving-cars/" target="_blank" rel="external">Andrew NG的采访</a>中，NG提到：</p><blockquote><p>目前深度学习的价值主要体现在能够获取大量数据的特定领域。目前一个无法做的事情是产生一个有意义的对话。</p></blockquote><p>许多创业公司声称只要有足够多的数据，就能够产生自动智能的对话系统。然而，目前的水平生产出面向一个特定的子领域的对话应用（如利用Uber打车），而对于一个稍微开放点的领域就难以实现了（如自动销售）。但是，帮助用户提供自动回复建议以及语法纠正还是可行的。</p><p>使用基于检索技术的对话系统更加可控和稳定，给出的回复出现语法错误的几率更低。而使用生成式模型的风险在于回复不可控，且容易出现一些风险，例如<a href="http://www.businessinsider.com/microsoft-deletes-racist-genocidal-tweets-from-ai-chatbot-tay-2016-3" target="_blank" rel="external">微软的Tay</a>。</p><h2 id="即将到来的事情和阅读列表">即将到来的事情和阅读列表</h2><p>在之后的博文中将具体介绍深度学习方面的技术细节。提前阅读下面的文章将会对后面的学习更加有帮助。</p><ul><li><a href="http://arxiv.org/abs/1503.02364" target="_blank" rel="external">Neural Responding Machine for Short-Text Conversation (2015-03)</a></li><li><a href="http://arxiv.org/abs/1506.05869" target="_blank" rel="external">A Neural Conversational Model (2015-06)</a></li><li><a href="http://arxiv.org/abs/1506.06714" target="_blank" rel="external">A Neural Network Approach to Context-Sensitive Generation of Conversational Responses (2015-06)</a></li><li><a href="http://arxiv.org/abs/1506.08909" target="_blank" rel="external">The Ubuntu Dialogue Corpus: A Large Dataset for Research in Unstructured Multi-Turn Dialogue Systems (2015-06)</a></li><li><a href="http://arxiv.org/abs/1507.04808" target="_blank" rel="external">Building End-To-End Dialogue Systems Using Generative Hierarchical Neural Network Models (2015-07)</a></li><li><a href="http://arxiv.org/abs/1510.03055" target="_blank" rel="external">A Diversity-Promoting Objective Function for Neural Conversation Models (2015-10)</a></li><li><a href="http://arxiv.org/abs/1510.08565" target="_blank" rel="external">Attention with Intention for a Neural Network Conversation Model (2015-10)</a></li><li><a href="http://arxiv.org/abs/1510.03753" target="_blank" rel="external">Improved Deep Learning Baselines for Ubuntu Corpus Dialogs (2015-10)</a></li><li><a href="http://arxiv.org/abs/1512.05742" target="_blank" rel="external">A Survey of Available Corpora for Building Data-Driven Dialogue Systems (2015-12)</a></li><li><a href="http://arxiv.org/abs/1603.06393" target="_blank" rel="external">Incorporating Copying Mechanism in Sequence-to-Sequence Learning (2016-03)</a></li><li><a href="http://arxiv.org/abs/1603.06155" target="_blank" rel="external">A Persona-Based Neural Conversation Model (2016-03)</a></li><li><a href="http://arxiv.org/abs/1603.08023" target="_blank" rel="external">How NOT To Evaluate Your Dialogue System: An Empirical Study of Unsupervised Evaluation Metrics for Dialogue Response Generation (2016-03)</a></li></ul><hr><p>本文结束，感谢欣赏。</p><p><strong>欢迎转载，请注明本文的链接地址：</strong></p><p><a href="http://www.jeyzhang.com/deep-learning-for-chatbots-1.html">http://www.jeyzhang.com/deep-learning-for-chatbots-1.html</a></p><hr><p><strong>文章写得不错？打赏一个呗:)</strong></p><p><img src="http://i.imgur.com/tTBAnzw.png" alt=""></p><p><strong>【打赏1.99￥以上，备注你的邮箱，可获得博主精心为你准备的深度学习/机器学习/自然语言处理的学习资料大礼包】</strong></p><p><strong>近期博主准备筹建NLP方面的技术群，欢迎感兴趣的小伙伴加我入群交流:)，加好友请备注：”博客”。</strong></p><p><img src="https://i.imgur.com/pBtBjMe.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;以下内容为原文 &lt;a href=&quot;http://www.wildml.com/2016/04/deep-learning-for-chatbots-part-1-introduction/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;《Deep Lear
      
    
    </summary>
    
      <category term="Deep Learning" scheme="http://www.jeyzhang.com/categories/Deep-Learning/"/>
    
    
      <category term="ChatBot" scheme="http://www.jeyzhang.com/tags/ChatBot/"/>
    
      <category term="Deep Learning" scheme="http://www.jeyzhang.com/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>C#学习笔记1：常见问题</title>
    <link href="http://www.jeyzhang.com/csharp-learning-notes-1-qna.html"/>
    <id>http://www.jeyzhang.com/csharp-learning-notes-1-qna.html</id>
    <published>2016-08-01T12:00:26.000Z</published>
    <updated>2016-08-28T01:52:20.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="概念">概念</h2><h3 id="同步、异步、阻塞、非阻塞">同步、异步、阻塞、非阻塞</h3><p>转自<a href="https://www.zhihu.com/question/19732473" target="_blank" rel="external">知乎-严肃的回答</a>：</p><p>“阻塞”与”非阻塞”与”同步”与“异步”不能简单的从字面理解，提供一个从分布式系统角度的回答。</p><ul><li><strong>同步与异步</strong></li></ul><p>同步和异步关注的是<strong>消息通信机制 (synchronous communication/ asynchronous communication)</strong>。<br>所谓同步，就是在发出一个<em>调用</em>时，在没有得到结果之前，该<em>调用</em>就不返回。但是一旦调用返回，就得到返回值了。<br>换句话说，就是由<em>调用者</em>主动等待这个<em>调用</em>的结果。</p><p>而异步则是相反，<em>调用</em>在发出之后，这个调用就直接返回了，所以没有返回结果。换句话说，当一个异步过程调用发出后，调用者不会立刻得到结果。而是在<em>调用</em>发出后，<em>被调用者</em>通过状态、通知来通知调用者，或通过回调函数处理这个调用。</p><p>典型的异步编程模型比如Node.js，举个例子：</p><p>普通B/S模式（同步）AJAX技术（异步）</p><p>同步：提交请求-&gt;等待服务器处理-&gt;处理完毕返回 这个期间客户端浏览器不能干任何事</p><p>异步: 请求通过事件触发-&gt;服务器处理（这是浏览器仍然可以作其他事情）-&gt;处理完毕</p><p>举个通俗的例子：</p><p>你打电话问书店老板有没有《分布式系统》这本书，如果是同步通信机制，书店老板会说，你稍等，”我查一下”，然后开始查啊查，等查好了（可能是5秒，也可能是一天）告诉你结果（返回结果）。<br>而异步通信机制，书店老板直接告诉你我查一下啊，查好了打电话给你，然后直接挂电话了（不返回结果）。然后查好了，他会主动打电话给你。在这里老板通过“回电”这种方式来回调。</p><ul><li><strong>阻塞与非阻塞</strong></li></ul><p>阻塞和非阻塞关注的是<strong>程序在等待调用结果（消息，返回值）时的状态</strong>.</p><p>阻塞调用是指调用结果返回之前，当前线程会被挂起。调用线程只有在得到结果之后才会返回。<br>非阻塞调用指在不能立刻得到结果之前，该调用不会阻塞当前线程。</p><p>还是上面的例子，</p><p>你打电话问书店老板有没有《分布式系统》这本书，你如果是阻塞式调用，你会一直把自己“挂起”，直到得到这本书有没有的结果，如果是非阻塞式调用，你不管老板有没有告诉你，你自己先一边去玩了， 当然你也要偶尔过几分钟check一下老板有没有返回结果。<br>在这里阻塞与非阻塞与是否同步异步无关。跟老板通过什么方式回答你结果无关。</p><h2 id="语法">语法</h2><h3 id="int?_的意思">int? 的意思</h3><p>下面两种声明int变量的方式：</p><pre><code><span class="built_in">int</span> <span class="built_in">num</span><span class="built_in">int</span>? <span class="built_in">num</span></code></pre><p>区别在于，第二种中的num可以为空（或者赋值为null），而第一种只能赋值整数类型值。</p><p>对于其他的基础类型也同样适用。</p><h2 id="关键字">关键字</h2><h3 id="ref与out的区别">ref与out的区别</h3><p>C#中参数传递的方式有两种，分别是值传递和引用传递。<code>ref</code>与<code>out</code>这两种方式都是属于引用传递。唯一的区别在于：</p><ul><li><code>out</code>关键字修饰的参数需要<strong>在调用的函数内部先初始化，再使用</strong>；</li><li><code>ref</code>关键字修饰的参数需要<strong>在调用函数前，先初始化再传入函数</strong>；</li></ul><h3 id="static_readonly与const的区别">static readonly与const的区别</h3><p><code>static readonly</code>与<code>const</code>非常类似，共同点有：(1) 通过类名而不是对象名进行访问；(2) 在程序中只读(不可更改)等。两者的本质区别在于：</p><ul><li><strong>const的值在编译期间就是确定的</strong>，只能在声明时通过常量表达式指定值；</li><li><strong>static readonly是在运行时计算出其值的</strong>，所以还可以通过静态构造函数来赋值。</li></ul><p>下面的例子可以更加清楚地认识<code>static readonly</code>与<code>const</code>的区别：</p><pre><code><span class="number">1.</span> <span class="keyword">static</span> readonly MyClass myins = <span class="keyword">new</span> MyClass();<span class="number">2.</span> <span class="keyword">static</span> readonly MyClass myins = null;<span class="number">3.</span> <span class="keyword">static</span> readonly B = <span class="number">10</span>;   <span class="keyword">static</span> readonly A = B * <span class="number">20</span>;<span class="number">4.</span> <span class="keyword">static</span> readonly <span class="keyword">int</span> [] constIntArray = <span class="keyword">new</span> <span class="keyword">int</span>[] {<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>};<span class="number">5.</span> <span class="function"><span class="keyword">void</span> <span class="title">SomeFunction</span><span class="params">()</span>   </span>{      <span class="keyword">const</span> <span class="keyword">int</span> a = <span class="number">10</span>;      ...   }<span class="number">6.</span><span class="keyword">private</span> <span class="keyword">static</span> <span class="built_in">string</span> astr=<span class="string">"abcd"</span>;  <span class="keyword">private</span> <span class="keyword">const</span> <span class="built_in">string</span> str = astr+<span class="string">"efg"</span>;</code></pre><p>1：不可以 换成const。new操作符是需要执行构造函数的，所以无法在编译期间确定；</p><p>2：可以换成const。我们也看到，Reference类型的常量 （除了String）只能是Null；</p><p>3：可以换成const。我们可以在编译期间很明确的说，A等于200；</p><p>4：不可以换成 const。道理和1是一样的，虽然看起来1,2,3的数组的确就是一个常量；</p><p>5：不可以换成readonly，readonly只能用来修饰类 的field，不能修饰局部变量，也不能修饰property等其他类成员；</p><p>6.错误：如果在astr前加上const或者const改为readonly即可；</p><p><strong>总结如下</strong>：</p><ul><li>const、readonly和static readonly定义的常量，指定初始值后(包括在构造函数内指定的初始值) 将不可更改，可读不可写；</li><li>const定义时必须指定初始值，而readonly定义时可以不进行初始化(MS建议在定义时初始值),同时也可以在构造函数内指定初始值，并以构造函数内指定的值为准；</li><li>const和static readonly定义的常量是静态的，只能由类直接访问；而readonly定义的常量是非静态的，只能由实例对象访问；   </li><li>static readonly常量，如果在构造函数内指定初始值，则必须是静态无参构造函数；</li><li>const是编译时常量，readonly是运行时常量；cosnt较高效，readonly较灵活。在应用上以static readonly代替const，以平衡const在灵活性上的不足，同时克服编译器优化cosnt性能，所带来的程序集引用不一致问题；</li></ul><h3 id="static关键字">static关键字</h3><p>使用<code>static</code>修饰符声明属于类型本身而不是属于特定对象的静态成员。<code>static</code>修饰符可用于类、字段、方法、属性、运算符、事件和构造函数，但不能用于索引器、析构函数或类以外的类型。 </p><ul><li>static修饰的类称为<strong>静态类</strong>，静态类与非静态类的区别在于：<strong>静态类不能够被实例化（不能包含构造函数），仅包含静态成员，访问成员的方式是通过类名</strong>；</li><li>静态成员的初始化工作可以在静态构造函数内部完成（包括static readonly修饰符修饰的成员）；</li></ul><p>与<code>static</code>修饰符相对应的是<code>auto</code>，通常它是默认的（即不用static修饰的都是auto的）。<strong>auto的含义是由程序自动控制变量的生存周期</strong>，通常指的就是变量在进入其作用域的时候被分配，离开其作用域的时候被释放；而static就是不auto，变量在程序初始化时被分配，直到程序退出前才被释放；也就是<strong>static是按照程序的生命周期来分配释放变量的</strong>，而不是变量自己的生命周期。看下面的例子：</p><pre><code>void <span class="function"><span class="keyword">func</span><span class="params">()</span></span>{     <span class="built_in">int</span> a<span class="comment">;</span>     <span class="keyword">static</span> <span class="built_in">int</span> b<span class="comment">;</span>}</code></pre><p>每一次调用上面的func函数，变量a都是新的，因为它是在进入函数体的时候被分配，退出函数体的时候被释放，所以多个线程调用该函数，都会拥有各自独立的变量a，因为它总是要被重新分配的；而变量b不管你是否使用该函数，在程序初始化时就被分配的了，或者在第一次执行到它的声明的时候分配（不同的编译器可能不同），所以多个线程调用该函数的时候，总是访问同一个变量b，这也是在多线程编程中必须注意的。</p><h2 id="语句">语句</h2><h3 id="使用using_block">使用using block</h3><p>在进行文件的读写操作、数据库连接操作等涉及程序结束时资源的释放，通常建议使用using block。格式如下：</p><pre><code><span class="tag">using</span>(代码段){    代码段...}</code></pre><p>好处在于using block结束后，using里面声明的对象会自动释放内存。尽管.Net的垃圾处理机制会处理，但那是不可控制的。</p><p>下面是一个使用using block进行文件的读操作的示例，可以看出使用using block能够让代码更加简洁。</p><pre><code><span class="keyword">using</span> (StreamReader sr=<span class="keyword">new</span> .....) {} </code></pre><p>相当于</p><pre><code>StreamReader sr=<span class="literal">null</span>; <span class="keyword">try</span> {     sr=<span class="keyword">new</span> ...; } <span class="keyword">finally</span> {     sr.Dispose(); }</code></pre><h3 id="使用LINQ语句">使用LINQ语句</h3><p>多种数据源（如数据库、XML、数组、集合等）的数据格式是不一样的，因此常常需要对不同的数据格式进行相互转换，以及学习多种数据查询语言。为了使得数据查询和操作变得更加简便，.NET 3.5版本发布了LINQ。</p><p>LINQ全称为语言集成查询（Language Integrated Query），是一种用来进行数据访问的编程模型，它是C# 3.0和.Net 3.5中的主要新增功能。LINQ以统一的方式操作各种数据源，降低数据访问的复杂度。LINQ支持的数据源有SQL Sever、XML以及内存中的数据集合。</p><p>下面举一个简单的示例，以说明使用LINQ语句带来的简便性：</p><pre><code><span class="keyword">bool</span> flag = <span class="keyword">false</span>;<span class="keyword">foreach</span> (<span class="keyword">var</span> elem <span class="keyword">in</span> list){    <span class="keyword">if</span> (elem...)    {        flag = <span class="keyword">true</span>;        <span class="keyword">break</span>;            }}...</code></pre><p>使用LINQ语句就是</p><pre><code><span class="built_in">bool</span> flag = <span class="built_in">list</span>.<span class="type">Any</span>(elem =&gt; ...)</code></pre><p>可以看到使用LINQ可以使得代码变得非常简洁。</p><h2 id="OO相关">OO相关</h2><h3 id="C#中的field与property">C#中的field与property</h3><p>property与field的区别在于，property拥有访问器，访问器定义了读取或者写入属性值必须执行的代码。property不是变量，没有存储数据的功能，数据都存在字段中，因此不能对property直接赋值，必须通过set访问器。</p><p>为了类的封装性，一般将描述类的特征的字段定义为private，再将属性定义为public来操作私有字段。例如如下：</p><pre><code><span class="keyword">private</span> <span class="keyword">string</span> phoneNumber;<span class="keyword">public</span> <span class="keyword">string</span> PhoneNumber{    <span class="keyword">get</span> { <span class="keyword">return</span> phoneNumbe; }    <span class="keyword">set</span> { phoneNumber = <span class="keyword">value</span>; }}</code></pre><p>上述代码也可以简写为</p><pre><code><span class="keyword">public</span> PhoneNumber { <span class="keyword">get</span>; <span class="keyword">set</span>; }</code></pre><p>使用property最大的好处在于<strong>可以在对field进行赋值时，加入一些逻辑</strong>，例如限制只能给字段赋于某个范围的值、或是要求字段只能读或只能写等。</p><hr><p>本文结束，感谢欣赏。</p><p><strong>欢迎转载，请注明本文的链接地址：</strong></p><p><a href="http://www.jeyzhang.com/cshape-learning-notes-1.html">http://www.jeyzhang.com/cshape-learning-notes-1.html</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;概念&quot;&gt;概念&lt;/h2&gt;&lt;h3 id=&quot;同步、异步、阻塞、非阻塞&quot;&gt;同步、异步、阻塞、非阻塞&lt;/h3&gt;&lt;p&gt;转自&lt;a href=&quot;https://www.zhihu.com/question/19732473&quot; target=&quot;_blank&quot; rel=&quot;extern
      
    
    </summary>
    
      <category term="C#" scheme="http://www.jeyzhang.com/categories/C/"/>
    
    
      <category term="C#" scheme="http://www.jeyzhang.com/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>C#学习笔记0：入门</title>
    <link href="http://www.jeyzhang.com/cshape-learning-notes-0.html"/>
    <id>http://www.jeyzhang.com/cshape-learning-notes-0.html</id>
    <published>2016-06-29T08:48:47.000Z</published>
    <updated>2016-08-20T03:58:27.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="关于-NET_Framework">关于.NET Framework</h2><h3 id="简介">简介</h3><p><strong>.NET Framework</strong>是微软公司为开发应用程序而设计的一个平台，它不限于运行的系统（尽管Windows系统上运行的最为广泛），包括Windows、linux（称为Mono）、Mac OS等。可以使用.NET Framework来创建各种不同类型的应用程序，例如Windows桌面应用程序、Web应用程序等等。.NET Framework的设计方式确保了它可以使用多种语言，例如C#，C++，VB等，所有的语言都可以访问.NET Framework，并且它们之间还可以互相通信，例如C#开发人员可以使用VB程序员编写的代码。</p><h3 id="包含的内容">包含的内容</h3><p>.NET Framework包含了一个庞大的代码库，可以在客户语言（如C#）中通过面向对象编程技术来使用这些代码。代码库分为多个不同的模块，例如一个模块包含Windows应用程序的构件，另一个模块包含网络编程的代码块，还有一个模块包含Web开发的代码块，可以根据需要来选择使用不同的模块。</p><p>部分.NET Framework库定义了一些基本类型，类型是数据的一种表达方式，指定最基本类型有助于使用.NET Framework的各种语言之间进行交互操作。这成为<strong>通用系统类型（Common Type System， CTS）</strong>。</p><p>.NET Framework还包含<strong>.NET公共语言运行库（Common Language Runtime, CLR）</strong>，它负责管理用.NET库开发的所有应用程序的执行。</p><h3 id="程序的编写和执行">程序的编写和执行</h3><h4 id="代码编译">代码编译</h4><p>使用.NET Framework编写应用程序，就是使用.NET代码库编写代码（使用支持.NET Framework的任何一种语言）。VS（Visual Studio）是一种强大的集成开发环境，能够方便将.NET功能集成到代码中。</p><p>使用C#创建程序，在程序执行中，需要把C#代码转换为目标操作系统能够理解的语言，即本机代码（naive code）。这种转换成为代码的编译，由编译器执行。在.NET Framework下，编译的过程包含两个阶段。</p><p>首先将代码编译为<strong>通用中间语言（Common Intermediate Language, CIL）</strong>代码（也称Microsoft Intermediate Language, MIL），这些代码不是专用于任何一种操作系统，也非专用于C#，其他的.NET语言如VB等也会在第一阶段编译为这种语言。使用VS开发C#应用程序时，这个编译步骤由VS完成。</p><p>要执行应用程序需要进一步的工作，这就是<strong>Just-In-Time(JIT)</strong>编译器的任务，它将CIL编译为专用于OS和目标机器结构的本机代码，这样才能在特定的机器和OS上运行程序。Just-In-Time反映了CIL代码仅在需要时才编译的事实，即<strong>在应用程序的运行过程中动态编译</strong>。</p><p>总结来说，JIT编译器使用的是CIL代码，CIL代码是独立于计算机、操作系统和CPU的，而不同的JIT编译器则可以针对最终程序执行的环境（如硬件条件、操作系统等）做优化。</p><h4 id="程序集">程序集</h4><p>在编译应用程序时，所创建的CIL代码存储在一个程序集中。程序集包含可执行的应用程序文件（.exe文件）和其他应用程序使用的库（.dll文件）。除此之外，程序集还包含元数据（即程序集中包含的数据的描述信息）和可选的资源（CIL使用的其他数据，例如图片文件）。</p><h4 id="托管代码">托管代码</h4><p>在将代码编译为CIL，再用JIT编译器将其编译为本机代码后，CLR的任务尚未全部完成，还需要管理正在执行的用.NET Framework编写的代码（这个执行代码的阶段称为<strong>运行时(runtime)</strong>）。即CLR管理着应用程序，其方式是管理内存、处理安全以及允许进行跨语言调试等。</p><p>不受CLR控制运行的应用程序属于非托管类型，某些语言（如C++）可以用于编写此类应用程序，例如访问操作系统的低级功能。在C#中只能编写在托管环境下运行的代码。将使用CLR的托管功能，让.NET处理与操作系统的任何交互。</p><h4 id="垃圾回收">垃圾回收</h4><p>托管代码中一个重要的功能是垃圾回收，它可以确保应用程序在不使用某些内存时就完全释放这些内存。.Net垃圾回收会定期检查计算机内存，从中删除不再需要的内容，但是执行垃圾回收的时间并不固定。因为垃圾回收的执行时间是不确定的（但是一定会执行），所以设计程序的时候需要注意这一点，在需要清理内存时自己手动完成清理工作也是一个不错的选择。</p><hr><p>本文结束，感谢欣赏。</p><p><strong>欢迎转载，请注明本文的链接地址：</strong></p><p><a href="http://www.jeyzhang.com/cshape-learning-notes-0.html">http://www.jeyzhang.com/cshape-learning-notes-0.html</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;关于-NET_Framework&quot;&gt;关于.NET Framework&lt;/h2&gt;&lt;h3 id=&quot;简介&quot;&gt;简介&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;.NET Framework&lt;/strong&gt;是微软公司为开发应用程序而设计的一个平台，它不限于运行的系统（尽管Windows
      
    
    </summary>
    
      <category term="C#" scheme="http://www.jeyzhang.com/categories/C/"/>
    
    
      <category term="C#" scheme="http://www.jeyzhang.com/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>whoosh+jieba：python下实现中文全文检索</title>
    <link href="http://www.jeyzhang.com/realization-of-full-chinese-text-search-using-whoosh-and-jieba.html"/>
    <id>http://www.jeyzhang.com/realization-of-full-chinese-text-search-using-whoosh-and-jieba.html</id>
    <published>2016-04-28T03:14:53.000Z</published>
    <updated>2018-02-19T13:44:44.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="需要安装">需要安装</h2><ul><li>python 2.xx</li><li>whoosh</li><li>jieba</li></ul><p>whoosh和jieba的安装使用<code>pip install</code>即可。</p><h2 id="快速入门">快速入门</h2><p>下面的代码实现了简单的中文检索</p><pre><code><span class="comment"># coding=utf-8</span><span class="keyword">import</span> os<span class="keyword">from</span> whoosh.index <span class="keyword">import</span> create_in<span class="keyword">from</span> whoosh.fields <span class="keyword">import</span> *<span class="keyword">from</span> jieba.analyse <span class="keyword">import</span> ChineseAnalyzer<span class="keyword">import</span> json<span class="comment"># 使用结巴中文分词</span>analyzer = ChineseAnalyzer()<span class="comment"># 创建schema, stored为True表示能够被检索</span>schema = Schema(title=TEXT(stored=<span class="keyword">True</span>, analyzer=analyzer), path=ID(stored=<span class="keyword">False</span>),                content=TEXT(stored=<span class="keyword">True</span>, analyzer=analyzer))<span class="comment"># 存储schema信息至'indexdir'目录下</span>indexdir = <span class="string">'indexdir/'</span><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(indexdir):    os.mkdir(indexdir)ix = create_in(indexdir, schema)<span class="comment"># 按照schema定义信息，增加需要建立索引的文档</span><span class="comment"># 注意：字符串格式需要为unicode格式</span>writer = ix.writer()writer.add_document(title=<span class="string">u"第一篇文档"</span>, path=<span class="string">u"/a"</span>,                    content=<span class="string">u"这是我们增加的第一篇文档"</span>)writer.add_document(title=<span class="string">u"第二篇文档"</span>, path=<span class="string">u"/b"</span>,                    content=<span class="string">u"第二篇文档也很interesting！"</span>)writer.commit()<span class="comment"># 创建一个检索器</span>searcher = ix.searcher()<span class="comment"># 检索标题中出现'文档'的文档</span>results = searcher.find(<span class="string">"title"</span>, <span class="string">u"文档"</span>)<span class="comment"># 检索出来的第一个结果，数据格式为dict{'title':.., 'content':...}</span>firstdoc = results[<span class="number">0</span>].fields()<span class="comment"># python2中，需要使用json来打印包含unicode的dict内容</span>jsondoc = json.dumps(firstdoc, ensure_ascii=<span class="keyword">False</span>)<span class="keyword">print</span> jsondoc  <span class="comment"># 打印出检索出的文档全部内容</span><span class="keyword">print</span> results[<span class="number">0</span>].highlights(<span class="string">"title"</span>)  <span class="comment"># 高亮标题中的检索词</span><span class="keyword">print</span> results[<span class="number">0</span>].score  <span class="comment"># bm25分数</span></code></pre><hr><p>本文结束，感谢欣赏。</p><p><strong>欢迎转载，请注明本文的链接地址：</strong></p><p><a href="http://www.jeyzhang.com/realization-of-full-chinese-text-search-using-whoosh-and-jieba.html">http://www.jeyzhang.com/realization-of-full-chinese-text-search-using-whoosh-and-jieba.html</a></p><hr><p><strong>文章写得不错？打赏一个呗:)</strong></p><p><img src="http://i.imgur.com/tTBAnzw.png" alt=""></p><p><strong>【打赏1.99￥以上，备注你的邮箱，可获得博主精心为你准备的深度学习/机器学习/自然语言处理的学习资料大礼包】</strong></p><p><strong>近期博主准备筹建NLP方面的技术群，欢迎感兴趣的小伙伴加我入群交流:)，加好友请备注：”博客”。</strong></p><p><img src="https://i.imgur.com/pBtBjMe.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;需要安装&quot;&gt;需要安装&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;python 2.xx&lt;/li&gt;
&lt;li&gt;whoosh&lt;/li&gt;
&lt;li&gt;jieba&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;whoosh和jieba的安装使用&lt;code&gt;pip install&lt;/code&gt;即可。&lt;/p&gt;
&lt;h
      
    
    </summary>
    
      <category term="Python" scheme="http://www.jeyzhang.com/categories/Python/"/>
    
    
      <category term="Jieba" scheme="http://www.jeyzhang.com/tags/Jieba/"/>
    
      <category term="Python" scheme="http://www.jeyzhang.com/tags/Python/"/>
    
      <category term="Search Engine" scheme="http://www.jeyzhang.com/tags/Search-Engine/"/>
    
      <category term="Whoosh" scheme="http://www.jeyzhang.com/tags/Whoosh/"/>
    
  </entry>
  
  <entry>
    <title>python学习笔记与常见问题</title>
    <link href="http://www.jeyzhang.com/python-learning-notes-and-common-problems.html"/>
    <id>http://www.jeyzhang.com/python-learning-notes-and-common-problems.html</id>
    <published>2016-04-27T09:22:49.000Z</published>
    <updated>2016-08-20T03:59:42.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="列表"><strong>列表</strong></h2><h3 id="使用lambda函数实现列表操作">使用lambda函数实现列表操作</h3><p>实现两个list的元素对应相乘，返回同等大小的list结果。</p><pre><code><span class="label">list1</span> = [...]<span class="label">list2</span> = [...]<span class="keyword">multiply_list </span>= <span class="preprocessor">map</span>(lambda (a, <span class="keyword">b): </span>a * <span class="keyword">b, </span>zip(list1, list2))</code></pre><h3 id="列表的类型转换">列表的类型转换</h3><p>例如，经常遇到需要将元素类型为<code>int</code>的列表，转为元素类型为<code>str</code>的列表，可以方便的使用<code>join</code>等函数进行格式化处理。使用<code>map</code>函数将很简单：</p><pre><code>int_list = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]str_list = <span class="built_in">map</span>(str, int_list) <span class="preprocessor"># str_list = [<span class="string">'1'</span>, <span class="string">'2'</span>, <span class="string">'3'</span>]</span><span class="preprocessor"># 类似的还有：</span><span class="built_in">map</span>(<span class="keyword">int</span>, <span class="built_in">list</span>) <span class="preprocessor"># list中的元素均转为int类型</span><span class="built_in">map</span>(<span class="keyword">float</span>, <span class="built_in">list</span>) <span class="preprocessor"># list中的元素均转为float类型</span></code></pre><h2 id="字符串及编码"><strong>字符串及编码</strong></h2><h3 id="python2中unicode编码下中文显示问题">python2中unicode编码下中文显示问题</h3><p>使用<code>json</code>对对象进行包装，再打印或者写入文件，如下</p><p><img src="http://imgur.com/F7w50wW.png" alt=""></p><p>写入文件时，需要转化为<code>UTF-8</code>编码，如下</p><pre><code>jsond = json.<span class="function"><span class="title">dumps</span><span class="params">(**, ensure_ascii=False)</span></span>f.<span class="function"><span class="title">write</span><span class="params">(jsond.encode(<span class="string">'utf-8'</span>)</span></span>)...</code></pre><p>在python3中打印unicode编码字符串很简单，使用<strong><code>pprint</code></strong>；python2中也可以使用<strong><code>pprint</code></strong>，具体做法见<a href="https://www.quora.com/How-do-you-print-a-python-unicode-data-structure" target="_blank" rel="external"><strong>这里</strong></a>。</p><hr><p>本文结束，感谢欣赏。</p><p><strong>欢迎转载，请注明本文的链接地址：</strong></p><p><a href="http://www.jeyzhang.com/python-learning-notes-and-common-problems.html">http://www.jeyzhang.com/python-learning-notes-and-common-problems.html</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;列表&quot;&gt;&lt;strong&gt;列表&lt;/strong&gt;&lt;/h2&gt;&lt;h3 id=&quot;使用lambda函数实现列表操作&quot;&gt;使用lambda函数实现列表操作&lt;/h3&gt;&lt;p&gt;实现两个list的元素对应相乘，返回同等大小的list结果。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&lt;span cl
      
    
    </summary>
    
      <category term="Python" scheme="http://www.jeyzhang.com/categories/Python/"/>
    
    
      <category term="Python" scheme="http://www.jeyzhang.com/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>TensorFlow中遇到的问题及解决方法</title>
    <link href="http://www.jeyzhang.com/problems-with-solution-in-tensorflow.html"/>
    <id>http://www.jeyzhang.com/problems-with-solution-in-tensorflow.html</id>
    <published>2016-03-25T14:36:46.000Z</published>
    <updated>2016-03-26T09:28:31.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文记录一下自己在使用TensorFlow的过程中，遇到的较为困扰的问题及最终的解决方法。</p><hr><h3 id="Q1-_如何查看TensorFlow中Tensor,_Variable,_Constant的值？">Q1. 如何查看TensorFlow中Tensor, Variable, Constant的值？</h3><p>TensorFlow中的许多方法返回的都是一个Tensor对象。在Debug的过程中，我们发现只能看到Tensor对象的一些属性信息，无法查看Tensor具体的输出值；而对于Variable和Constant，我们很容易对其进行创建操作，但是如何得到它们的值呢？</p><p>假设<code>ts</code>是我们想要查看的对象(Variable / Constant / 0输入的Tensor)，运行</p><pre><code>ts_res = sess.<span class="function"><span class="title">run</span><span class="params">(ts)</span></span><span class="function"><span class="title">print</span><span class="params">(ts_res)</span></span></code></pre><p>其中，<code>sess</code>为之前创建或默认的<code>session</code>. 运行后将得到一个<code>narray</code>格式的<code>ts_res</code>对象，通过<code>print</code>函数我们可以很方便的查看其中的内容。</p><p>但是，如果<code>ts</code>是一个有输入要求的Tensor，需要在查看其输出值前，填充(feed)输入数据。如下（假设ts只有一种输入）：</p><pre><code><span class="built_in">input</span> = ××××××  # the <span class="built_in">input</span> data need <span class="keyword">to</span> feedts_res = sess.run(<span class="keyword">ts</span>, feed_dict=<span class="built_in">input</span>)<span class="keyword">print</span>(ts_res)</code></pre><p>其他要求多种输入的Tensor类似处理即可。</p><h3 id="Q2-_模型训练完成后，如何获取模型的参数？">Q2. 模型训练完成后，如何获取模型的参数？</h3><p>模型训练完成后，通常会将模型参数存储于/checkpoint/×××.model文件(当然文件路径和文件名都可以更改，许多基于TensorFlow的开源包习惯将模型参数存储为model或者model.ckpt文件)。那么，在模型训练完成后，如何得到这些模型参数呢？</p><p>需要以下两个步骤：</p><p><strong>Step 1: 通过tf.train.Saver()恢复模型参数</strong> </p><p>运行</p><pre><code>saver = tf<span class="class">.train</span><span class="class">.Saver</span>()</code></pre><p>通过<code>saver</code>的<code>restore()</code>方法可以从本地的模型文件中恢复模型参数。大致做法如下：</p><pre><code><span class="comment"># your model's params</span><span class="comment"># you don't have to initialize them</span><span class="constant">x</span> = tf.placeholder(tf.float32)<span class="constant">y</span> = tf.placeholder(tf.float32)<span class="constant">W</span> = tf.Variable(...)<span class="constant">b</span> = tf.Variable(...)<span class="constant">y_</span> = tf.add(b, tf.matmul(x, w))<span class="comment"># create the saver</span><span class="constant">saver</span> = tf.train.Saver()<span class="comment"># creat the session you used in the training processing</span><span class="comment"># launch the model</span>with tf.Session() as sess:  <span class="comment"># Restore variables from disk.</span>  saver.restore(sess, "/your/path/model.ckpt")  print("Model restored.")  <span class="comment"># Do some work with the model, such as do a prediction</span>  pred = sess.run(y_, feed_dict={batch_x})  ...</code></pre><p>有关TensorFlow中变量的创建、存储及恢复操作，详细见<a href="http://tensorflow.org/how_tos/variables/index.md" target="_blank" rel="external">API文档</a>.</p><p><strong>Step 2: 通过tf.trainable_variables()得到训练参数</strong></p><p>tf.trainable_variables()方法将返回模型中所有可训练的参数，详细见<a href="https://www.tensorflow.org/versions/r0.7/api_docs/python/state_ops.html#trainable_variables" target="_blank" rel="external">API文档</a>。类似于以下的变量参数不会被返回：</p><pre><code>tf_var = tf.<span class="function"><span class="title">Variable</span><span class="params">(<span class="number">0</span>, name=<span class="string">"××××××"</span>, trainable=False)</span></span></code></pre><p>还可以通过<code>Variable</code>的<code>name</code>属性过滤出需要查看的参数，如下：</p><pre><code><span class="tag">var</span> = [v <span class="keyword">for</span> v <span class="keyword">in</span> t_vars <span class="keyword">if</span> v<span class="class">.name</span> == <span class="string">"W"</span>]</code></pre><p>（不断更新中…）</p><hr><p>本文结束，感谢欣赏。</p><p><strong>欢迎转载，请注明本文的链接地址：</strong></p><p><a href="http://www.jeyzhang.com/problems-with-solution-in-tensorflow.html">http://www.jeyzhang.com/problems-with-solution-in-tensorflow.html</a></p><p><strong>参考资料</strong></p><p><a href="https://stackoverflow.com/questions/33759623/tensorflow-how-to-restore-a-previously-saved-model-python" target="_blank" rel="external">Tensorflow: How to restore a previously saved model (python)</a></p><p><a href="https://stackoverflow.com/questions/34172622/get-original-value-of-tensor-in-tensorflow" target="_blank" rel="external">Get original value of Tensor in Tensorflow</a></p><p><a href="https://stackoverflow.com/questions/36193553/get-the-value-of-some-weights-in-a-model-trained-by-tensorflow" target="_blank" rel="external">Get the value of some weights in a model trained by TensorFlow</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本文记录一下自己在使用TensorFlow的过程中，遇到的较为困扰的问题及最终的解决方法。&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&quot;Q1-_如何查看TensorFlow中Tensor,_Variable,_Constant的值？&quot;&gt;Q1. 如何查看TensorFlow中Tenso
      
    
    </summary>
    
      <category term="Machine Learning" scheme="http://www.jeyzhang.com/categories/Machine-Learning/"/>
    
    
      <category term="Artificial Intelligence" scheme="http://www.jeyzhang.com/tags/Artificial-Intelligence/"/>
    
      <category term="Deep Learning" scheme="http://www.jeyzhang.com/tags/Deep-Learning/"/>
    
      <category term="Machine Learning" scheme="http://www.jeyzhang.com/tags/Machine-Learning/"/>
    
      <category term="TensorFlow" scheme="http://www.jeyzhang.com/tags/TensorFlow/"/>
    
  </entry>
  
  <entry>
    <title>TensorFlow学习笔记3：词向量</title>
    <link href="http://www.jeyzhang.com/tensorflow-learning-notes-3.html"/>
    <id>http://www.jeyzhang.com/tensorflow-learning-notes-3.html</id>
    <published>2016-03-16T13:24:38.000Z</published>
    <updated>2018-02-19T13:44:49.000Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://www.jeyzhang.com/tensorflow-learning-notes-2.html"><strong>上篇博文</strong></a>讲了如何构建一个简单的CNN模型，并运行在MNIST数据集上。下面讲述一下如何在TensorFlow中生成词向量(Word Embedding)，使用的模型来自<a href="http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf" target="_blank" rel="external">Mikolov et al</a>。</p><p>本文的目录如下：</p><ul><li>解释使用连续词向量的原因；</li><li>词向量模型的原理及训练过程；</li><li>在TensorFlow中实现模型的简单版本，并给出优化的方法；</li></ul><p>TensorFlow实现了两个版本的模型：<a href="https://www.tensorflow.org/code/tensorflow/examples/tutorials/word2vec/word2vec_basic.py" target="_blank" rel="external">简单版</a>和<a href="https://www.tensorflow.org/code/tensorflow/models/embedding/word2vec.py" target="_blank" rel="external">正式版</a>。如果想看源码的，可以直接下载。</p><hr><h3 id="为什么要使用Word_Embedding">为什么要使用Word Embedding</h3><p>在信号处理领域，图像和音频信号的输入往往是表示成高维度、密集的向量形式，在图像和音频的应用系统中，如何对输入信息进行编码(Encoding)显得非常重要和关键，这将直接决定了系统的质量。然而，在自然语言处理领域中，传统的做法是将词表示成离散的符号，例如将 [cat] 表示为 [Id537]，而 [dog] 表示为 [Id143]。<strong>这样做的缺点在于，没有提供足够的信息来体现词语之间的某种关联</strong>，例如尽管cat和dog不是同一个词，但是却应该有着某种的联系（如都是属于动物种类）。由于这种一元表示法(One-hot Representation)使得词向量过于稀疏，所以往往需要大量的语料数据才能训练出一个令人满意的模型。而Word Embedding技术则可以解决上述传统方法带来的问题。</p><p><img src="http://i.imgur.com/dHTf4Gq.png" alt=""></p><p><strong>向量空间模型(Vector space models, VSMs)</strong>将词语表示为一个连续的词向量，并且语义接近的词语对应的词向量在空间上也是接近的。VSMs在NLP中拥有很长的历史，但是所有的方法在某种程度上都是基于一种<strong><a href="https://en.wikipedia.org/wiki/Distributional_semantics#Distributional_Hypothesis" target="_blank" rel="external">分布式假说</a></strong>，该假说的思想是<strong>如果两个词的上下文(context)相同，那么这两个词所表达的语义也是一样的</strong>；换言之，两个词的语义是否相同或相似，取决于两个词的上下文内容，上下文相同表示两个词是可以等价替换的。</p><p>基于分布式假说理论的词向量生成方法主要分两大类：<strong>计数法</strong>(count-based methods, e.g. <a href="https://en.wikipedia.org/wiki/Latent_semantic_analysis" target="_blank" rel="external">Latent Semantic Analysis</a>)和<strong>预测法</strong>(predictive methods, e.g. <a href="http://www.scholarpedia.org/article/Neural_net_language_models" target="_blank" rel="external">neural probabilistic language models</a>)。<a href="http://clic.cimec.unitn.it/marco/publications/acl2014/baroni-etal-countpredict-acl2014.pdf" target="_blank" rel="external">Baroni等人</a>详细论述了这两种方法的区别，简而言之，计数法是在大型语料中统计词语及邻近的词的共现频率，然后将之为每个词都映射为一个稠密的向量表示；预测法是直接利用词语的邻近词信息来得到预测词的词向量（词向量通常作为模型的训练参数）。</p><p><strong><code>Wrod2vec</code></strong>是一个典型的预测模型，用于高效地学习Word Embedding。实现的模型有两种：<strong>连续词袋模型(CBOW)</strong>和<strong>Skip-Gram模型</strong>。算法上这两个模型是相似的，只不过CBOW是从输入的上下文信息来预测目标词(例如利用 [the cat sits on the] 来预测 [mat] )；而skip-gram模型则是相反的，从目标词来预测上下文信息。一般而言，这种方式上的区别使得CBOW模型更适合应用在小规模的数据集上，能够对很多的分布式信息进行平滑处理；而Skip-Gram模型则比较适合用于大规模的数据集上。</p><p>下面重点将介绍Skip-Gram模型。</p><h3 id="噪声-对比(Noise-Contrastive)训练">噪声-对比(Noise-Contrastive)训练</h3><p>基于神经网络的概率语言模型通常都是使用<strong><a href="https://en.wikipedia.org/wiki/Maximum_likelihood" target="_blank" rel="external">最大似然估计</a></strong>的方法进行训练的，通过Softmax函数得到在前面出现的词语 \( h \) (<code>history</code>)的情况下，目标词 \( w_{t} \) (<code>target</code>)出现的最大概率，数学表达式如下：</p><p><img src="http://i.imgur.com/vpOKwSG.png" alt=""></p><p>其中，\( score(w_t, h) \) 为词 \(w_t\) 和上下文 \(h\) 的 [兼容程度]。上式的对数形式如下：</p><p><img src="http://i.imgur.com/jG5Rppa.png" alt=""></p><p>理论上可以根据这个来建立一个合理的模型，但是现实中目标函数的计算代价非常昂贵，这是因为在训练过程中的每一步，我们都需要计算词库 \(w’\) 中其他词在当前的上下文环境下出现的概率值，这导致计算量十分巨大。</p><p><img src="http://i.imgur.com/Ck90mom.png" alt=""></p><p>然而，对于word2vec中的特征学习，可以不需要一个完整的概率模型。CBOW和Skip-Gram模型在输出端使用的是一个二分类器(即Logistic Regression)，来区分目标词和词库中其他的 \(k\) 个词。下面是一个CBOW模型的图示，对于Skip-Gram模型输入输出是倒置的。</p><p><img src="http://i.imgur.com/KnqFhUD.png" alt=""></p><p>此时，最大化的目标函数如下：</p><p><img src="http://i.imgur.com/g4PPKUW.png" alt=""></p><p>其中，\( Q_\theta(D=1 | w, h) \) 为二元逻辑回归的概率，具体为在数据集 \(D\) 中、输入的embedding vector \( \theta \)、上下文为 \( h \) 的情况下词语 \(w\) 出现的概率；公式后半部分为 \(k\) 个从 [噪声数据集] 中随机选择 \(k\) 个对立的词语出现概率(log形式)的期望值（即为<a href="https://en.wikipedia.org/wiki/Monte_Carlo_integration" target="_blank" rel="external">Monte Carlo average</a>）。</p><p>可以看出，目标函数的意义是显然的，即尽可能的 [分配(assign)] 高概率给真实的目标词，而低概率给其他 \( k \) 个 [噪声词]，这种技术称为<strong><a href="http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf" target="_blank" rel="external">负采样(Negative Sampling)</a></strong>。同时，该目标函数具有很好的数学意义：<strong>即在条件限制(训练时间)的情况下尽可能的逼近原有的Softmax函数（选择 \( k \) 个 [噪声点] 作为整个 [噪声数据] 的代表）</strong>，这样做无疑能够大大提升模型训练的速度。实际中我们使用的是类似的<a href="http://papers.nips.cc/paper/5165-learning-word-embeddings-efficiently-with-noise-contrastive-estimation.pdf" target="_blank" rel="external">噪声对比估计损失函数(noise-contrastive estimation (NCE))</a>，在TensorFlow中对应的实现函数为<code>tf.nn.nce_loss()</code>。</p><p>下面看看具体是如何训练Skip-Gram模型的。</p><h3 id="Skip-Gram模型">Skip-Gram模型</h3><p>举个例子，假设现在的数据集如下：</p><pre><code><span class="operator">the</span> quick brown fox jumped over <span class="operator">the</span> lazy dog</code></pre><p>这个数据集中包含了词语及其上下文信息。值得说明的是，<strong>上下文信息(Context)</strong>是一个比较宽泛的概念，有多种不同的理解：例如，词语周边的句法结构，词语的左边部分的若干个词语信息，对应的右半部分等。这里，我们使用最原始和基本的定义，即认为<strong>词语左右相邻的若干个词汇是该词对应的上下文信息</strong>。例如，取左右的词窗口为1，下面是数据集中的<strong><code>(上下文信息，对应的词)</code></strong>的pairs：</p><pre><code><span class="comment">([the, brown], quick)</span>, <span class="comment">([quick, fox], brown)</span>, <span class="comment">([brown, jumped], fox)</span>, ...</code></pre><p>Skip-Gram模型是通过输入的目标词来预测其对应的上下文信息，所以目标是通过[quick]来预测[the]和[brown]，通过[brown]来预测[quick]和[fox]… 将上面的pair转换为<strong><code>(input, output)</code></strong>的形式如下：</p><pre><code><span class="comment">(quick, the)</span>, <span class="comment">(quick, brown)</span>, <span class="comment">(brown, quick)</span>, <span class="comment">(brown, fox)</span>, ...</code></pre><p>目标函数定义如上，使用<a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent" target="_blank" rel="external">随机梯度下降算法(SGD)</a>来进行最优化求解，并且使用mini-batch方法 (通常batch_size在16到512之间)。</p><p>下面将详细剖析一下训练过程。假设在训练的第 \(t\) 步，目标是得到上面第一个实例输入 [quick] 的输出预测；我们选择<code>num_noise</code>个 [噪声点数据]，简单起见，这里<code>num_noise</code>为1，假设选择 [sheep] 作为噪声对比词。那么，此时的目标函数值如下：</p><p><img src="http://i.imgur.com/tmgHXZZ.png" alt=""></p><p>目标是<strong>更新embedding参数 \(\theta\) 以增大目标函数值</strong>，更新的方式是计算损失函数对参数 \(\theta\) 的导数，即 \( \frac{\partial}{\partial \theta} J_\text{NEG} \) (TensorFlow中有相应的函数以方便计算)，然后使得参数 \(\theta\) 朝梯度方向进行调整。当这个过程在训练数据集上执行多次后，产生的效果是使得输入的embedding vector的值发生改变，使得模型最终能够很好地区别目标词和 [噪声词]。</p><p>我们可以将学到的词向量进行降维(如<a href="\frac{\partial}{\partial \theta} J_\text{NEG}">t-SNE降维技术</a>)和可视化，通过可视化发现<strong>连续的词向量能够捕捉到更多的语义和关联信息</strong>；有趣的是，在降维空间中某些特定的方向表征着特定的语义信息，例如下图中的[man-&gt;women]，[king-&gt;queen]方向表示性别关系(出自<a href="http://www.aclweb.org/anthology/N13-1090" target="_blank" rel="external">Mikolov et al., 2013</a>)。</p><p><img src="http://i.imgur.com/vM1dtFq.png" alt=""></p><p>这也证实了连续词向量的作用，目前有非常多NLP中的任务(例如词性标注、命名实体识别等)都是使用连续词向量作为特征输入（更多可参考<a href="http://arxiv.org/abs/1103.0398" target="_blank" rel="external">Collobert et al., 2011</a>，<a href="http://www.aclweb.org/anthology/P10-1040" target="_blank" rel="external">Turian et al., 2010</a>）。</p><p>下面看看具体在TensorFlow中，是如何实现模型的创建和训练的。</p><h3 id="构建模型">构建模型</h3><p>首先，我们要定义一下<strong>词嵌入矩阵(Embedding Matrix)</strong>，并随机初始化。</p><pre><code>embeddings = tf.Variable(tf.<span class="function"><span class="title">random_uniform</span><span class="params">([vocabulary_size, embedding_size], -<span class="number">1.0</span>, <span class="number">1.0</span>)</span></span>)</code></pre><p>噪声-对比估计的损失函数在输出的逻辑回归模型中定义，为此，需要定义词库中每个词的权值和偏置参数(称为输出层权值参数)，如下：</p><pre><code>nce_weights = tf.Variable(  tf.truncated_normal([vocabulary_size, embedding_size],    stddev=<span class="number">1.0</span> / math.<span class="function"><span class="title">sqrt</span><span class="params">(embedding_size)</span></span>))nce_biases = tf.<span class="function"><span class="title">Variable</span><span class="params">(tf.zeros([vocabulary_size])</span></span>)</code></pre><p>现在我们有了这些模型参数，接下来需要定义Skip-Gram模型。简单起见，假设我们已经将语料库中的词[<strong>整数化</strong>]，即每个词被表示为一个整数(具体见<a href="https://www.tensorflow.org/code/tensorflow/examples/tutorials/word2vec/word2vec_basic.py" target="_blank" rel="external">tensorflow/examples/tutorials/word2vec/word2vec_basic.py</a>)。Skip-Gram模型有两种输入，都是整数形式表示：一种是批量的上下文词汇，一种是目标词。我们先为这些输入创建占位符(placeholder)，之后再进行数据的填充。</p><pre><code># Placeholders <span class="keyword">for</span> inputstrain_inputs = <span class="keyword">tf</span>.placeholder(<span class="keyword">tf</span>.int32, shape=[batch_size])train_labels = <span class="keyword">tf</span>.placeholder(<span class="keyword">tf</span>.int32, shape=[batch_size, <span class="number">1</span>])</code></pre><p>我们还需要能够查找(look up)batch中的输入词对应的vector，如下：</p><pre><code>embed = tf<span class="class">.nn</span><span class="class">.embedding_lookup</span>(embeddings, train_inputs)</code></pre><p>现在，我们有了每个词对应的embedding，接下来使用噪声-对比策略来预测目标词：</p><pre><code><span class="comment"># Compute the NCE loss, using a sample of the negative labels each time.</span><span class="constant">loss</span> = tf.reduce_mean(  tf.nn.nce_loss(nce_weights, nce_biases, embed, train_labels,                 num_sampled, vocabulary_size))</code></pre><p>现在，我们有了损失函数节点(loss node)，还需要利用随机梯度下降来进行优化，定义如下的优化器：</p><pre><code><span class="comment"># We use the SGD optimizer.</span><span class="setting">optimizer = <span class="value">tf.train.GradientDescentOptimizer(learning_rate=<span class="number">1.0</span>).minimize(loss)</span></span></code></pre><h3 id="模型的训练">模型的训练</h3><p>模型的训练方式很简单，只需要迭代地通过<code>feed_dict</code>进行训练数据的填充，并启动一个session。</p><pre><code><span class="keyword">for</span> inputs, labels <span class="keyword">in</span> generate_batch(...):  feed_dict = {<span class="string">training_inputs:</span> inputs, <span class="string">training_labels:</span> labels}  _, cur_loss = session.run([optimizer, loss], feed_dict=feed_dict)</code></pre><p>完整的示例代码请参考<a href="https://www.tensorflow.org/code/tensorflow/examples/tutorials/word2vec/word2vec_basic.py" target="_blank" rel="external">tensorflow/examples/tutorials/word2vec/word2vec_basic.py</a>。</p><h3 id="Embedding的可视化">Embedding的可视化</h3><p>模型训练结束后，我们利用<code>t-SNE技术</code>实现学习到的embedding可视化，如下图所示：</p><p><img src="http://i.imgur.com/z2VpgFz.png" alt=""></p><p>正如我们期望的那样，语义相似的词语会聚集在一起。关于word2vec更加高级的实现版本，可参考<a href="https://www.tensorflow.org/code/tensorflow/models/embedding/word2vec.py" target="_blank" rel="external">tensorflow/models/embedding/word2vec.py</a>。</p><h3 id="Embedding的评价：类比推理(Analogical_Reasoning)">Embedding的评价：类比推理(Analogical Reasoning)</h3><p>Embedding在许多的NLP任务中都很有效果，那么如何评价Embedding的效果呢？一种简单的方式是，直接用来预测句法和语义的关联性，例如预测<strong><code>king is to queen as father is to ?</code></strong>，这称作<strong><code>Analogical Reasoning</code></strong>(By <a href="http://msr-waypoint.com/en-us/um/people/gzweig/Pubs/NAACL2013Regularities.pdf" target="_blank" rel="external">Mikolov and colleagues</a>, 评价数据集可在<a href="https://www.google.com/url?q=https://word2vec.googlecode.com/svn/trunk/questions-words.txt&amp;usg=AFQjCNHs2OomcnDRRaht8ih-rL2oHnOSwQ" target="_blank" rel="external">这里</a>下载)。</p><p>具体如何进行评价的，可以参考<a href="https://www.tensorflow.org/code/tensorflow/models/embedding/word2vec.py" target="_blank" rel="external">正式word2vec版本</a>中的<code>build_eval_graph()</code>和<code>eval()</code>函数。</p><p>评价任务的准确性依赖于模型的超参数们，为了达到最佳的效果，往往需要将评价任务建立在一个巨大的数据集上，还可能需要使用一些trick，例如数据抽样、适当的fine tuning等。</p><h3 id="进一步的优化">进一步的优化</h3><p>以上的Vanilla版本展示了TensorFlow的简单易用。例如，只需要调用<code>tf.nn.nce_loss()</code>就可以替换<code>tf.nn.sampled_softmax_loss()</code>。如果你有关于损失函数的新想法，也可以自己在TensorFlow中手写一个，然后使用优化器计算导数并作优化。TensorFlow的简单易用，可以帮助你快速验证自己的想法。</p><p>一旦你有了一个令人满意的模型结构，你可以针对它进行优化使其更加高效。例如，原始版本中有个不足之处是，数据读取和填充是用Python实现的，因此会相对低效。你可以自己实现一个reader，参考<a href="https://www.tensorflow.org/versions/r0.7/how_tos/new_data_formats/index.html" target="_blank" rel="external">数据格式要求</a>。对于Skip-Gram模型，我们在<a href="https://www.tensorflow.org/code/tensorflow/models/embedding/word2vec.py" target="_blank" rel="external">这个版本</a>中自定义了reader，可供参考。</p><p>如果你的模型在I/O上足够好了，但仍然想要提升效率，你可以自己编写TensorFlow Ops（<a href="https://www.tensorflow.org/versions/r0.7/how_tos/adding_an_op/index.html" target="_blank" rel="external">参考这里</a>）.<a href="https://www.tensorflow.org/code/tensorflow/models/embedding/word2vec_optimized.py" target="_blank" rel="external">优化版本</a>中提供了示例。</p><h3 id="总结">总结</h3><p>这篇博文介绍了word2vec模型，一个用来高效学习出word embedding的模型。我们解释了为什么word embedding是有效的，讨论了如何更加高效地训练模型以及如何在TensorFlow中去实现。</p><hr><p>本文结束，感谢欣赏。</p><p><strong>欢迎转载，请注明本文的链接地址：</strong></p><p><a href="http://www.jeyzhang.com/tensorflow-learning-notes-3.html">http://www.jeyzhang.com/tensorflow-learning-notes-3.html</a></p><p><strong>参考资料</strong></p><p><a href="https://www.tensorflow.org/versions/r0.7/tutorials/word2vec/index.html" target="_blank" rel="external">TensorFlow: Vector Representation of Words</a></p><hr><p><strong>文章写得不错？打赏一个呗:)</strong></p><p><img src="http://i.imgur.com/tTBAnzw.png" alt=""></p><p><strong>【打赏1.99￥以上，备注你的邮箱，可获得博主精心为你准备的深度学习/机器学习/自然语言处理的学习资料大礼包】</strong></p><p><strong>近期博主准备筹建NLP方面的技术群，欢迎感兴趣的小伙伴加我入群交流:)，加好友请备注：”博客”。</strong></p><p><img src="https://i.imgur.com/pBtBjMe.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a href=&quot;http://www.jeyzhang.com/tensorflow-learning-notes-2.html&quot;&gt;&lt;strong&gt;上篇博文&lt;/strong&gt;&lt;/a&gt;讲了如何构建一个简单的CNN模型，并运行在MNIST数据集上。下面讲述一下如何在Tenso
      
    
    </summary>
    
      <category term="Machine Learning" scheme="http://www.jeyzhang.com/categories/Machine-Learning/"/>
    
    
      <category term="Artificial Intelligence" scheme="http://www.jeyzhang.com/tags/Artificial-Intelligence/"/>
    
      <category term="Deep Learning" scheme="http://www.jeyzhang.com/tags/Deep-Learning/"/>
    
      <category term="Machine Learning" scheme="http://www.jeyzhang.com/tags/Machine-Learning/"/>
    
      <category term="TensorFlow" scheme="http://www.jeyzhang.com/tags/TensorFlow/"/>
    
  </entry>
  
  <entry>
    <title>卷积神经网络(CNN)在句子建模上的应用</title>
    <link href="http://www.jeyzhang.com/cnn-apply-on-modelling-sentence.html"/>
    <id>http://www.jeyzhang.com/cnn-apply-on-modelling-sentence.html</id>
    <published>2016-03-11T02:36:35.000Z</published>
    <updated>2018-02-19T13:44:24.000Z</updated>
    
    <content type="html"><![CDATA[<p>之前的博文已经介绍了CNN的基本原理，本文将大概总结一下最近CNN在NLP中的句子建模（或者句子表示）方面的应用情况，主要阅读了以下的文献：</p><blockquote><p>Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.</p><p>Kalchbrenner N, Grefenstette E, Blunsom P. A convolutional neural network for modelling sentences[J]. arXiv preprint arXiv:1404.2188, 2014.</p><p>Hu B, Lu Z, Li H, et al. Convolutional neural network architectures for matching natural language sentences[C]//Advances in Neural Information Processing Systems. 2014: 2042-2050.</p><p>He H, Gimpel K, Lin J. Multi-perspective sentence similarity modeling with convolutional neural networks[C]//Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. 2015: 1576-1586.</p><p>Wenpeng Yin, Hinrich Schütze. Convolutional Neural Network for Paraphrase Identification. The 2015 Conference of the North American Chapter of the Association for Computational Linguistics</p><p>Zhang Y, Wallace B. A Sensitivity Analysis of (and Practitioners’ Guide to) Convolutional Neural Networks for Sentence Classification[J]. arXiv preprint arXiv:1510.03820, 2015.</p></blockquote><p>下面对文献中CNN的结构和细节进行梳理。</p><hr><h3 id="Kim_Y’s_Paper">Kim Y’s Paper</h3><h4 id="模型结构及原理">模型结构及原理</h4><p>模型的结构如下：</p><p><img src="http://i.imgur.com/yxoZDt9.png" alt=""></p><p>说明如下：</p><ul><li><strong>输入层</strong></li></ul><p>如图所示，输入层是句子中的词语对应的word vector依次（从上到下）排列的矩阵，假设句子有 \( n \) 个词，vector的维数为 \( k \) ，那么这个矩阵就是 \( n × k \) 的。</p><p>这个矩阵的类型可以是静态的(static)，也可以是动态的(non static)。静态就是word vector是固定不变的，而动态则是在模型训练过程中，word vector也当做是可优化的参数，通常把反向误差传播导致word vector中值发生变化的这一过程称为<strong><code>Fine tune</code></strong>。</p><p>对于未登录词的vector，可以用0或者随机小的正数来填充。</p><ul><li><strong>第一层卷积层</strong></li></ul><p>输入层通过卷积操作得到若干个<code>Feature Map</code>，卷积窗口的大小为 \( h × k \) ，其中 \( h \) 表示纵向词语的个数，而 \( k \) 表示word vector的维数。通过这样一个大型的卷积窗口，将得到若干个列数为1的<code>Feature Map</code>。</p><ul><li><strong>池化层</strong></li></ul><p>接下来的池化层，文中用了一种称为<strong><code>Max-over-time Pooling</code></strong>的方法。这种方法就是简单地从之前一维的<code>Feature Map</code>中提出最大的值，文中解释最大值代表着最重要的信号。可以看出，这种Pooling方式可以解决可变长度的句子输入问题（因为不管<code>Feature Map</code>中有多少个值，只需要提取其中的最大值）。</p><p>最终池化层的输出为各个<code>Feature Map</code>的最大值们，即一个一维的向量。</p><ul><li><strong>全连接 + Softmax层</strong></li></ul><p>池化层的一维向量的输出通过全连接的方式，连接一个Softmax层，Softmax层可根据任务的需要设置（通常反映着最终类别上的概率分布）。</p><p>最终实现时，我们可以在倒数第二层的全连接部分上使用<code>Dropout</code>技术，即对全连接层上的权值参数给予<strong><code>L2正则化</code></strong>的限制。这样做的好处是防止隐藏层单元自适应（或者对称），从而减轻过拟合的程度。</p><h4 id="实验部分">实验部分</h4><p><strong>1. 数据</strong></p><p>实验用到的数据集如下（具体的名称和来源可以参考论文）：</p><p><img src="http://i.imgur.com/8VDJDDJ.png" alt=""></p><p><strong>2. 模型训练和调参</strong></p><ul><li>修正线性单元(Rectified linear units)</li><li>滤波器的h大小：3,4,5；对应的Feature Map的数量为100；</li><li>Dropout率为0.5，L2正则化限制权值大小不超过3；</li><li>mini-batch的大小为50；</li></ul><p>这些参数的选择都是基于SST-2 dev数据集，通过网格搜索方法(Grid Search)得到的最优参数。另外，训练过程中采用随机梯度下降方法，基于shuffled mini-batches之上的，使用了Adadelta update rule(Zeiler, 2012)。</p><p><strong>3. 预训练的Word Vector</strong></p><p>这里的word vector使用的是公开的数据，即连续词袋模型(COW)在Google News上的训练结果。未登录次的vector值是随机初始化的。</p><p><strong>4. 实验结果</strong></p><p>实验结果如下图：</p><p><img src="http://i.imgur.com/sNpll24.png" alt=""></p><p>其中，前四个模型是上文中所提出的基本模型的各个变种：</p><ul><li><strong>CNN-rand</strong>: 所有的word vector都是随机初始化的，同时当做训练过程中优化的参数；</li><li><strong>CNN-static</strong>: 所有的word vector直接使用无监督学习即Google的Word2Vector工具(COW模型)得到的结果，并且是固定不变的；</li><li><strong>CNN-non-static</strong>: 所有的word vector直接使用无监督学习即Google的Word2Vector工具(COW模型)得到的结果，但是会在训练过程中被<code>Fine tuned</code>；</li><li><strong>CNN-multichannel</strong>: CNN-static和CNN-non-static的混合版本，即两种类型的输入；</li></ul><p>博主自己下载了论文作者的实现程序(<a href="https://github.com/yoonkim/CNN_sentence" target="_blank" rel="external"><strong>Github地址</strong></a>)，最终在MR数据集上的运行结果如下：</p><ul><li>CNN-rand: 0.7669</li><li>CNN-static: 0.8076</li><li>CNN-non-static: 0.8151</li></ul><p>和论文中的结果差不多。</p><p><strong>5. 结论</strong></p><ul><li><strong><code>CNN-static</code></strong>较与<strong><code>CNN-rand</code></strong>好，<strong>说明pre-training的word vector确实有较大的提升作用</strong>（这也难怪，因为pre-training的word vector显然利用了更大规模的文本数据信息）；</li><li><strong><code>CNN-non-static</code></strong>较于<strong><code>CNN-static</code></strong>大部分要好，<strong>说明适当的Fine tune也是有利的，是因为使得vectors更加贴近于具体的任务</strong>；</li><li><strong><code>CNN-multichannel</code></strong>较于<strong><code>CNN-single</code></strong>在小规模的数据集上有更好的表现，实际上<strong><code>CNN-multichannel</code></strong>体现了一种折中思想，即既不希望Fine tuned的vector距离原始值太远，但同时保留其一定的变化空间。</li></ul><p>值得注意的是，static的vector和non-static的相比，有一些有意思的现象如下表格：</p><p><img src="http://i.imgur.com/fW6pr0p.png" alt=""></p><ul><li>原始的word2vector训练结果中，<code>bad</code>对应的最相近词为<code>good</code>，原因是这两个词在句法上的使用是极其类似的（可以简单替换，不会出现语句毛病）；而在<code>non-static</code>的版本中，<code>bad</code>对应的最相近词为<code>terrible</code>，这是因为在<code>Fune tune</code>的过程中，vector的值发生改变从而更加贴切数据集（是一个情感分类的数据集），所以在情感表达的角度这两个词会更加接近；</li><li>句子中的<strong><code>!</code></strong>最接近一些表达形式较为激进的词汇，如<code>lush</code>等；而<strong><code>,</code></strong>则接近于一些连接词，这和我们的主观感受也是相符的。</li></ul><p>Kim Y的这个模型很简单，但是却有着很好的性能。后续Denny用TensorFlow实现了这个模型的简单版本，可参考<strong><a href="http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/" target="_blank" rel="external">这篇博文</a></strong>；以及Ye Zhang等人对这个模型进行了大量的实验，并给出了调参的建议，可参考<strong><a href="http://arxiv.org/abs/1510.03820" target="_blank" rel="external">这篇论文</a></strong>。</p><p>下面总结一下Ye Zhang等人基于Kim Y的模型做了大量的调参实验之后的结论：</p><ul><li>由于模型训练过程中的随机性因素，如随机初始化的权重参数，mini-batch，随机梯度下降优化算法等，造成模型在数据集上的结果有一定的浮动，如准确率(accuracy)能达到1.5%的浮动，而AUC则有3.4%的浮动；</li><li>词向量是使用word2vec还是GloVe，对实验结果有一定的影响，具体哪个更好依赖于任务本身；</li><li>Filter的大小对模型性能有较大的影响，并且Filter的参数应该是可以更新的；</li><li>Feature Map的数量也有一定影响，但是需要兼顾模型的训练效率；</li><li>1-max pooling的方式已经足够好了，相比于其他的pooling方式而言；</li><li>正则化的作用微乎其微。</li></ul><p>Ye Zhang等人给予模型调参者的建议如下：</p><ul><li>使用<strong><code>non-static</code></strong>版本的<strong><code>word2vec</code></strong>或者<strong><code>GloVe</code></strong>要比单纯的<code>one-hot representation</code>取得的效果好得多；</li><li>为了找到最优的过滤器(Filter)大小，可以使用线性搜索的方法。通常过滤器的大小范围在<strong><code>1-10</code></strong>之间，当然对于长句，使用更大的过滤器也是有必要的；</li><li><strong><code>Feature Map</code></strong>的数量在<strong><code>100-600</code></strong>之间；</li><li>可以尽量多尝试激活函数，实验发现<strong><code>ReLU</code></strong>和<strong><code>tanh</code></strong>两种激活函数表现较佳；</li><li>使用简单的<strong><code>1-max pooling</code></strong>就已经足够了，可以没必要设置太复杂的pooling方式；</li><li>当发现增加<code>Feature Map</code>的数量使得模型的性能下降时，可以考虑增大正则的力度，如调高<code>dropout</code>的概率；</li><li>为了检验模型的性能水平，多次反复的交叉验证是必要的，这可以确保模型的高性能并不是偶然。</li></ul><p>论文附录中还附上了各种调参结果，感兴趣的可以前往阅读之。</p><h3 id="Kalchbrenner’s_Paper">Kalchbrenner’s Paper</h3><p>Kal的这篇文章引用次数较高，他提出了一种名为DCNN(Dynamic Convolutional Neural Network)的网络模型，在上一篇（Kim’s Paper）中的实验结果部分也验证了这种模型的有效性。这个模型的精妙之处在于Pooling的方式，使用了一种称为<strong><code>动态Pooling</code></strong>的方法。</p><p>下图是这个模型对句子语义建模的过程，可以看到底层通过组合邻近的词语信息，逐步向上传递，上层则又组合新的Phrase信息，从而使得句子中即使相离较远的词语也有交互行为（或者某种语义联系）。从直观上来看，这个模型能够通过词语的组合，提取出句子中重要的语义信息（通过Pooling），某种意义上来说，层次结构的<strong><code>feature graph</code></strong>的作用类似于一棵语法解析树。</p><p><img src="http://i.imgur.com/3IbLJX4.png" alt=""></p><p>DCNN能够处理可变长度的输入，网络中包含两种类型的层，分别是<strong>一维的卷积层</strong>和<strong>动态k-max的池化层(Dynamic k-max pooling)</strong>。其中，动态k-max池化是最大化池化更一般的形式。之前LeCun将CNN的池化操作定义为一种非线性的抽样方式，返回一堆数中的最大值，原话如下：</p><blockquote><p>The max pooling operator is a non-linear subsampling function that returns the maximum of a set of values (LuCun et al., 1998).</p></blockquote><p>而文中的k-max pooling方式的一般化体现在：</p><ul><li>pooling的结果不是返回一个最大值，而是返回k组最大值，这些最大值是原输入的一个子序列；</li><li>pooling中的参数k可以是一个动态函数，具体的值依赖于输入或者网络的其他参数；</li></ul><h4 id="模型结构及原理-1">模型结构及原理</h4><p>DCNN的网络结构如下图：</p><p><img src="http://i.imgur.com/CNMa0VL.png" alt=""></p><p>网络中的卷积层使用了一种称之为<strong><code>宽卷积(Wide Convolution)</code></strong>的方式，紧接着是动态的k-max池化层。中间卷积层的输出即<code>Feature Map</code>的大小会根据输入句子的长度而变化。下面讲解一下这些操作的具体细节：</p><p><strong>1. 宽卷积</strong></p><p>相比于传统的卷积操作，宽卷积的输出的<code>Feature Map</code>的宽度(width)会更宽，原因是卷积窗口并不需要覆盖所有的输入值，也可以是部分输入值（可以认为此时其余的输入值为0，即填充0）。如下图所示：</p><p><img src="http://i.imgur.com/YgM3Tsg.png" alt=""></p><p>图中的右图即表示宽卷积的计算过程，当计算第一个节点即\( s_1 \)时，可以假使\( s_1 \)节点前面有四个输入值为0的节点参与卷积（卷积窗口为5）。明显看出，狭义上的卷积输出结果是宽卷积输出结果的一个子集。</p><p><strong>2. k-max池化</strong></p><p>给出数学形式化的表述是，给定一个\( k \)值，和一个序列\( p \in R^p \)(其中\( p ≥ k \))，<code>k-max pooling</code>选择了序列\( p \)中的前\( k \)个最大值，这些最大值保留原来序列的次序（实际上是原序列的一个子序列）。</p><p><code>k-max pooling</code>的好处在于，既提取除了句子中的较重要信息（不止一个），同时保留了它们的次序信息（相对位置）。同时，由于应用在最后的卷积层上只需要提取出\( k \)个值，所以这种方法允许不同长度的输入（输入的长度应该要大于\( k \)）。然而，对于中间的卷积层而言，池化的参数\( k \)不是固定的，具体的选择方法见下面的介绍。</p><p><strong>3. 动态k-max池化</strong></p><p>动态k-max池化操作，其中的\( k \)是<code>输入句子长度</code>和<code>网络深度</code>两个参数的函数，具体如下：</p><p>$$ K_{l}=\max \left( k_{top}, \left \lceil \frac {L-l}{L} s \right \rceil \right) $$</p><p>其中\( l \)表示当前卷积的层数（即第几个卷积层），\( L \)是网络中总共卷积层的层数；\( k_{top} \)为最顶层的卷积层pooling对应的\( k \)值，是一个固定的值。举个例子，例如网络中有三个卷积层，\( k_{top} = 3\)，输入的句子长度为18；那么，对于第一层卷积层下面的pooling参数\( k_{1} = 12\)，而第二层卷积层对于的为\( k_{2} = 6\)，而\( k_{3} = k_{top} = 3\)。</p><p>动态k-max池化的意义在于，从不同长度的句子中提取出相应数量的语义特征信息，以保证后续的卷积层的统一性。</p><p><strong>4. 非线性特征函数</strong></p><p>pooling层与下一个卷积层之间，是通过与一些权值参数相乘后，加上某个偏置参数而来的，这与传统的CNN模型是一样的。</p><p><strong>5. 多个Feature Map</strong></p><p>和传统的CNN一样，会提出多个Feature Map以保证提取特征的多样性。</p><p><strong>6. 折叠操作(Folding)</strong></p><p>之前的宽卷积是在输入矩阵\( d × s \)中的每一行内进行计算操作，其中\(d\)是word vector的维数，\(s\)是输入句子的词语数量。而<strong><code>Folding</code></strong>操作则是考虑相邻的两行之间的某种联系，方式也很简单，就是将两行的vector相加；该操作没有增加参数数量，但是提前（在最后的全连接层之前）考虑了特征矩阵中行与行之间的某种关联。</p><h4 id="模型的特点">模型的特点</h4><ul><li>保留了句子中词序信息和词语之间的相对位置；</li><li>宽卷积的结果是传统卷积的一个扩展，某种意义上，也是n-gram的一个扩展；</li><li>模型不需要任何的先验知识，例如句法依存树等，并且模型考虑了句子中相隔较远的词语之间的语义信息；</li></ul><h4 id="实验部分-1">实验部分</h4><p><strong>1. 模型训练及参数</strong></p><ul><li>输出层是一个类别概率分布（即softmax），与倒数第二层全连接；</li><li>代价函数为交叉熵，训练目标是最小化代价函数；</li><li>L2正则化；</li><li>优化方法：mini-batch + gradient-based (使用Adagrad update rule, Duchi et al., 2011)</li></ul><p><strong>2. 实验结果</strong></p><p>在三个数据集上进行了实验，分别是(1)电影评论数据集上的情感识别，(2)TREC问题分类，以及(3)Twitter数据集上的情感识别。结果如下图：</p><p><img src="http://i.imgur.com/zuf2bSu.png" alt=""></p><p><img src="http://i.imgur.com/6lWY7zC.png" alt=""></p><p><img src="http://i.imgur.com/PX9N2JB.png" alt=""></p><p>可以看出，DCNN的性能非常好，几乎不逊色于传统的模型；而且，DCNN的好处在于不需要任何的先验信息输入，也不需要构造非常复杂的人工特征。</p><h3 id="Hu’s_Paper">Hu’s Paper</h3><h4 id="模型结构与原理">模型结构与原理</h4><p><strong>1. 基于CNN的句子建模</strong></p><p>这篇论文主要针对的是<strong>句子匹配(Sentence Matching)</strong>的问题，但是基础问题仍然是句子建模。首先，文中提出了一种基于CNN的句子建模网络，如下图：</p><p><img src="http://i.imgur.com/kG7AbW3.png" alt=""></p><p>图中灰色的部分表示对于长度较短的句子，其后面不足的部分填充的全是0值(Zero Padding)。可以看出，模型解决不同长度句子输入的方法是规定一个最大的可输入句子长度，然后长度不够的部分进行0值的填充；图中的卷积计算和传统的CNN卷积计算无异，而池化则是使用Max-Pooling。</p><ul><li><strong>卷积结构的分析</strong></li></ul><p>下图示意性地说明了卷积结构的作用，作者认为卷积的作用是<strong>从句子中提取出局部的语义组合信息</strong>，而多张<code>Feature Map</code>则是从多种角度进行提取，也就是<strong>保证提取的语义组合的多样性</strong>；而池化的作用是对多种语义组合进行选择，过滤掉一些置信度低的组合（可能这样的组合语义上并无意义）。</p><p><img src="http://i.imgur.com/yrFS2k1.png" alt=""></p><p><strong>2. 基于CNN的句子匹配模型</strong></p><p>下面是基于之前的句子模型，建立的两种用于两个句子的匹配模型。</p><p><strong>2.1 结构I</strong></p><p>模型结构如下图：</p><p><img src="http://i.imgur.com/xaP0KNV.png" alt=""></p><p>简单来说，首先分别单独地对两个句子进行建模（使用上文中的句子模型），从而得到两个相同且固定长度的向量，向量表示句子经过建模后抽象得来的特征信息；然后，将这两个向量作为一个多层感知机(MLP)的输入，最后计算匹配的分数。</p><p>这个模型比较简单，但是有一个较大的缺点：两个句子在建模过程中是完全独立的，没有任何交互行为，一直到最后生成抽象的向量表示后才有交互行为（一起作为下一个模型的输入），这样做使得句子在抽象建模的过程中会丧失很多语义细节，同时过早地失去了句子间语义交互计算的机会。因此，推出了第二种模型结构。</p><p><strong>2.2 结构II</strong></p><p>模型结构如下图：</p><p><img src="http://i.imgur.com/NWvAPVr.png" alt=""></p><p>图中可以看出，这种结构提前了两个句子间的交互行为。</p><ul><li><strong>第一层卷积层</strong></li></ul><p>第一层中，首先取一个固定的卷积窗口\( k1 \)，然后遍历 \( S_{x} \) 和 \( S_{y} \) 中所有组合的二维矩阵进行卷积，每一个二维矩阵输出一个值（文中把这个称作为一维卷积，因为实际上是把组合中所有词语的vector排成一行进行的卷积计算），构成Layer-2。下面给出数学形式化表述：</p><p><img src="http://i.imgur.com/f3DqYsp.png" alt=""></p><ul><li><strong>第一层卷积层后的Max-Pooling层</strong></li></ul><p>从而得到Layer-2，然后进行2×2的Max-pooling：</p><p><img src="http://i.imgur.com/DaFv3ps.png" alt=""></p><ul><li><strong>后续的卷积层</strong></li></ul><p>后续的卷积层均是传统的二维卷积操作，形式化表述如下：</p><p><img src="http://i.imgur.com/Pr5Mm9n.png" alt=""></p><ul><li><strong>二维卷积结果后的Pooling层</strong></li></ul><p>与第一层卷积层后的简单Max-Pooling方式不同，后续的卷积层的Pooling是一种<strong>动态Pooling方法</strong>，这种方法来源于参考文献[1]。</p><ul><li><strong>结构II的性质</strong></li></ul><ol><li>保留了词序信息；</li><li>更具一般性，实际上结构I是结构II的一种特殊情况（取消指定的权值参数）；</li></ol><h4 id="实验部分-2">实验部分</h4><p><strong>1. 模型训练及参数</strong></p><ul><li>使用基于排序的自定义损失函数(Ranking-based Loss)</li><li>BP反向传播+随机梯度下降；</li><li>mini-batch为100-200,并行化；</li><li>为了防止过拟合，对于中型和大型数据集，会提前停止模型训练；而对于小型数据集，还会使用Dropout策略；</li><li>Word2Vector：50维；英文语料为Wikipedia(~1B words)，中文语料为微博数据(~300M words)；</li><li>使用ReLu函数作为激活函数；</li><li>卷积窗口为3-word window；</li><li>使用Fine tuning；</li></ul><p><strong>2. 实验结果</strong></p><p>一共做了三个实验，分别是(1)句子自动填充任务，(2)推文与评论的匹配，以及(3)同义句识别；结果如下面的图示：</p><p><img src="http://i.imgur.com/wLIUAHW.png" alt=""></p><p><img src="http://i.imgur.com/fO0Xhnj.png" alt=""></p><p><img src="http://i.imgur.com/qRfsoB0.png" alt=""></p><p>其实结构I和结构II的结果相差不大，结构II稍好一些；而相比于其他的模型而言，结构I和结构II的优势还是较大的。</p><h3 id="He’s_Paper">He’s Paper</h3><p>第四篇论文即He的文章中所提出的模型，是所有基于NN的模型中，在Paraphrase identification任务标准数据集MSRP上效果最佳的。下面我们来学习一下这个模型。</p><h4 id="模型结构与原理-1">模型结构与原理</h4><p>模型主要分为两个部分：</p><ul><li><strong>句子的表征模型</strong>：得到句子的表征(representation)，以供后续的相似度计算；</li><li><strong>相似度计算模型</strong>：使用多种相似度计算方法，针对句子表征后的局部进行相应的计算；</li></ul><p>模型不需要借助WordNet, 句法解析树等资源；但是可以选择性地使用词性标注、word embedding等方法来增强模型的性能；与之前的模型区别在于，文中的模型使用了多种类型的卷积、池化方法，以及针对得到的句子表征的局部进行相应的相似度计算。（这样做的优点在于能够更加充分地挖掘出句子中的特征信息，从而提升性能，但同时使得模型变得复杂、耗时）</p><p>模型的整体框架如下：</p><p><img src="http://i.imgur.com/uz4z7le.png" alt=""></p><p>下面具体看看这两个模型是如何实现的。</p><ol><li><strong>句子的表征模型</strong></li></ol><p>模型是基于CNN的，卷积层有两种卷积方式，池化层则有三种。</p><ul><li><strong>卷积层</strong></li></ul><p>假设模型的输入为二维矩阵 \( Sent \)，\( Sent \in R^{len×Dim} \)，其中 \(len\) 表示句子切分为Token List后的长度(Token可以是词/字)，\(Dim\) 表示Token的Embedding表示的维度。由此有 \(Sent_{i}\) 表示矩阵的第 \(i\) 行，即输入中的第 \(i\) 个Token的Embedding表示；\(Sent_{i:j}\) 表示矩阵中的第 \(i\) 到第 \(j\) 行的一个切片，也是一个子矩阵；\(Sent_{i}^{[k]}\) 表示矩阵的第 \(i\) 行第 \(k\) 列的值，对应是Embedding的第 \(k\) 个值；而 \(Sent_{i:j}^{[k]}\) 则是矩阵中第 \(i\) 行到第 \(j\) 行中的第 \(k\) 列的一个切片。</p><p>卷积层有两种卷积的方式：(1)粒度为word的卷积;(2)粒度为embedding 维度上的卷积。如下图：</p><p><img src="http://i.imgur.com/26LDDfD.png" alt=""></p><p>其中，第一种卷积方式与之前的Kim Y提出模型中的相同，相当于是<em>n-gram</em>特征的抽取；而对于第二种卷积方式，论文作者给出的解释是，(1)这种方式有助于充分地提取出输入的特征信息；(2)由于粒度更小，所以在学习过程中的参数调整上，每一个维度能够得到不同程度的参数调整。（第二种卷积方式从直观上没有太多的物理意义，而作者也是直说不能够给出符合人直观想法上的解释）。</p><ul><li><strong>池化层</strong></li></ul><p>模型除了使用传统的<code>max-pooling</code>，还使用了<code>min-pooling</code>和<code>mean-pooling</code>方式。</p><p>假设 \(group(ws, pooling, sent)\) 表示卷积宽度为 \(ws\)，使用 \(pooling\) 池化函数，应用在输入的句子 \(sent\) 上。我们使用了两种类型的<strong><code>building block</code></strong>，分别是 \(block_{A}\) 和 \(block_{B}\) 上，定义如下</p><p>$$ block_{A} = \lbrace group_{A}(ws_{a}, p, sent): p \in {max, min, mean} \rbrace $$</p><p>这里 \(block_{A}\) 有三组卷积层，卷积窗口的宽度一致(都是 \(ws_{a}\) )，每一组对应一种池化操作。这里池化操作和卷积层是一一对应的，也就是说并不是一个卷积层上实施三种池化操作(虽然也可以这么做，作者没有这么做的原因是由于激活函数的存在，对每个卷积结果都进行<code>max-pooling</code>和<code>min-pooling</code>是没有必要的)。</p><p>而 \(block_{B}\) 的定义如下：</p><p>$$ block_{B} = \lbrace group_{B}(ws_{b}, p, sent): p \in {max, min} \rbrace $$</p><p>这里 \(block_{B}\) 有两组卷积层，卷积窗口的宽度为 \(ws_{b}\)，两组分别对应<code>max-pooling</code>和<code>min-pooling</code>的操作。值得说明的是，\(group_{B}(*)\) 中的卷积层对应有 \(Dim\) 个以<code>embedding dimension</code>为粒度的卷积窗口，也就是对<code>embedding</code>的每一维度做卷积运算。</p><p>这里只所以要组合这些多样的卷积和池化操作，原因是希望能够从多个方面来提取出输入中的特征信息，以供后续的决策任务。</p><ul><li><strong>多种窗口尺寸</strong></li></ul><p>与传统的<em>n-gram</em>模型相似，这里在<strong><code>building block</code></strong>中使用了多种尺寸的卷积窗口。如下图所示：</p><p><img src="http://imgur.com/kRijNVc.png" alt=""></p><p>其中 \(ws\) 表示卷积时卷积的<em>n-gram</em>长度，而 \(ws=\infty\) 表示卷积窗口为整个<code>word embedding</code>矩阵。\(ws\) 的值及<code>Feature Map</code> 的数量都是需要调参的。</p><ol><li><strong>相似度计算模型</strong></li></ol><p>下面介绍在得到句子的表征向量之后，如何计算它们的相似度。直观的想法是，我们可以使用传统的相似度计算方法如余弦相似度等来计算两个句子向量的相似度。但是，<strong>直接应用这种做法在两个句子向量上并不是最优的</strong>，原因在于最后生成的句子向量中的每一个部分的意义各不相同，这样简单粗暴的计算势必会影响效果，所以做法是<strong>对句子向量中的各个部分进行相应的比较和计算(Structured Comparision)</strong>。为了使得句子向量中的局部间的比较和计算更加有效，我们需要考虑如下方面：</p><p>(1) 是否来自相同的<code>building block</code>；<br>(2) 是否来自相同卷积窗口大小下的卷积结果；<br>(3) 是否来自相同的<code>pooling层</code>；<br>(4) 是否来自相同的<code>Feature Map</code>；</p><p>最终比较句子中的相应部分时，需要至少满足以上两个条件。为了识别句子中的哪些对应部分需要参与到相似度计算，文中提供了两种算法。</p><p>2.1. <strong>相似度计算单元(Unit)</strong> </p><p>两种相似度计算单元如下：</p><p><img src="http://imgur.com/wttqwKe.png" alt=""></p><p>2.2. <strong>基于句子局部的相似度计算</strong></p><p>算法1和算法2为句子表征向量的两种计算方法，其中算法1仅用在 \(block_{A}\) 上；而算法2则都用在 \(block_{A}\) 和 \(block_{B}\) 上，两种算法都是针对相同类型(pooling和block类型)的输出做局部比较。</p><p>给出如下的符号假设：</p><p><img src="http://imgur.com/0Oxsp9O.png" alt=""></p><p>算法的伪代码如下：</p><p><img src="http://imgur.com/pkDPaky.png" alt=""></p><p>下面的图示说明了在 \(block_{A}\) 上，两种算法的计算方式的区别，算法一表现了向量在水平方向上的比较；而算法二则是在垂直方向。</p><p><img src="http://imgur.com/f4qrseS.png" alt=""></p><p>需要注意的是，在算法二中相同类型的pooling的输出groups中，向量是两两进行比较的（图中的红色虚线只是为了说明比较的方向，并不是只针对group中相同大小的卷积窗口作比较）；而算法一中的每一行都要作比较，不仅仅是第一行。</p><ol><li><strong>模型的其他细节</strong></li></ol><ul><li><strong>相似度向量输出 + 全连接层</strong></li></ul><p>基于句子局部的相似度计算之后，得到相应的相似度向量；然后这组向量之后连接一个全连接层，最后softmax对应输出。如果是计算相似度度量值，可以用softmax输出的类别概率值。</p><ul><li><strong>激活函数</strong></li></ul><p>使用<code>tanh</code>函数作为激活函数。</p><h4 id="实验部分-3">实验部分</h4><ol><li><strong>实验数据集</strong></li></ol><ul><li><a href="http://research.microsoft.com/en-us/downloads/607d14d9-20cd-47e3-85bc-a2f65cd28042/" target="_blank" rel="external">Microsoft Research Paraphrase Corpus (MSRP)</a></li></ul><p>用于评测同义句检测 (Paraphrase Identification) 任务的经典数据集，数据集来源于新闻；包含5801对句子对，其中4076对用于模型训练，而1725对用于测试；每一对句子拥有一个标签，0或者1,0表示两个句子不是互为同义句，而1则表示两个句子互为同义句。因此这是一个二分类的任务。</p><ul><li><a href="http://alt.qcri.org/semeval2014/task1/index.php?id=data-and-tools" target="_blank" rel="external">Sentences Involving Compositional Knowledge (SICK)</a></li></ul><p>数据来源于2014年SemEval比赛，数据集有9927对句子对，其中4500对用于模型训练，500对用于模型验证，而剩下的4927对用于模型测试。这些句子都是在图片和视频描述中抽取得到的，每一对句子对有一个相关分数，区间在[1, 5]，分数越高表示句子越相关。</p><ul><li><a href="https://www.cs.york.ac.uk/semeval-2012/task6/data/uploads/datasets/train-readme.txt" target="_blank" rel="external">Microsoft Video Paraphrase Corpus (MSRVID)</a></li></ul><p>数据集来源于2012年的SemEval比赛，包含1500对短文本（用于描述视频信息）。其中一般用于模型训练，一半用于模型测试，每一对句子有一个相关性分数，区间在[0, 5]，分数越高表示句子越相关。</p><ol><li><strong>模型训练</strong></li></ol><p>针对MSRP和其他两个数据集，分别使用两种损失函数。对于MSRP数据集，损失函数（Hinge Loss）如下：</p><p><img src="http://imgur.com/jjQu3pY.png" alt=""></p><p>对于其余两个数据集，损失函数（KL-divergence Loss）如下：</p><p><img src="http://imgur.com/kfVigMW.png" alt=""></p><ol><li><strong>实验参数设置</strong></li></ol><ul><li><strong>\(ws\) 的值</strong>：\(ws \in [1, 3]\)和 \(ws=\infty\).</li><li><strong>Word Embedding</strong>: 300维的<code>GloVe word embedding</code>；对于MSRP数据集，还额外使用了200维的<code>POS embedding</code> (<a href="http://nlp.stanford.edu/software/tagger.shtml" target="_blank" rel="external">Standford POS tagger</a>)和25维的<code>Paragram Vectors</code> (<a href="http://ttic.uchicago.edu/~wieting/wieting2015TACL.pdf" target="_blank" rel="external">Wieting et al., 2015 PDF</a>，<a href="http://ttic.uchicago.edu/~wieting/paragram_vectors.txt" target="_blank" rel="external">数据下载地址</a>)。因此对于MSRP任务而言，<code>word embedding</code>的维数为525维 (200+300+25)；而其余两个任务则对应是300维。</li><li>在MSRP上使用了<strong>5-折交叉验证</strong>的方式，对模型参数进行<em>tuning</em>. <em>Tuning</em>好的模型参数将会用在另外两个数据集任务上。</li><li>只有在MSRP数据集任务上，允许模型参数进行更新。</li><li>输出的全连接层，MSRP有250个神经元节点，而SICK和MSRVID则是150个。</li><li>在 \(block_{A}\) 中，<code>Feature Map</code> 的数量与输入的<code>embedding</code>维数相同，即MSRP是525个，而SICK和MSRVID则是300个。</li><li>优化算法使用随机梯度下降方法。</li><li>学习率为0.01，而正则化参数 \(\lambda=10^{-4}\).</li></ul><ol><li><strong>实验结果</strong></li></ol><ul><li><strong>MSRP数据集</strong></li></ul><p><img src="http://imgur.com/CLF0SKJ.png" alt=""></p><p>可以看出，文中的模型是所有基于NN的方法中在MSRP数据集上性能最好的。</p><ul><li><strong>SICK数据集</strong></li></ul><p><img src="http://imgur.com/16bJWHS.png" alt=""></p><ul><li><strong>MSRVID数据集</strong></li></ul><p><img src="http://imgur.com/s89LYEb.png" alt=""></p><p>而模型在SICK和MSRVID数据集上的表现也很好。</p><ol><li><strong>模型的敏感度分析</strong></li></ol><p>下面的表格说明了在不使用某种技术下，模型性能在实验数据集上的变化情况。</p><p><img src="http://imgur.com/pmTY9TY.png" alt=""></p><p>从中可以得出以下结论：</p><ul><li>对于MSRP数据集任务而言，增加<strong><code>POS Embedding</code></strong>和<strong><code>Paragram Vector</code></strong>效果显著；</li><li>移除相似度计算层的影响显著，说明结构化的句子局部比较方法是有效且必要的；</li><li><strong><code>Horizontal</code></strong>和<strong><code>Vertical</code></strong>算法均有一定的提升效果，而<strong><code>Vertical</code></strong>算法的提升程度更高；</li><li><strong><code>max-pooling</code></strong>方式确实要比<strong><code>min-pooling</code></strong>和<strong><code>mean-pooling</code></strong>强太多。</li></ul><ol><li><strong>总结</strong></li></ol><p>文中的模型包含两个部分：卷积-池化模型和相似度计算模型。实验部分已经验证了模型的有效性，在MSRP数据集上模型取得了仅次于state-of-art的结果，并且在基于NN的方法中是最好的。模型中的相似度计算层是有必要的，因为对卷积池化处理后的句子成分进行了针对性的比较，从直观上要比直接扔进全连接层更合理，而实验结果也表明了这一点。</p><p>然而，个人觉得，文中的模型结构较为复杂，而且其中有很多trick的地方，比如为什么要对word embedding中的每一维度做卷积，\(block_{B}\) 中的<code>pooling</code>方式为什么只用了max和min，不用mean的方式等问题，而这些方式或许是作者自己做了大量实验后，从果到因而使用的。</p><h3 id="Yin’s_Paper">Yin’s Paper</h3><p>Yin的这篇论文提出了一种叫<code>Bi-CNN-MI</code>的架构，其中<code>Bi-CNN</code>表示两个使用<code>Siamese</code>框架的CNN模型；<code>MI</code>表示多粒度的交互特征。<code>Bi-CNN-MI</code>包含三个部分：</p><ul><li><strong>句子分析模型 (CNN-SM)</strong></li></ul><p>这部分模型主要使用了上述Kal在2014年提出的模型，针对句子本身提取出四种粒度的特征表示：词、短<em>ngram</em>、长<em>ngram</em>和句子粒度。多种粒度的特征表示是非常必要的，一方面提高模型的性能，另一方面增强模型的鲁棒性。</p><ul><li><strong>句子交互计算模型 (CNN-IM)</strong></li></ul><p>这部分模型主要是基于2011年Socher提出的RAE模型，做了一些简化，即仅对同一种粒度下的提取特征做两两比较。</p><ul><li><strong>LR或Softmax网络层以适配任务</strong></li></ul><h4 id="模型结构">模型结构</h4><p>论文提出的模型主要是基于Kal的模型及Socher的RAE模型的结合体，如下图：</p><p><img src="http://imgur.com/Ubku2XR.png" alt=""></p><p>通过模型图可以看出模型的主要思想：一方面利用Kal的模型进行多种粒度上的特征提取，另一方面采取RAE模型的思想，对提取出来的特征进行两两的相似度计算，计算完成的结果通过<code>dynamic pooling</code>的方式进一步提取少量特征，然后各个层次的<code>pooling</code>计算结果平摊为一组向量，通过全连接的方式与LR(或者softmax)层连接，从而适配同义句检测任务本身。</p><p>这个模型具体的计算细节不再赘述了，感兴趣的读者可以直接去看论文。除了提出这种模型结构之外，论文还有一个亮点在于使用了一种类似于语言模型的<code>CNN-LM</code>来对上述CNN部分的模型进行预训练，从而提前确定模型的参数。<code>CNN-LM</code>的网络结构如下图：</p><p><img src="http://imgur.com/zMyzscM.png" alt=""></p><p><code>CNN-LM</code>模型的训练预料使用了最终的实验数据集，即MSRP；另外，由于MSRP的数据规模较小，所以作者又增加了100,000个英文句子语料。<code>CNN-LM</code>模型最终能够得到word embedding, 模型权值等参数。需要注意的是，这些参数并不是固定的，在之后的句子匹配任务中是会不断更新的。从后面的实验结果中可以看出，<code>CNN-LM</code>的作用是显著的。</p><h4 id="实验结果">实验结果</h4><p>论文仅使用了一种数据集，即公认的PI (Paraphrase Identification)任务数据集，MSRP。实验结果如下：</p><p><img src="http://imgur.com/Y67eY0a.png" alt=""></p><p>可以看出，<code>CNN-LM</code>的预训练效果显著，预训练后的模型性能很强（但是结果上比之前He提出的模型稍差一些）。</p><hr><p>本文结束，感谢欣赏。</p><p><strong>欢迎转载，请注明本文的链接地址：</strong></p><p><a href="http://www.jeyzhang.com/cnn-apply-on-modelling-sentence.html">http://www.jeyzhang.com/cnn-apply-on-modelling-sentence.html</a></p><p><strong>参考文献</strong></p><p>[1] R. Socher, E. H. Huang, and A. Y. Ng. Dynamic pooling and unfolding recursive autoencoders for paraphrase detection. In Advances in NIPS, 2011.</p><p><strong>推荐资料</strong></p><p><a href="http://arxiv.org/abs/1510.03820" target="_blank" rel="external">A Sensitivity Analysis of (and Practitioners’ Guide to) Convolutional Neural Networks for Sentence Classification</a></p><p><a href="http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/" target="_blank" rel="external">Implementing a CNN for Text Classification in TensorFlow</a></p><p><a href="https://github.com/yoonkim/CNN_sentence" target="_blank" rel="external">Kim Y’s Implement: Convolutional Neural Networks for Sentence Classification</a></p><hr><p><strong>文章写得不错？打赏一个呗:)</strong></p><p><img src="http://i.imgur.com/tTBAnzw.png" alt=""></p><p><strong>【打赏1.99￥以上，备注你的邮箱，可获得博主精心为你准备的深度学习/机器学习/自然语言处理的学习资料大礼包】</strong></p><p><strong>近期博主准备筹建NLP方面的技术群，欢迎感兴趣的小伙伴加我入群交流:)，加好友请备注：”博客”。</strong></p><p><img src="https://i.imgur.com/pBtBjMe.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;之前的博文已经介绍了CNN的基本原理，本文将大概总结一下最近CNN在NLP中的句子建模（或者句子表示）方面的应用情况，主要阅读了以下的文献：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Kim Y. Convolutional neural networks for sente
      
    
    </summary>
    
      <category term="Machine Learning" scheme="http://www.jeyzhang.com/categories/Machine-Learning/"/>
    
    
      <category term="CNN" scheme="http://www.jeyzhang.com/tags/CNN/"/>
    
      <category term="Deep Learning" scheme="http://www.jeyzhang.com/tags/Deep-Learning/"/>
    
      <category term="Machine Learning" scheme="http://www.jeyzhang.com/tags/Machine-Learning/"/>
    
      <category term="NLP" scheme="http://www.jeyzhang.com/tags/NLP/"/>
    
      <category term="Sentence Model" scheme="http://www.jeyzhang.com/tags/Sentence-Model/"/>
    
  </entry>
  
  <entry>
    <title>词向量表示技术(Word Representation)介绍</title>
    <link href="http://www.jeyzhang.com/introduction-to-word-representation.html"/>
    <id>http://www.jeyzhang.com/introduction-to-word-representation.html</id>
    <published>2016-03-09T01:56:08.000Z</published>
    <updated>2016-03-09T02:03:02.000Z</updated>
    
    <content type="html"><![CDATA[<p>先刨个坑，以后来填:)</p><hr><p>本文结束，感谢欣赏。</p><p><strong>欢迎转载，请注明本文的链接地址：</strong></p><p><a href="http://www.jeyzhang.com/introduction-to-word-representation.html">http://www.jeyzhang.com/introduction-to-word-representation.html</a></p><p><strong>参考资料</strong></p><p><a href="http://licstar.net/archives/328" target="_blank" rel="external">Deep Learning in NLP （一）词向量和语言模型</a></p><p><a href="http://licstar.net/archives/687" target="_blank" rel="external">博士论文《基于神经网络的词和文档语义向量表示方法研究》</a></p><p><a href="http://licstar.net/archives/620" target="_blank" rel="external">《How to Generate a Good Word Embedding?》导读</a></p><p><a href="http://techblog.youdao.com/?p=915" target="_blank" rel="external">Deep Learning实战之word2vec</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;先刨个坑，以后来填:)&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;本文结束，感谢欣赏。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;欢迎转载，请注明本文的链接地址：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.jeyzhang.com/introduction-to-word-
      
    
    </summary>
    
      <category term="Machine Learning" scheme="http://www.jeyzhang.com/categories/Machine-Learning/"/>
    
    
      <category term="Deep Learning" scheme="http://www.jeyzhang.com/tags/Deep-Learning/"/>
    
      <category term="Machine Learning" scheme="http://www.jeyzhang.com/tags/Machine-Learning/"/>
    
      <category term="Word Embedding" scheme="http://www.jeyzhang.com/tags/Word-Embedding/"/>
    
      <category term="Word2Vector" scheme="http://www.jeyzhang.com/tags/Word2Vector/"/>
    
  </entry>
  
  <entry>
    <title>2015年校招总结：技术面试干货</title>
    <link href="http://www.jeyzhang.com/2015-campus-recurit-technology-interview-summary.html"/>
    <id>http://www.jeyzhang.com/2015-campus-recurit-technology-interview-summary.html</id>
    <published>2016-03-03T12:11:07.000Z</published>
    <updated>2016-05-24T02:53:01.000Z</updated>
    
    <content type="html"><![CDATA[<p>关于实习及校招的全面概括性总结在<a href="http://www.jeyzhang.com/2015-campus-recruit-summary.html"><strong>这篇博文</strong></a>，里面也提出了一些技术面试过程中的注意事项。本文主要是单纯针对<strong>程序员技术面试的面试内容</strong>，将（1）推荐一些优秀的资源（包括书籍、网站等），以及（2）总结一下自己及周遭同学在实习与校招技术面试过程中遇到的各种原题，以供后人参考。</p><hr><h1 id="推荐资源">推荐资源</h1><h2 id="书籍">书籍</h2><h3 id="算法类">算法类</h3><ul><li><strong>《Crack the code interview》(Gayle Laakmann著) [<a href="http://vdisk.weibo.com/s/DpqS8KKk4Vcu" target="_blank" rel="external">PDF下载地址</a>]</strong></li></ul><p>这本书是经典的程序员技术面试必备书了，作者是曾经的Google面试官，从面试官的角度教你应该如何一步步地准备面试。书中分析了硅谷的一些巨头公司的面试风格和特点，对于想要面国外公司的再合适不过了；还帮助你制定了面试准备的流程和计划，给出写简历的建议，如何应对行为面试(Behavioral Interview)等；当然，最主要的篇幅集中在技术面试的准备中，总结了常见的数据结构及相应的算法题，数理概率，及一些其他面试中常见的技术题型。</p><ul><li><strong>《进军硅谷：程序员面试揭秘》(陈东锋著) [<a href="https://book.douban.com/subject/25844586/" target="_blank" rel="external">豆瓣地址</a>]</strong></li></ul><p>尽管这本书在豆瓣上的评分很低（leetcode作者认为该书抄袭了leetcode上的题目…），但对于面试者来说，这本书还是值得推荐的。这本书前面部分也是主要介绍了一下面试流程和注意事项，硅谷公司的特点；其余的大篇幅都是集中在算法题的解题思路分析和代码实现，确实大部分的算法题与leetcode上的一样，所以刷leetcode的时候配合这本书，应该会顺畅挺多的。这本书的代码都是Java，简单易懂。</p><ul><li><strong>《剑指Offer》(何海涛著) [<a href="http://vdisk.weibo.com/s/EjagsS5Ugjw" target="_blank" rel="external">PDF下载地址</a>]</strong></li></ul><p>这本书的结构其实与前两本比较类似，但是有一个亮点是，对于所有的算法题都会给出测试样例，包括特殊边界和正常功能测试样例等。写算法题能够提前考虑测试样例是非常好的编程习惯，称之为<strong><code>防御式编程</code></strong>；大多数人都是习惯写完代码后，再进行样例测试，然后修修补补之类的。</p><ul><li><strong>《微软面试100题系列》(July著) [<a href="http://vdisk.weibo.com/s/akZyBqthxGDMn?from=page_100505_profile&amp;wvr=6" target="_blank" rel="external">PDF下载地址</a>]</strong></li></ul><p>严格上来说，这个并不是一本正式的书籍。但是这个资料里收集了许多经典真实的企业面试题。题型比较杂，大部分是算法题，还有智力题等。虽然答案不是很全，但是值得好好看看里面的题，从本人的笔试面试经历来看，遇到了里面挺多的原题~</p><ul><li><strong>《编程之美：微软技术面试心得》[<a href="http://download.csdn.net/detail/sunmeng_alex/4606246" target="_blank" rel="external">PDF下载地址</a>]</strong></li></ul><p>如果时间充裕的话，这本书也可一看。这本书是由MSRA的一些FTE和实习生们编写的，老实说，这本书中很多题还是挺有难度的，有许多数学相关的题，不折不扣地考验你的智商……偶尔翻翻，转转脑子也挺好的。</p><p>此外，还有一些神书，例如《算法导论》《编程珠玑》也可一看。但是，时间总是有限的，<strong>认真刷刷1-2本书，然后多动手配合刷题（刷题平台下面有推荐）</strong>，应付面试的算法能力自然会慢慢变强。</p><h3 id="数据结构类">数据结构类</h3><ul><li><strong>《Java数据结构和算法》(Robert Lafore著) [<a href="http://vdisk.weibo.com/s/dhYy6pCj8N-9z?from=page_100505_profile&amp;wvr=6" target="_blank" rel="external">PDF下载地址</a>]</strong></li></ul><p>相比起清华的严奶奶那本，这本书通俗易懂得多:)要是觉得之前的数据结构掌握的不够好，这本书绝对能拉你入门~</p><ul><li><strong>《数据结构：C语言版》(严蔚敏著) [<a href="http://vdisk.weibo.com/s/aFmBnrN-WDuX6" target="_blank" rel="external">PDF下载地址</a>]</strong></li></ul><p>虽然刚学的时候觉得晦涩难懂，但是还是国内经典的书籍，对数据结构研究的比较深刻，内容较上本会丰富很多。</p><h3 id="编程语言类">编程语言类</h3><ul><li><strong>Java</strong></li></ul><p>《Java编程思想》(Bruce Eckel著) [<a href="http://vdisk.weibo.com/s/aPgqW10HL3Q90" target="_blank" rel="external">PDF下载地址</a>]</p><p>《Effective Java》(Joshua Bloch著)(中文版) [<a href="http://vdisk.weibo.com/s/grsVw" target="_blank" rel="external">PDF下载地址</a>] | (英文版) [<a href="http://vdisk.weibo.com/s/dq65Vm6HA4vmD" target="_blank" rel="external">PDF下载地址</a>]</p><p>《疯狂Java讲义》(李刚著) [<a href="http://vdisk.weibo.com/s/A-1hO0QV0ZhQ" target="_blank" rel="external">PDF下载地址</a>]</p><ul><li><strong>C</strong></li></ul><p>《C Primer Plus》(Stephen Prata著) [<a href="http://vdisk.weibo.com/s/zfhMNTK9gWJOV" target="_blank" rel="external">PDF下载地址</a>]</p><p>《征服C指针》(前桥和弥著) [<a href="http://vdisk.weibo.com/s/e41M8kWaqoim" target="_blank" rel="external">PDF下载地址</a>]</p><ul><li><strong>Python</strong></li></ul><p>《Python基础教程》(Magnus Lie Hetland著) [<a href="http://vdisk.weibo.com/s/dhZbFvYADsgqr" target="_blank" rel="external">PDF下载地址</a>]</p><p>《Python简明教程》(Swaroop著) [<a href="http://vdisk.weibo.com/s/BE2Z8B94-5w97" target="_blank" rel="external">PDF下载地址</a>]</p><p>《利用Python进行数据分析》(Wes McKinney著) [<a href="http://vdisk.weibo.com/s/AFN3jW3skIDf" target="_blank" rel="external">PDF下载地址</a>]</p><p>《Learn Python The Hard Way》[<a href="http://vdisk.weibo.com/s/BCRaGM7XY1jut" target="_blank" rel="external">PDF下载地址</a>]</p><h3 id="数据库类">数据库类</h3><p>《SQL必知必会》(Ben Forta著) [<a href="http://vdisk.weibo.com/s/y-3ktzWX4vlzr" target="_blank" rel="external">PDF下载地址</a>]</p><p>《深入浅出SQL》(Lynn Beighley著) [<a href="http://vdisk.weibo.com/s/aHSh1alRGXpb" target="_blank" rel="external">PDF下载地址</a>]</p><p>《高性能MySQL》(Baron Schwarlz等著) [<a href="http://vdisk.weibo.com/s/GNZwNnGfiqSm" target="_blank" rel="external">PDF下载地址</a>]</p><h2 id="刷题网站">刷题网站</h2><ul><li><strong><a href="https://leetcode.com/" target="_blank" rel="external">Leetcode</a></strong></li></ul><p>众所周知的刷题网站了，许多公司的面试题都是从里面出的。建议刷3遍左右。</p><ul><li><strong><a href="http://www.lintcode.com/" target="_blank" rel="external">Lintcode</a></strong></li></ul><p>一个类似于leetcode的刷题网站，但是比起leetcode，里面的题目更加齐全。还有一些特色的功能，如限时提交，编程风格检测等。</p><ul><li><strong><a href="http://ac.jobdu.com/" target="_blank" rel="external">九度OJ</a></strong></li></ul><p>里面收录了《剑指Offer》中的题，可以配合看书练习。还有一些考研机试、比赛类型的题，适合刷完leetcode等网站后，磨练算法能力。</p><ul><li><strong><a href="http://www.hihocoder.com/" target="_blank" rel="external">hihoCoder</a></strong></li></ul><p>这个平台经常举办一些编程比赛，一些公司的笔试会选择在这个平台进行，例如微软(中国)、网易游戏等。另外，这个平台里面的题有一定难度，适合算法能力中上的人。</p><h2 id="网站与论坛">网站与论坛</h2><ul><li><strong><a href="http://www.jiuzhang.com/" target="_blank" rel="external">九章算法</a></strong></li></ul><p>曾经上过它的算法课，还可以。里面有leetcode中大多数题的解答（只有代码，大多数是Java），还有一些面筋之类的分享。有时间和米的还可以去听听他家的课，都是PPT+白板+语音的形式。</p><ul><li><p><strong><a href="http://www.geeksforgeeks.org/" target="_blank" rel="external">GeeksforGeeks</a></strong> </p></li><li><p><strong><a href="https://www.careercup.com/" target="_blank" rel="external">Career Cup</a></strong></p></li></ul><p>以上这两个网站上面有很多国外最近的、真实的面试题分享和讨论，也可以经常去水水~另外，这个<strong><a href="https://www.zhihu.com/question/20368410" target="_blank" rel="external">知乎问题</a></strong>，票数第一的回答还总结了挺多的。</p><ul><li><strong><a href="http://home.cnblogs.com/u/v-July-v/" target="_blank" rel="external">July的cnblog</a></strong></li></ul><p>这个博主总结了之前提及的《微软面试100题系列》，有个<strong><a href="http://www.cnblogs.com/v-July-v/archive/2012/03/22/2413055.html" target="_blank" rel="external">教你如何迅速秒杀99%的海量数据处理面试题</a></strong>也写得不错，基本足够应付面试中遇到的大数据相关的题。</p><ul><li><strong><a href="http://www.cnblogs.com/harrygogo/" target="_blank" rel="external">我的cnblog</a></strong></li></ul><p>之前在面试准备过程中，在cnblog上建了个博客，记录了以下刷的算法题及面试题。欢迎访问。</p><h1 id="真实面筋">真实面筋</h1><h2 id="算法和数据结构">算法和数据结构</h2><blockquote><p><strong>Google SED实习</strong></p></blockquote><ul><li>非递归实现二叉树深度的求解</li><li>如何实现双端队列</li></ul><blockquote><p><strong>阿里春招实习</strong></p></blockquote><ul><li>一维的连连看实现 </li><li>动归和贪心的区别 </li><li>大小为999的一维数组，按序存放着1-1000的数字，但有一个数字缺失，找到它</li><li>最长公共子序列 </li><li>一个排序的数组, 如何做压缩?</li><li>三个排序数组, 找到同时存在于三个数组中的元素</li><li>three sum</li><li>判断链表中有环 环的大小</li><li>写个KMP</li><li>给定一些金币，金币的数额都是2的整数幂，然后每种硬币都有两枚，然后给定一个数额，求可行的组合方式（重复不算）[动态规划]</li><li>给定一个m*n的长方形，然后每次对长方形进行分割，分割的直线均平行于长方形的边，而且落在长方形内，给定一系列有顺序的分割直线，问每次分割后形成的所有小长方形中面积最大的。[最小堆]</li><li>Leetcode: Excel Sheet Column Title</li><li>给定N个骰子, 每一面上有一个字母. 给定一个长度为M的单词. 问这些骰子您不能拼出这个单词. 每个骰子只能用一次, 顺序随便排.</li><li>两个骰子, 每个骰子各个面上可以放不同数字(自己安排数字), 问能否组成1~31. 如果扩展为N个骰子, 能组成的最长的连续数字(从1开始)是多大.</li><li>数组表示的数, 实现一个加一函数.</li><li>字符串中找到字母数不超过M的最长子串.</li><li></li></ul><blockquote><p><strong>Hulu实习</strong></p></blockquote><ul><li>判断一颗二叉树是否完全二叉树</li><li>给一个整数数组，找其中的连续子序列，使得字段和的绝对值最小</li><li>给一个单链表，写个快排</li><li>给一个值已排序的双链表，双链表存储在一个Node*数组里，每个元素是一个指向双链表某个节点的指针。现在只有一次查询x，找到x在双链表中的位置或报告找不到</li><li>整数数组，找到满足f(j) &gt; f(i) 最大的（j - i）</li><li>一个数组两种操作，1）修改数组中的一个值，2）计算数组某个子区间所有数字之和。写个线段树？</li><li>一个矩形格子区域，每个格子上有一个数字，还有红蓝2中颜色其中之一，初始从某个位置开始，问能否找到一条能够走到边界外的路线，这条路线要满足，1）数字大小严格递增，2）红蓝两色至少各出现一次。（搜索？我先说宽搜，后来想想只要找一条就行那就深搜。这里貌似可以记忆化一下存储一些信息，可惜当时并没有很清晰地考虑清楚，而且时间不很足够的样子了。写代码。）</li><li>写代码判断一棵树是否是完全二叉树</li><li>一个长度为n的数组，求最小连续子段和，求绝对值最小的连续子段和，求绝对值最接近某个数的连续子段和</li><li>蛇形打印矩阵</li><li>n个数字，a1,a2…an，数字之间可以添加+、*、括号变成一个表达式，求表达式的最大值</li><li>有一个字符串流，里面是一些单词和空格。给一个api：read_char()，每次调用将在流中读取一个字符，如果遇到流的结尾，则返回0。请设计函数print_stream()，通过调用read_char()打印流中的单词，要求，每行长度不超过M，一个单词不能跨越两行，单词之间只保留1个空格，删除首尾空格。</li><li>n个元素的数组，设计算法找出现次数大于n/3的元素，要求时空复杂度尽可能小</li><li></li></ul><blockquote><p><strong>有道实习</strong></p></blockquote><ul><li>判断2个url是否是同一个网站的。比如news.sina.com.cn/asdasd和car.sina.com.cn/asdasd/asdasd就是同一个网站的.</li><li>给定整数b，求最大的a，满足a*(a+b)是完全平方数</li><li>给定一个棋盘，马初始在(0,0)，棋盘上有些点为禁行点，用*表示。另外棋盘上有个兵，兵的移动路线已知，每次移一步，在棋盘上用1,2,3….表示出。要求计算马最少跳多少步能把兵吃掉。</li><li></li></ul><blockquote><p><strong>豌豆荚</strong></p></blockquote><ul><li>实现atoi函数</li><li>码镜像二叉树</li><li>找最后一个出现的字符串匹配</li><li>求树的深度</li><li>高精度加法</li><li></li></ul><blockquote><p><strong>网易游戏实习</strong></p></blockquote><ul><li>m个数中找最小的n个</li><li>删除链表的某个节点</li><li>无向普通图G中找两个点最短路径</li><li></li></ul><h2 id="大数据">大数据</h2><blockquote><p><strong>阿里春招实习</strong></p></blockquote><ul><li>集合A：40亿个未排序，不重复的unsigned int；集合B：1万个unsined int；判断集合B中的数是否属于集合A。（输出1W个bool值）</li><li>1亿个查询记录，找出frequency top1000；follow up：讲解堆的调整过程。</li><li><a href="http://www.cnblogs.com/v-July-v/archive/2012/03/22/2413055.html" target="_blank" rel="external">一个100G的文件, 存放搜索的关键词, 统计其中出现最多的20个</a></li><li>现在有淘宝的登录日志5亿条, 支付宝登录日志3亿条, 假设账号最多20个汉字. 找到所有两个都登陆过的账号. (哈希表使用的具体数据结构, 冲突如何处理, 分析下分解之后文件应该有多大才能保证内存能装下, 重复条目处理)</li><li>100万个数字, 没有重复的有序数组, 有什么办法压缩大小.</li><li>Hadoop题：一个表每一行是一个key和许多value，有另一个表，记录着value到value’的映射。问题1）若第二个表不很大，写个hadoop 2）若第二个表很大，写个hadoop。</li><li>1亿条搜索输入文本记录，找到频率topN条，写代码。</li><li></li></ul><h2 id="数据挖掘和机器学习">数据挖掘和机器学习</h2><blockquote><p><strong>阿里春招实习</strong></p></blockquote><ul><li>如何识别买家评价的虚假评价</li><li>SVM特征怎么提的，参数怎么调的，半监督学习是在干嘛，整体学习是在干嘛?</li><li>讲解CNN，CNN和DNN相比有什么优点为什么用它?</li><li>随机森林和决策树的基本原理 </li><li>SVM原理及公式推导 </li><li>Boosting算法 </li><li>对数线性模型 </li><li>概率主题模型，LDA思想 </li><li>怎么判断两个词指的是同一个东西（语言模型，Wordvec）</li><li>对推荐和搜索排序的理解</li></ul><h2 id="编程语言">编程语言</h2><h3 id="C/C++">C/C++</h3><blockquote><p><strong>阿里春招实习</strong></p></blockquote><ul><li>C++的多态和虚函数</li><li>malloc和new关键字</li><li><a href="http://www.cnblogs.com/graphics/archive/2010/07/04/1770900.html" target="_blank" rel="external">类的构造函数初始化和初始化列表初始化区别</a></li><li>虚函数表</li><li></li><li></li></ul><blockquote><p><strong>网易游戏实习</strong></p></blockquote><ul><li>如果一个static对象被创建，什么时候被创建和删除</li><li>介绍overload和override</li><li>介绍inline (原理，编译器，优缺点，虚函数和Inline同时声明)</li><li>多态的实现机制(虚函数表，虚指针)</li><li>知不知道智能指针，介绍一下，如果多个线程同用一个shared_ptr，会不会互相影响，实现机制是什么样的(比如shared_ptr和它所指向的对象分别存在哪)</li><li>vector实现机制，他和list区别</li><li>map和set的实现机制，以及为什么不用其他的平衡二叉树；除了上面的BST实现方法,map还能怎么实现，以及实现机制</li><li>虚拟内存的作用和实现机制</li><li>介绍动态链接库和静态连接库，如果在运行时找到DLL中的那个函数入口</li><li></li></ul><h3 id="Java">Java</h3><blockquote><p><strong>阿里春招实习</strong></p></blockquote><ul><li>Spring的IOC是什么？Spring是怎么实现依赖控制的？</li><li>Java的synchronized和lock有什么区别？volatile有什么作用？</li><li>Java的hashmap怎么实现。</li><li></li></ul><blockquote><p><strong>网易游戏实习</strong></p></blockquote><ul><li><blockquote><p><strong>豌豆荚实习</strong></p></blockquote></li><li><p>类继承/接口实现</p></li><li>synchronize</li><li>线程安全的单例模式</li><li></li></ul><h3 id="Python">Python</h3><h2 id="移动客户端开发">移动客户端开发</h2><h3 id="Android">Android</h3><blockquote><p><strong>阿里春招实习</strong></p></blockquote><ul><li>Android的fragment和activity有什么区别？activity能否在不同的进程中启动？</li><li></li></ul><h3 id="iOS">iOS</h3><h2 id="计算机网络">计算机网络</h2><blockquote><p><strong>阿里春招实习</strong></p></blockquote><ul><li>HTTP协议中的SSL怎么实现？</li><li>1G文件, 点到点传输, 提高传输速率</li><li></li></ul><blockquote><p><strong>网易游戏实习</strong></p></blockquote><ul><li>TCP三次握手和四次握手</li><li>TCP, UPD, HTTP的关系，还问我会不会socket编程</li><li>cache的作用和实现机制</li><li></li></ul><h2 id="数据库">数据库</h2><h2 id="操作系统">操作系统</h2><blockquote><p><strong>阿里春招实习</strong></p></blockquote><ul><li>操作系统分页和分块有什么区别？</li><li>什么是线程安全？</li></ul><blockquote><p><strong>网易游戏实习</strong></p></blockquote><ul><li>进程之间通信方法</li></ul><h3 id="Linux">Linux</h3><h2 id="系统设计">系统设计</h2><blockquote><p><strong>阿里春招实习</strong></p></blockquote><ul><li>设计个系统：在搜索框里输入一个词，找到以它为前缀的商品，显示给用户作为辅助输入提示</li><li></li></ul><h2 id="数学、智力题">数学、智力题</h2><blockquote><p><strong>Hulu实习</strong></p></blockquote><ul><li>四个瓶子，每个瓶子10个药丸，某些瓶子里的药丸全是坏的，正常药丸是10g，坏药丸是9g。现在只能进行一次称量重量操作，确定哪些药瓶里的药丸是坏的。药瓶里的药丸全是好的或者全是坏的；不准切割或溶解药丸。 如果每个瓶子里只有7个药丸呢？</li><li>四个人A、B、C、D，站成一排，面向西边，每人头顶戴顶帽子，帽子有红黄蓝三种颜色，每个人只能看见自己前面的人的帽子的颜色，比如C可以看见A的和B的，A看不见任何人的帽子。现在有3顶红色帽子，2顶黄色帽子，1顶蓝色帽子，随机给这几个人带上。然后D说自己不知道自己是什么颜色，C说自己不知道自己是是什么颜色，B说自己不知道自己是什么颜色，A说自己知道自己是什么颜色，问A怎么推测的。在A说出自己帽子的颜色后，B、C、D能否确定自己帽子的颜色？</li><li></li></ul><h2 id="杂项">杂项</h2><blockquote><p><strong>阿里春招实习</strong></p></blockquote><ul><li>接触过什么开源项目</li><li>最近读过的值得推荐的书是什么</li></ul><hr><p>本文结束，感谢欣赏。</p><p><strong>欢迎转载，请注明本文的链接地址：</strong></p><p><a href="http://www.jeyzhang.com/2015-campus-recurit-technology-interview-summary.html">http://www.jeyzhang.com/2015-campus-recurit-technology-interview-summary.html</a></p><p><strong>最后特别感谢2015年面点交流群各位伙伴的面筋:)</strong></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;关于实习及校招的全面概括性总结在&lt;a href=&quot;http://www.jeyzhang.com/2015-campus-recruit-summary.html&quot;&gt;&lt;strong&gt;这篇博文&lt;/strong&gt;&lt;/a&gt;，里面也提出了一些技术面试过程中的注意事项。本文主要是单纯
      
    
    </summary>
    
      <category term="Interview" scheme="http://www.jeyzhang.com/categories/Interview/"/>
    
    
      <category term="Algorithm" scheme="http://www.jeyzhang.com/tags/Algorithm/"/>
    
      <category term="IT" scheme="http://www.jeyzhang.com/tags/IT/"/>
    
      <category term="Interview" scheme="http://www.jeyzhang.com/tags/Interview/"/>
    
      <category term="Job" scheme="http://www.jeyzhang.com/tags/Job/"/>
    
  </entry>
  
</feed>
